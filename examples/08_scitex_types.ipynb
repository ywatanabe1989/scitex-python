{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for automated execution\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Type Handling Utilities Tutorial\n",
    "\n",
    "This comprehensive notebook demonstrates the SciTeX types module, covering type definitions, type checking utilities, and validation functions for scientific computing workflows.\n",
    "\n",
    "## Features Covered\n",
    "\n",
    "### Type Definitions\n",
    "* ArrayLike - Union type for array-like objects\n",
    "* ColorLike - Union type for color representations\n",
    "\n",
    "### Type Checking Functions\n",
    "* is_array_like - Check if object is array-like\n",
    "* is_listed_X - Check if list contains specific types\n",
    "* is_list_of_type - Conventional alias for type checking\n",
    "\n",
    "### Applications\n",
    "* Input validation for scientific functions\n",
    "* Type safety in data processing pipelines\n",
    "* Flexible parameter handling\n",
    "* Cross-library compatibility checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect notebook name for output directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get notebook name (for papermill compatibility)\n",
    "notebook_name = \"08_scitex_types\"\n",
    "if 'PAPERMILL_NOTEBOOK_NAME' in os.environ:\n",
    "    notebook_name = Path(os.environ['PAPERMILL_NOTEBOOK_NAME']).stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "import scitex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import List, Tuple, Union, Any\n",
    "\n",
    "# Try to import optional dependencies\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import xarray as xr\n",
    "    XARRAY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XARRAY_AVAILABLE = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ArrayLike Type and Validation\n",
    "\n",
    "### 1.1 Understanding ArrayLike\n",
    "\n",
    "The ArrayLike type union allows functions to accept various array-like objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different types of array-like objects\n",
    "test_objects = {\n",
    "    'python_list': [1, 2, 3, 4, 5],\n",
    "    'python_tuple': (1, 2, 3, 4, 5),\n",
    "    'numpy_array': np.array([1, 2, 3, 4, 5]),\n",
    "    'pandas_series': pd.Series([1, 2, 3, 4, 5]),\n",
    "    'pandas_dataframe': pd.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]}),\n",
    "    'nested_list': [[1, 2], [3, 4], [5, 6]],\n",
    "    'string': \"not an array\",\n",
    "    'integer': 42,\n",
    "    'float': 3.14,\n",
    "    'dictionary': {'a': 1, 'b': 2}\n",
    "}\n",
    "\n",
    "# Add optional objects if available\n",
    "if TORCH_AVAILABLE:\n",
    "    test_objects['torch_tensor'] = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "if XARRAY_AVAILABLE:\n",
    "    test_objects['xarray_dataarray'] = xr.DataArray([1, 2, 3, 4, 5], dims=['x'])\n",
    "\n",
    "# Test is_array_like function\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "array_like_results = {}\n",
    "print_count = 0  # Limit output\n",
    "for name, obj in test_objects.items():\n",
    "    is_array_like = scitex.types.is_array_like(obj)\n",
    "    array_like_results[name] = is_array_like\n",
    "    status = \"\u2713 Array-like\" if is_array_like else \"\u2717 Not array-like\"\n",
    "    obj_type = type(obj).__name__\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "# Summary\n",
    "array_like_count = sum(array_like_results.values())\n",
    "total_count = len(array_like_results)\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Array-like Operations and Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate operations with different array-like types\n",
    "def process_array_like(data, operation=\"sum\"):\n",
    "    \"\"\"\n",
    "    Process array-like data with type checking.\n",
    "    \n",
    "    Args:\n",
    "    data: ArrayLike object\n",
    "    operation: Operation to perform ('sum', 'mean', 'max', 'min')\n",
    "    \n",
    "    Returns:\n",
    "    Result of operation or None if data is not array-like\n",
    "    \"\"\"\n",
    "    if not scitex.types.is_array_like(data):\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        return None\n",
    "    \n",
    "print_count = 0  # Limit output\n",
    "    # Convert to numpy array for consistent operations\n",
    "    try:\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            # For DataFrames, operate on all numeric columns\n",
    "            numeric_data = data.select_dtypes(include=[np.number])\n",
    "            if numeric_data.empty:\n",
    "                if print_count < 5:  # Limit output\n",
    "                print_count += 1\n",
    "                return None\n",
    "            data_array = numeric_data.values\n",
    "        elif isinstance(data, pd.Series):\n",
    "            data_array = data.values\n",
    "        elif TORCH_AVAILABLE and torch.is_tensor(data):\n",
    "            data_array = data.numpy()\n",
    "        elif XARRAY_AVAILABLE and isinstance(data, xr.DataArray):\n",
    "            data_array = data.values\n",
    "        else:\n",
    "            data_array = np.array(data)\n",
    "        \n",
    "        # Perform operation\n",
    "        if operation == \"sum\":\n",
    "            result = np.sum(data_array)\n",
    "        elif operation == \"mean\":\n",
    "            result = np.mean(data_array)\n",
    "        elif operation == \"max\":\n",
    "            result = np.max(data_array)\n",
    "        elif operation == \"min\":\n",
    "            result = np.min(data_array)\n",
    "        else:\n",
    "            result = f\"Unknown operation: {operation}\"\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        return None\n",
    "\n",
    "# Test the function with different array-like objects\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "operations = ['sum', 'mean', 'max', 'min']\n",
    "processing_results = {}\n",
    "\n",
    "# Select only array-like objects for processing\n",
    "array_like_objects = {name: obj for name, obj in test_objects.items() \n",
    "    if array_like_results[name]}\n",
    "\n",
    "for op in operations:\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    \n",
    "    operation_results = {}\n",
    "    for name, obj in array_like_objects.items():\n",
    "        result = process_array_like(obj, op)\n",
    "        operation_results[name] = result\n",
    "        \n",
    "        if result is not None:\n",
    "            if print_count < 5:  # Limit output\n",
    "            print_count += 1\n",
    "        else:\n",
    "            if print_count < 5:  # Limit output\n",
    "            print_count += 1\n",
    "    \n",
    "    processing_results[op] = operation_results\n",
    "\n",
    "# Test with non-array-like objects\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "non_array_objects = {name: obj for name, obj in test_objects.items() \n",
    "    if not array_like_results[name]}\n",
    "\n",
    "for name, obj in non_array_objects.items():\n",
    "    result = process_array_like(obj, 'sum')\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Cross-library Compatibility Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate seamless conversion between different array-like types\n",
    "def convert_array_like(data, target_type):\n",
    "    \"\"\"\n",
    "    Convert array-like data to specified target type.\n",
    "    \n",
    "    Args:\n",
    "    data: ArrayLike object\n",
    "    target_type: Target type ('numpy', 'pandas_series', 'pandas_dataframe', 'list', 'torch', 'xarray')\n",
    "    \n",
    "    Returns:\n",
    "    Converted data or None if conversion fails\n",
    "    \"\"\"\n",
    "    if not scitex.types.is_array_like(data):\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # First convert to numpy array as intermediate format\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            # For DataFrames, use the first numeric column or all numeric data\n",
    "            numeric_data = data.select_dtypes(include=[np.number])\n",
    "            if not numeric_data.empty:\n",
    "                if numeric_data.shape[1] == 1:\n",
    "                    np_array = numeric_data.iloc[:, 0].values\n",
    "                else:\n",
    "                    np_array = numeric_data.values\n",
    "            else:\n",
    "                np_array = np.array(data.values)\n",
    "        elif isinstance(data, pd.Series):\n",
    "            np_array = data.values\n",
    "        elif TORCH_AVAILABLE and torch.is_tensor(data):\n",
    "            np_array = data.detach().numpy() if data.requires_grad else data.numpy()\n",
    "        elif XARRAY_AVAILABLE and isinstance(data, xr.DataArray):\n",
    "            np_array = data.values\n",
    "        else:\n",
    "            np_array = np.array(data)\n",
    "        \n",
    "        # Convert to target type\n",
    "        if target_type == 'numpy':\n",
    "            return np_array\n",
    "        elif target_type == 'list':\n",
    "            return np_array.tolist()\n",
    "        elif target_type == 'pandas_series':\n",
    "            return pd.Series(np_array.flatten() if np_array.ndim > 1 else np_array)\n",
    "        elif target_type == 'pandas_dataframe':\n",
    "            if np_array.ndim == 1:\n",
    "                return pd.DataFrame({'data': np_array})\n",
    "            else:\n",
    "                return pd.DataFrame(np_array)\n",
    "        elif target_type == 'torch' and TORCH_AVAILABLE:\n",
    "            return torch.from_numpy(np_array.astype(np.float32))\n",
    "        elif target_type == 'xarray' and XARRAY_AVAILABLE:\n",
    "            if np_array.ndim == 1:\n",
    "                return xr.DataArray(np_array, dims=['x'])\n",
    "            else:\n",
    "                return xr.DataArray(np_array, dims=['x', 'y'])\n",
    "        else:\n",
    "            return f\"Unsupported target type: {target_type}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        return None\n",
    "\n",
    "# Test conversions with sample data\n",
    "sample_data = np.random.randn(5, 3)\n",
    "target_types = ['numpy', 'list', 'pandas_series', 'pandas_dataframe']\n",
    "\n",
    "if TORCH_AVAILABLE:\n",
    "    target_types.append('torch')\n",
    "if XARRAY_AVAILABLE:\n",
    "    target_types.append('xarray')\n",
    "\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "conversion_results = {}\n",
    "print_count = 0  # Limit output\n",
    "for target in target_types:\n",
    "    converted = convert_array_like(sample_data, target)\n",
    "    conversion_results[target] = converted\n",
    "    \n",
    "    if converted is not None and not isinstance(converted, str):\n",
    "        converted_type = type(converted).__name__\n",
    "        if hasattr(converted, 'shape'):\n",
    "            shape_info = f\"shape: {converted.shape}\"\n",
    "        elif hasattr(converted, '__len__'):\n",
    "            shape_info = f\"length: {len(converted)}\"\n",
    "        else:\n",
    "            shape_info = \"scalar\"\n",
    "        \n",
    "        # Check if converted object is array-like\n",
    "        is_still_array_like = scitex.types.is_array_like(converted)\n",
    "        array_like_status = \"\u2713\" if is_still_array_like else \"\u2717\"\n",
    "        \n",
    "        if print_count < 5:  # Limit output\n",
    "            print_count += 1\n",
    "    else:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "\n",
    "# Demonstrate round-trip conversions\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "original_list = [1, 2, 3, 4, 5]\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "# Convert through different types and back to list\n",
    "conversion_chain = ['numpy', 'pandas_series', 'pandas_dataframe', 'list']\n",
    "current_data = original_list\n",
    "\n",
    "for i, target in enumerate(conversion_chain):\n",
    "    current_data = convert_array_like(current_data, target)\n",
    "    if current_data is not None:\n",
    "        data_preview = str(current_data)[:50] + \"...\" if len(str(current_data)) > 50 else str(current_data)\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    else:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        break\n",
    "\n",
    "# Check if we got back to the original\n",
    "if current_data is not None and isinstance(current_data, list):\n",
    "    success = current_data == original_list\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if success:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "else:\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: ColorLike Type and Color Handling\n",
    "\n",
    "### 2.1 Understanding ColorLike\n",
    "\n",
    "The ColorLike type allows flexible color specification in scientific plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different types of color specifications\n",
    "color_examples = {\n",
    "    'named_color': 'red',\n",
    "    'hex_color': '#FF5733',\n",
    "    'rgb_tuple': (0.2, 0.6, 0.8),\n",
    "    'rgba_tuple': (0.2, 0.6, 0.8, 0.7),\n",
    "    'rgb_list': [0.9, 0.3, 0.1],\n",
    "    'rgba_list': [0.9, 0.3, 0.1, 0.5],\n",
    "    'matplotlib_color': 'C0',  # Matplotlib color cycle\n",
    "    'grayscale': '0.5',  # Grayscale value\n",
    "    'invalid_string': 'not_a_color',\n",
    "    'invalid_tuple': (1, 2),  # Wrong number of elements\n",
    "    'invalid_list': [1, 2, 3, 4, 5],  # Too many elements\n",
    "    'invalid_type': 42\n",
    "}\n",
    "\n",
    "def is_valid_color(color):\n",
    "    \"\"\"\n",
    "    Check if a color specification is valid according to ColorLike type.\n",
    "    \n",
    "    Args:\n",
    "    color: Color specification to validate\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if color is valid ColorLike, False otherwise\n",
    "    \"\"\"\n",
    "    # Check string colors\n",
    "    if isinstance(color, str):\n",
    "        return True  # We'll assume string validation is done by matplotlib\n",
    "    \n",
    "    # Check tuple colors\n",
    "    if isinstance(color, tuple):\n",
    "        if len(color) == 3:  # RGB\n",
    "print_count = 0  # Limit output\n",
    "    return all(isinstance(c, (int, float)) and 0 <= c <= 1 for c in color)\n",
    "    elif len(color) == 4:  # RGBA\n",
    "    return all(isinstance(c, (int, float)) and 0 <= c <= 1 for c in color)\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    # Check list colors\n",
    "    if isinstance(color, list):\n",
    "        if len(color) == 3:  # RGB\n",
    "        return all(isinstance(c, (int, float)) and 0 <= c <= 1 for c in color)\n",
    "        elif len(color) == 4:  # RGBA\n",
    "        return all(isinstance(c, (int, float)) and 0 <= c <= 1 for c in color)\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "def normalize_color(color):\n",
    "    \"\"\"\n",
    "    Normalize a ColorLike object to RGBA tuple.\n",
    "    \n",
    "    Args:\n",
    "    color: ColorLike object\n",
    "    \n",
    "    Returns:\n",
    "    tuple: RGBA tuple (r, g, b, a) or None if invalid\n",
    "    \"\"\"\n",
    "    if not is_valid_color(color):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Use matplotlib to convert color to RGBA\n",
    "        import matplotlib.colors as mcolors\n",
    "        \n",
    "        if isinstance(color, str):\n",
    "            try:\n",
    "                rgba = mcolors.to_rgba(color)\n",
    "                return rgba\n",
    "            except ValueError:\n",
    "                return None\n",
    "        elif isinstance(color, (tuple, list)):\n",
    "            if len(color) == 3:\n",
    "                return (*color, 1.0)  # Add alpha=1.0\n",
    "            elif len(color) == 4:\n",
    "                return tuple(color)\n",
    "        \n",
    "        return None\n",
    "    except ImportError:\n",
    "        # Fallback without matplotlib\n",
    "        if isinstance(color, (tuple, list)):\n",
    "            if len(color) == 3:\n",
    "                return (*color, 1.0)\n",
    "            elif len(color) == 4:\n",
    "                return tuple(color)\n",
    "        return None\n",
    "\n",
    "# Test color validation\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "color_validation_results = {}\n",
    "for name, color in color_examples.items():\n",
    "    is_valid = is_valid_color(color)\n",
    "    normalized = normalize_color(color)\n",
    "    color_validation_results[name] = {'valid': is_valid, 'normalized': normalized}\n",
    "    \n",
    "    status = \"\u2713 Valid\" if is_valid else \"\u2717 Invalid\"\n",
    "    color_repr = str(color)[:30] + \"...\" if len(str(color)) > 30 else str(color)\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    \n",
    "    if normalized:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "\n",
    "# Summary\n",
    "valid_colors = sum(1 for result in color_validation_results.values() if result['valid'])\n",
    "total_colors = len(color_validation_results)\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Color Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Demonstrate color processing and visualization\n",
    "def create_color_palette(base_colors, n_variations=5):\n",
    "    \"\"\"\n",
    "    Create color variations from base ColorLike objects.\n",
    "    \n",
    "    Args:\n",
    "    base_colors: List of ColorLike objects\n",
    "    n_variations: Number of variations per base color\n",
    "    \n",
    "    Returns:\n",
    "    dict: Dictionary of color variations\n",
    "    \"\"\"\n",
    "    palette = {}\n",
    "    \n",
    "print_count = 0  # Limit output\n",
    "    for i, color in enumerate(base_colors):\n",
    "        normalized = normalize_color(color)\n",
    "        if normalized is None:\n",
    "            continue\n",
    "        \n",
    "        r, g, b, a = normalized\n",
    "        variations = []\n",
    "        \n",
    "        # Create variations by adjusting brightness\n",
    "        for j in range(n_variations):\n",
    "            factor = 0.3 + (0.7 * j / (n_variations - 1))  # Range from 0.3 to 1.0\n",
    "            var_r = min(1.0, r * factor + 0.1 * (1 - factor))\n",
    "            var_g = min(1.0, g * factor + 0.1 * (1 - factor))\n",
    "            var_b = min(1.0, b * factor + 0.1 * (1 - factor))\n",
    "            variations.append((var_r, var_g, var_b, a))\n",
    "        \n",
    "        palette[f'color_{i+1}'] = {\n",
    "            'original': normalized,\n",
    "            'variations': variations,\n",
    "            'input': color\n",
    "        }\n",
    "    \n",
    "        gc.collect()  # Free memory\n",
    "    return palette\n",
    "\n",
    "# Create a color palette from valid colors\n",
    "valid_color_examples = [\n",
    "    'red', \n",
    "    (0.2, 0.6, 0.8), \n",
    "    [0.9, 0.3, 0.1], \n",
    "    '#FF5733'\n",
    "]\n",
    "\n",
    "color_palette = create_color_palette(valid_color_examples, n_variations=5)\n",
    "\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "for color_name, color_data in color_palette.items():\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "# Visualize the color palette\n",
    "fig, axes = plt.subplots(len(color_palette), 1, figsize=(10, 2 * len(color_palette)))\n",
    "if len(color_palette) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (color_name, color_data) in enumerate(color_palette.items()):\n",
    "    # Create a color bar showing variations\n",
    "    variations = color_data['variations']\n",
    "    colors_array = np.array(variations)[:, :3]  # Remove alpha for visualization\n",
    "    \n",
    "    # Create a horizontal color bar\n",
    "    axes[i].imshow(colors_array.reshape(1, -1, 3), aspect='auto', extent=[0, len(variations), 0, 1])\n",
    "    axes[i].set_title(f\"{color_name} - Input: {color_data['input']}\")\n",
    "    axes[i].set_xticks(np.arange(len(variations)) + 0.5)\n",
    "    axes[i].set_xticklabels([f'V{j+1}' for j in range(len(variations))])\n",
    "    axes[i].set_yticks([])\n",
    "    axes[i].set_xlabel('Variations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('output.png'); plt.close()\n",
    "plt.close()\n",
    "\n",
    "# Demonstrate color distance calculation\n",
    "def color_distance(color1, color2):\n",
    "    \"\"\"\n",
    "    Calculate Euclidean distance between two colors in RGB space.\n",
    "    \n",
    "    Args:\n",
    "    color1, color2: ColorLike objects\n",
    "    \n",
    "    Returns:\n",
    "    float: Distance between colors (0-\u221a3)\n",
    "    \"\"\"\n",
    "    rgba1 = normalize_color(color1)\n",
    "    rgba2 = normalize_color(color2)\n",
    "    \n",
    "    if rgba1 is None or rgba2 is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate Euclidean distance in RGB space\n",
    "    r_diff = rgba1[0] - rgba2[0]\n",
    "    g_diff = rgba1[1] - rgba2[1]\n",
    "    b_diff = rgba1[2] - rgba2[2]\n",
    "    \n",
    "    distance = np.sqrt(r_diff**2 + g_diff**2 + b_diff**2)\n",
    "    return distance\n",
    "\n",
    "# Test color distances\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "test_color_pairs = [\n",
    "    ('red', 'blue'),\n",
    "    ('red', '#FF0000'),  # Same color, different representation\n",
    "    ((1, 0, 0), (0.9, 0.1, 0.1)),  # Similar reds\n",
    "    ('black', 'white'),\n",
    "    ((0.5, 0.5, 0.5), '0.5')  # Same gray, different representation\n",
    "]\n",
    "\n",
    "for color1, color2 in test_color_pairs:\n",
    "    distance = color_distance(color1, color2)\n",
    "    if distance is not None:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    else:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: List Type Checking with is_listed_X\n",
    "\n",
    "### 3.1 Basic Type Checking for Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test lists with different types\n",
    "test_lists = {\n",
    "    'integers': [1, 2, 3, 4, 5],\n",
    "    'floats': [1.1, 2.2, 3.3, 4.4, 5.5],\n",
    "    'strings': ['a', 'b', 'c', 'd', 'e'],\n",
    "    'mixed_numbers': [1, 2.5, 3, 4.0, 5],\n",
    "    'mixed_types': [1, 'two', 3.0, [4], {'five': 5}],\n",
    "    'booleans': [True, False, True, True, False],\n",
    "    'nested_lists': [[1, 2], [3, 4], [5, 6]],\n",
    "    'empty_list': [],\n",
    "    'single_element': [42],\n",
    "    'none_values': [None, None, None],\n",
    "    'numpy_arrays': [np.array([1, 2]), np.array([3, 4])],\n",
    "    'pandas_objects': [pd.Series([1, 2]), pd.DataFrame({'a': [1]})]\n",
    "}\n",
    "\n",
    "# Also test non-list objects\n",
    "non_list_objects = {\n",
    "    'tuple': (1, 2, 3),\n",
    "    'string': \"hello\",\n",
    "    'integer': 42,\n",
    "    'numpy_array': np.array([1, 2, 3]),\n",
    "    'dict': {'a': 1, 'b': 2}\n",
    "}\n",
    "\n",
    "# Test different type specifications\n",
    "type_tests = [\n",
    "    (int, \"integers only\"),\n",
    "    (float, \"floats only\"),\n",
    "    (str, \"strings only\"),\n",
    "    ((int, float), \"numbers (int or float)\"),\n",
    "    ([int, float], \"numbers (list of types)\"),\n",
    "    (bool, \"booleans only\"),\n",
    "    (list, \"lists only\"),\n",
    "    (type(None), \"None values only\"),\n",
    "    (np.ndarray, \"numpy arrays only\")\n",
    "]\n",
    "\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "# Test all combinations\n",
    "print_count = 0  # Limit output\n",
    "for type_spec, type_desc in type_tests:\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    \n",
    "    # Test with list objects\n",
    "    for name, test_list in test_lists.items():\n",
    "        result = scitex.types.is_listed_X(test_list, type_spec)\n",
    "        alternative_result = scitex.types.is_list_of_type(test_list, type_spec)\n",
    "        \n",
    "        # Verify both functions give same result\n",
    "        assert result == alternative_result, f\"Functions disagree for {name}\"\n",
    "        \n",
    "        status = \"\u2713\" if result else \"\u2717\"\n",
    "        preview = str(test_list)[:30] + \"...\" if len(str(test_list)) > 30 else str(test_list)\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    \n",
    "    # Test with non-list objects (should all be False)\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    for name, obj in non_list_objects.items():\n",
    "        result = scitex.types.is_listed_X(obj, type_spec)\n",
    "        status = \"\u2713\" if result else \"\u2717\"\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Advanced List Validation for Scientific Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scientific data validation functions\n",
    "def validate_numeric_list(data, allow_nan=False, min_length=1, max_length=None):\n",
    "    \"\"\"\n",
    "    Validate a list contains only numeric data with optional constraints.\n",
    "    \n",
    "    Args:\n",
    "    data: List to validate\n",
    "    allow_nan: Whether to allow NaN values\n",
    "    min_length: Minimum required length\n",
    "print_count = 0  # Limit output\n",
    "    max_length: Maximum allowed length (None for no limit)\n",
    "    \n",
    "    Returns:\n",
    "    dict: Validation results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "    'is_list': isinstance(data, list),\n",
    "    'length': len(data) if isinstance(data, list) else 0,\n",
    "    'is_numeric': False,\n",
    "    'has_nan': False,\n",
    "    'length_valid': False,\n",
    "    'overall_valid': False,\n",
    "    'errors': []\n",
    "    }\n",
    "    \n",
    "    if not results['is_list']:\n",
    "        results['errors'].append(\"Input is not a list\")\n",
    "        return results\n",
    "    \n",
    "    # Check if all elements are numeric\n",
    "    results['is_numeric'] = scitex.types.is_list_of_type(data, (int, float))\n",
    "    \n",
    "    if not results['is_numeric']:\n",
    "        results['errors'].append(\"List contains non-numeric elements\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    if results['is_numeric']:\n",
    "        results['has_nan'] = any(np.isnan(x) for x in data if isinstance(x, float))\n",
    "        if results['has_nan'] and not allow_nan:\n",
    "            results['errors'].append(\"List contains NaN values\")\n",
    "    \n",
    "    # Check length constraints\n",
    "    if results['length'] < min_length:\n",
    "        results['errors'].append(f\"List too short (minimum: {min_length})\")\n",
    "    elif max_length is not None and results['length'] > max_length:\n",
    "        results['errors'].append(f\"List too long (maximum: {max_length})\")\n",
    "    else:\n",
    "        results['length_valid'] = True\n",
    "    \n",
    "    # Overall validation\n",
    "    results['overall_valid'] = (\n",
    "        results['is_list'] and \n",
    "        results['is_numeric'] and \n",
    "        results['length_valid'] and\n",
    "        (allow_nan or not results['has_nan'])\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "def validate_coordinate_list(data):\n",
    "    \"\"\"\n",
    "    Validate a list of coordinate tuples/lists.\n",
    "    \n",
    "    Args:\n",
    "    data: List of coordinates [(x1, y1), (x2, y2), ...]\n",
    "    \n",
    "    Returns:\n",
    "    dict: Validation results\n",
    "    \"\"\"\n",
    "    results = {\n",
    "    'is_list': isinstance(data, list),\n",
    "    'all_coordinates': False,\n",
    "    'consistent_dimensions': False,\n",
    "    'dimensions': None,\n",
    "    'count': len(data) if isinstance(data, list) else 0,\n",
    "    'overall_valid': False,\n",
    "    'errors': []\n",
    "    }\n",
    "    \n",
    "    if not results['is_list']:\n",
    "        results['errors'].append(\"Input is not a list\")\n",
    "        return results\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        results['errors'].append(\"List is empty\")\n",
    "        return results\n",
    "    \n",
    "    # Check if all elements are coordinate-like (tuples or lists)\n",
    "    results['all_coordinates'] = scitex.types.is_list_of_type(data, (tuple, list))\n",
    "    \n",
    "    if not results['all_coordinates']:\n",
    "        results['errors'].append(\"Not all elements are coordinate-like (tuple/list)\")\n",
    "        return results\n",
    "    \n",
    "    # Check dimension consistency\n",
    "    first_dim = len(data[0]) if len(data) > 0 else 0\n",
    "    results['dimensions'] = first_dim\n",
    "    \n",
    "    for i, coord in enumerate(data):\n",
    "        if len(coord) != first_dim:\n",
    "            results['errors'].append(f\"Inconsistent dimensions at index {i}\")\n",
    "            return results\n",
    "        \n",
    "        # Check if all coordinate components are numeric\n",
    "        if not all(isinstance(c, (int, float)) for c in coord):\n",
    "            results['errors'].append(f\"Non-numeric coordinate at index {i}\")\n",
    "            return results\n",
    "    \n",
    "    results['consistent_dimensions'] = True\n",
    "    results['overall_valid'] = True\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test scientific data validation\n",
    "scientific_test_data = {\n",
    "    'valid_measurements': [1.2, 3.4, 5.6, 7.8, 9.0],\n",
    "    'with_nan': [1.2, 3.4, float('nan'), 7.8, 9.0],\n",
    "    'mixed_numbers': [1, 2.5, 3, 4.0, 5],\n",
    "    'with_strings': [1.2, '3.4', 5.6, 7.8, 9.0],\n",
    "    'too_short': [1.2],\n",
    "    'empty': [],\n",
    "    'coordinates_2d': [(0, 1), (2, 3), (4, 5)],\n",
    "    'coordinates_3d': [(0, 1, 2), (3, 4, 5), (6, 7, 8)],\n",
    "    'mixed_dimensions': [(0, 1), (2, 3, 4), (5, 6)],\n",
    "    'invalid_coordinates': [(0, 1), 'not_coord', (4, 5)],\n",
    "    'non_numeric_coords': [('a', 'b'), ('c', 'd')]\n",
    "}\n",
    "\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "# Test numeric validation\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "numeric_tests = [\n",
    "    'valid_measurements', 'with_nan', 'mixed_numbers', \n",
    "    'with_strings', 'too_short', 'empty'\n",
    "]\n",
    "\n",
    "for test_name in numeric_tests:\n",
    "    data = scientific_test_data[test_name]\n",
    "    \n",
    "    # Test with different constraints\n",
    "    result_strict = validate_numeric_list(data, allow_nan=False, min_length=3)\n",
    "    result_lenient = validate_numeric_list(data, allow_nan=True, min_length=1)\n",
    "    \n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if result_strict['errors']:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if result_lenient['errors']:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "\n",
    "# Test coordinate validation\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "coordinate_tests = [\n",
    "    'coordinates_2d', 'coordinates_3d', 'mixed_dimensions',\n",
    "    'invalid_coordinates', 'non_numeric_coords'\n",
    "]\n",
    "\n",
    "for test_name in coordinate_tests:\n",
    "    data = scientific_test_data[test_name]\n",
    "    result = validate_coordinate_list(data)\n",
    "    \n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if result['overall_valid']:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if result['errors']:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Practical Applications and Integration\n",
    "\n",
    "### 4.1 Type-Safe Scientific Function Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Design type-safe scientific functions using SciTeX types\n",
    "def safe_statistical_analysis(data, method='mean', confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis with comprehensive type checking.\n",
    "    \n",
    "    Args:\n",
    "print_count = 0  # Limit output\n",
    "    data: ArrayLike - Numeric data for analysis\n",
    "    method: str - Statistical method ('mean', 'median', 'std', 'var')\n",
    "    confidence_level: float - Confidence level for intervals\n",
    "    \n",
    "    Returns:\n",
    "    dict: Analysis results or error information\n",
    "    \"\"\"\n",
    "    result = {\n",
    "    'success': False,\n",
    "    'method': method,\n",
    "    'data_info': {},\n",
    "    'statistics': {},\n",
    "    'errors': []\n",
    "    }\n",
    "    \n",
    "    # Type checking\n",
    "    if not scitex.types.is_array_like(data):\n",
    "        result['errors'].append(f\"Data is not array-like (type: {type(data).__name__})\")\n",
    "        return result\n",
    "    \n",
    "    # Convert to numpy for analysis\n",
    "    try:\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            numeric_data = data.select_dtypes(include=[np.number])\n",
    "            if numeric_data.empty:\n",
    "                result['errors'].append(\"DataFrame contains no numeric columns\")\n",
    "                return result\n",
    "            np_data = numeric_data.values.flatten()\n",
    "        elif isinstance(data, pd.Series):\n",
    "            if not pd.api.types.is_numeric_dtype(data):\n",
    "                result['errors'].append(\"Series is not numeric\")\n",
    "                return result\n",
    "            np_data = data.values\n",
    "        else:\n",
    "            np_data = np.array(data, dtype=float)\n",
    "    except (ValueError, TypeError) as e:\n",
    "        result['errors'].append(f\"Cannot convert data to numeric array: {e}\")\n",
    "        return result\n",
    "    \n",
    "    # Remove NaN values and validate\n",
    "    clean_data = np_data[~np.isnan(np_data)]\n",
    "    \n",
    "    if len(clean_data) == 0:\n",
    "        result['errors'].append(\"No valid numeric data after removing NaN values\")\n",
    "        return result\n",
    "    \n",
    "    # Store data info\n",
    "    result['data_info'] = {\n",
    "        'original_size': len(np_data),\n",
    "        'valid_size': len(clean_data),\n",
    "        'nan_count': len(np_data) - len(clean_data),\n",
    "        'data_type': type(data).__name__\n",
    "    }\n",
    "    \n",
    "    # Perform statistical analysis\n",
    "    try:\n",
    "        if method == 'mean':\n",
    "            stat_value = np.mean(clean_data)\n",
    "            # Calculate confidence interval for mean\n",
    "            sem = np.std(clean_data, ddof=1) / np.sqrt(len(clean_data))\n",
    "            from scipy.stats import t\n",
    "            t_val = t.ppf((1 + confidence_level) / 2, len(clean_data) - 1)\n",
    "            margin = t_val * sem\n",
    "            ci_lower = stat_value - margin\n",
    "            ci_upper = stat_value + margin\n",
    "            \n",
    "        elif method == 'median':\n",
    "            stat_value = np.median(clean_data)\n",
    "            # Simple confidence interval for median (bootstrap approximation)\n",
    "            n = len(clean_data)\n",
    "            sorted_data = np.sort(clean_data)\n",
    "            z_val = 1.96  # For 95% confidence\n",
    "            margin = z_val * np.sqrt(n) / 2\n",
    "            lower_idx = max(0, int(n/2 - margin))\n",
    "            upper_idx = min(n-1, int(n/2 + margin))\n",
    "            ci_lower = sorted_data[lower_idx]\n",
    "            ci_upper = sorted_data[upper_idx]\n",
    "            \n",
    "        elif method == 'std':\n",
    "            stat_value = np.std(clean_data, ddof=1)\n",
    "            # Chi-square confidence interval for standard deviation\n",
    "            from scipy.stats import chi2\n",
    "            n = len(clean_data)\n",
    "            chi2_lower = chi2.ppf((1 - confidence_level) / 2, n - 1)\n",
    "            chi2_upper = chi2.ppf((1 + confidence_level) / 2, n - 1)\n",
    "            ci_lower = np.sqrt((n - 1) * stat_value**2 / chi2_upper)\n",
    "            ci_upper = np.sqrt((n - 1) * stat_value**2 / chi2_lower)\n",
    "            \n",
    "        elif method == 'var':\n",
    "            stat_value = np.var(clean_data, ddof=1)\n",
    "            # Chi-square confidence interval for variance\n",
    "            from scipy.stats import chi2\n",
    "            n = len(clean_data)\n",
    "            chi2_lower = chi2.ppf((1 - confidence_level) / 2, n - 1)\n",
    "            chi2_upper = chi2.ppf((1 + confidence_level) / 2, n - 1)\n",
    "            ci_lower = (n - 1) * stat_value / chi2_upper\n",
    "            ci_upper = (n - 1) * stat_value / chi2_lower\n",
    "            \n",
    "        else:\n",
    "            result['errors'].append(f\"Unknown method: {method}\")\n",
    "            return result\n",
    "        \n",
    "        result['statistics'] = {\n",
    "            'value': stat_value,\n",
    "            'confidence_interval': (ci_lower, ci_upper),\n",
    "            'confidence_level': confidence_level\n",
    "        }\n",
    "        result['success'] = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        result['errors'].append(f\"Statistical calculation failed: {e}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def safe_plotting_function(x_data, y_data, colors=None, markers=None, title=\"Plot\"):\n",
    "    \"\"\"\n",
    "    Create a plot with comprehensive type checking.\n",
    "    \n",
    "    Args:\n",
    "    x_data: ArrayLike - X coordinates\n",
    "    y_data: ArrayLike - Y coordinates\n",
    "    colors: List of ColorLike objects or single ColorLike\n",
    "    markers: List of strings or single string\n",
    "    title: str - Plot title\n",
    "    \n",
    "    Returns:\n",
    "    dict: Plot creation results\n",
    "    \"\"\"\n",
    "    result = {\n",
    "    'success': False,\n",
    "    'errors': [],\n",
    "    'warnings': [],\n",
    "    'plot_info': {}\n",
    "    }\n",
    "    \n",
    "    # Type checking for coordinates\n",
    "    if not scitex.types.is_array_like(x_data):\n",
    "        result['errors'].append(\"x_data is not array-like\")\n",
    "        return result\n",
    "    \n",
    "    if not scitex.types.is_array_like(y_data):\n",
    "        result['errors'].append(\"y_data is not array-like\")\n",
    "        return result\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    try:\n",
    "        x_array = np.array(x_data, dtype=float)\n",
    "        y_array = np.array(y_data, dtype=float)\n",
    "    except (ValueError, TypeError) as e:\n",
    "        result['errors'].append(f\"Cannot convert coordinates to numeric arrays: {e}\")\n",
    "        return result\n",
    "    \n",
    "    # Check dimensions match\n",
    "    if len(x_array) != len(y_array):\n",
    "        result['errors'].append(f\"Coordinate arrays have different lengths: {len(x_array)} vs {len(y_array)}\")\n",
    "        return result\n",
    "    \n",
    "    # Validate colors if provided\n",
    "    processed_colors = None\n",
    "    if colors is not None:\n",
    "        if isinstance(colors, (list, tuple)):\n",
    "            # Check if it's a list of colors\n",
    "            if scitex.types.is_list_of_type(colors, str):\n",
    "                processed_colors = colors\n",
    "            else:\n",
    "                # Check if each element is a valid color\n",
    "                valid_colors = []\n",
    "                for i, color in enumerate(colors):\n",
    "                    normalized = normalize_color(color)\n",
    "                    if normalized:\n",
    "                        valid_colors.append(normalized)\n",
    "                    else:\n",
    "                        result['warnings'].append(f\"Invalid color at index {i}: {color}\")\n",
    "                processed_colors = valid_colors if valid_colors else None\n",
    "        else:\n",
    "            # Single color\n",
    "            normalized = normalize_color(colors)\n",
    "            if normalized:\n",
    "                processed_colors = [normalized]\n",
    "            else:\n",
    "                result['warnings'].append(f\"Invalid color: {colors}\")\n",
    "    \n",
    "    # Validate markers if provided\n",
    "    processed_markers = None\n",
    "    if markers is not None:\n",
    "        if isinstance(markers, str):\n",
    "            processed_markers = [markers]\n",
    "        elif scitex.types.is_list_of_type(markers, str):\n",
    "            processed_markers = markers\n",
    "        else:\n",
    "            result['warnings'].append(\"Invalid markers - must be string or list of strings\")\n",
    "    \n",
    "    # Create the plot\n",
    "    try:\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        \n",
    "        # Plot data\n",
    "        n_points = len(x_array)\n",
    "        \n",
    "        if processed_colors and processed_markers:\n",
    "            # Use both colors and markers\n",
    "            for i in range(n_points):\n",
    "                color_idx = i % len(processed_colors)\n",
    "                marker_idx = i % len(processed_markers)\n",
    "                ax.scatter(x_array[i], y_array[i], \n",
    "                c=[processed_colors[color_idx]],\n",
    "                marker=processed_markers[marker_idx],\n",
    "                s=50)\n",
    "            gc.collect()  # Free memory\n",
    "        elif processed_colors:\n",
    "            # Use colors only\n",
    "            for i in range(n_points):\n",
    "                color_idx = i % len(processed_colors)\n",
    "                ax.scatter(x_array[i], y_array[i], \n",
    "                c=[processed_colors[color_idx]], s=50)\n",
    "            gc.collect()  # Free memory\n",
    "        elif processed_markers:\n",
    "            # Use markers only\n",
    "            for i in range(n_points):\n",
    "                marker_idx = i % len(processed_markers)\n",
    "                ax.scatter(x_array[i], y_array[i], \n",
    "                marker=processed_markers[marker_idx], s=50)\n",
    "            gc.collect()  # Free memory\n",
    "        else:\n",
    "            # Default plotting\n",
    "            ax.scatter(x_array, y_array, s=50)\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('output.png'); plt.close()\n",
    "plt.close()\n",
    "        \n",
    "    result['success'] = True\n",
    "    result['plot_info'] = {\n",
    "    'n_points': n_points,\n",
    "    'x_range': (np.min(x_array), np.max(x_array)),\n",
    "    'y_range': (np.min(y_array), np.max(y_array)),\n",
    "    'colors_used': len(processed_colors) if processed_colors else 0,\n",
    "    'markers_used': len(processed_markers) if processed_markers else 0\n",
    "    }\n",
    "        \n",
    "    except Exception as e:\n",
    "        result['errors'].append(f\"Plot creation failed: {e}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test the type-safe functions\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "# Test statistical analysis\n",
    "test_datasets = {\n",
    "    'valid_list': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'numpy_array': np.random.normal(10, 2, 50),\n",
    "    'pandas_series': pd.Series(np.random.exponential(2, 30)),\n",
    "    'with_nan': [1, 2, float('nan'), 4, 5, 6, 7, 8, 9, 10],\n",
    "    'invalid_data': 'not_array_like'\n",
    "}\n",
    "\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "for name, data in test_datasets.items():\n",
    "    result = safe_statistical_analysis(data, method='mean')\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    \n",
    "    if result['success']:\n",
    "        stats = result['statistics']\n",
    "        data_info = result['data_info']\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    \n",
    "    if result['errors']:\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "\n",
    "# Test plotting function\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "# Generate test data\n",
    "x_test = np.linspace(0, 10, 20)\n",
    "y_test = np.sin(x_test) + np.random.normal(0, 0.1, 20)\n",
    "\n",
    "test_colors = ['red', (0.2, 0.6, 0.8), '#FF5733']\n",
    "test_markers = ['o', 's', '^']\n",
    "\n",
    "plot_result = safe_plotting_function(\n",
    "    x_test, y_test, \n",
    "    colors=test_colors, \n",
    "    markers=test_markers,\n",
    "    title=\"Type-Safe Plotting Demo\"\n",
    ")\n",
    "\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if plot_result['success']:\n",
    "    info = plot_result['plot_info']\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "\n",
    "if plot_result['errors']:\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if plot_result['warnings']:\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Performance Comparison and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Performance comparison of type checking approaches\n",
    "import time\n",
    "from typing import get_type_hints\n",
    "\n",
    "def benchmark_type_checking():\n",
    "    \"\"\"\n",
    "    Compare performance of different type checking approaches.\n",
    "    \"\"\"\n",
    "    # Create test data\n",
    "    test_data = {\n",
    "    'small_list': list(range(100)),\n",
    "    'large_list': list(range(10000)),\n",
    "    'numpy_array': np.random.randn(100),\n",
    "    'pandas_series': pd.Series(range(10000)),\n",
    "print_count = 0  # Limit output\n",
    "    'nested_list': [[i, i+1] for i in range(1000)]\n",
    "    }\n",
    "    \n",
    "    # Type checking functions to compare\n",
    "    def scitex_is_array_like(obj):\n",
    "        return scitex.types.is_array_like(obj)\n",
    "    \n",
    "    def scitex_is_list_of_type(obj):\n",
    "        return scitex.types.is_list_of_type(obj, int) if isinstance(obj, list) else False\n",
    "    \n",
    "    def manual_type_check(obj):\n",
    "        return isinstance(obj, (list, tuple, np.ndarray, pd.Series, pd.DataFrame))\n",
    "    \n",
    "    def hasattr_check(obj):\n",
    "        return hasattr(obj, '__iter__') and hasattr(obj, '__len__')\n",
    "    \n",
    "    # Benchmark functions\n",
    "    functions_to_test = [\n",
    "        ('SciTeX is_array_like', scitex_is_array_like),\n",
    "        ('Manual isinstance', manual_type_check),\n",
    "        ('hasattr check', hasattr_check)\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    n_iterations = 1000\n",
    "    \n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    \n",
    "    for data_name, data in test_data.items():\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        \n",
    "        data_results = {}\n",
    "        \n",
    "        for func_name, func in functions_to_test:\n",
    "            # Warm up\n",
    "            for _ in range(10):\n",
    "                func(data)\n",
    "            \n",
    "            # Benchmark\n",
    "            start_time = time.time()\n",
    "            for _ in range(n_iterations):\n",
    "                result = func(data)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            total_time = end_time - start_time\n",
    "            avg_time = total_time / n_iterations * 1000000  # microseconds\n",
    "            \n",
    "            data_results[func_name] = {\n",
    "                'total_time': total_time,\n",
    "                'avg_time_us': avg_time,\n",
    "                'result': result\n",
    "            }\n",
    "            \n",
    "            if print_count < 5:  # Limit output\n",
    "                print_count += 1\n",
    "        \n",
    "            gc.collect()  # Free memory\n",
    "        results[data_name] = data_results\n",
    "    \n",
    "    # Test list type checking performance\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    \n",
    "    list_test_data = {\n",
    "        'small_int_list': list(range(10)),\n",
    "        'large_int_list': list(range(1000)),\n",
    "        'mixed_list': [1, 'two', 3.0, [4]],\n",
    "        'string_list': ['a', 'b', 'c', 'd', 'e'] * 100\n",
    "    }\n",
    "    \n",
    "    for data_name, data in list_test_data.items():\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        \n",
    "        # SciTeX approach\n",
    "        start_time = time.time()\n",
    "        for _ in range(n_iterations):\n",
    "            result_scitex = scitex.types.is_list_of_type(data, int)\n",
    "        scitex_time = (time.time() - start_time) / n_iterations * 1000000\n",
    "        \n",
    "        # Manual approach\n",
    "        start_time = time.time()\n",
    "        for _ in range(n_iterations):\n",
    "            result_manual = isinstance(data, list) and all(isinstance(x, int) for x in data)\n",
    "        manual_time = (time.time() - start_time) / n_iterations * 1000000\n",
    "        \n",
    "        if print_count < 5:  # Limit output\n",
    "            print_count += 1\n",
    "        if print_count < 5:  # Limit output\n",
    "            print_count += 1\n",
    "        if print_count < 5:  # Limit output\n",
    "            print_count += 1\n",
    "    \n",
    "        gc.collect()  # Free memory\n",
    "    return results\n",
    "\n",
    "def demonstrate_best_practices():\n",
    "    \"\"\"\n",
    "    Demonstrate best practices for using SciTeX type utilities.\n",
    "    \"\"\"\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    \n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "    \n",
    "    def robust_function(data, colors=None):\n",
    "        \"\"\"Example of robust input validation.\"\"\"\n",
    "        errors = []\n",
    "        \n",
    "        # Check main data\n",
    "        if not scitex.types.is_array_like(data):\n",
    "            errors.append(\"Data must be array-like\")\n",
    "            return {'success': False, 'errors': errors}\n",
    "        \n",
    "        # Check optional parameters\n",
    "        if colors is not None:\n",
    "            if isinstance(colors, list):\n",
    "                if not all(normalize_color(c) for c in colors):\n",
    "                    errors.append(\"Some colors are invalid\")\n",
    "            else:\n",
    "                if not normalize_color(colors):\n",
    "                    errors.append(\"Color is invalid\")\n",
    "        \n",
    "        if errors:\n",
    "            return {'success': False, 'errors': errors}\n",
    "        \n",
    "        return {'success': True, 'message': 'All inputs valid'}\n",
    "    \n",
    "    # Test the pattern\n",
    "    test_cases = [\n",
    "        ([1, 2, 3], 'red'),\n",
    "        ('not_array', 'blue'),\n",
    "        ([1, 2, 3], 'invalid_color'),\n",
    "        (np.array([1, 2, 3]), ['red', 'blue', 'green'])\n",
    "    ]\n",
    "    \n",
    "    for data, colors in test_cases:\n",
    "        result = robust_function(data, colors)\n",
    "        status = \"\u2713\" if result['success'] else \"\u2717\"\n",
    "        if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "        if not result['success']:\n",
    "            if print_count < 5:  # Limit output\n",
    "            print_count += 1\n",
    "    \n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    \n",
    "    def flexible_array_function(data):\n",
    "        \"\"\"Example of flexible array handling.\"\"\"\n",
    "        if not scitex.types.is_array_like(data):\n",
    "            return None\n",
    "        \n",
    "        # Convert to numpy for processing\n",
    "        try:\n",
    "            if isinstance(data, pd.DataFrame):\n",
    "                # Handle DataFrames specially\n",
    "                numeric_cols = data.select_dtypes(include=[np.number])\n",
    "                if not numeric_cols.empty:\n",
    "                    array_data = numeric_cols.values\n",
    "                else:\n",
    "                    return None\n",
    "            else:\n",
    "                array_data = np.asarray(data)\n",
    "            \n",
    "            # Process the array\n",
    "            result = np.sum(array_data)\n",
    "            return result\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    # Test flexible handling\n",
    "    flexible_test_data = [\n",
    "        [1, 2, 3, 4, 5],\n",
    "        np.array([1, 2, 3, 4, 5]),\n",
    "        pd.Series([1, 2, 3, 4, 5]),\n",
    "        pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]}),\n",
    "        \"not_array\"\n",
    "    ]\n",
    "    \n",
    "    for data in flexible_test_data:\n",
    "        result = flexible_array_function(data)\n",
    "        data_str = str(data)[:30] + \"...\" if len(str(data)) > 30 else str(data)\n",
    "        if result is not None:\n",
    "            if print_count < 5:  # Limit output\n",
    "            print_count += 1\n",
    "        else:\n",
    "            if print_count < 5:  # Limit output\n",
    "            print_count += 1\n",
    "    \n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "    if print_count < 5:  # Limit output\n",
    "        print_count += 1\n",
    "\n",
    "# Run benchmarks and demonstrations\n",
    "benchmark_results = benchmark_type_checking()\n",
    "demonstrate_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Best Practices\n",
    "\n",
    "This tutorial demonstrated the comprehensive type handling capabilities of the SciTeX types module:\n",
    "\n",
    "### Key Components Covered:\n",
    "\n",
    "1. **ArrayLike Type Union**:\n",
    "   - Supports lists, tuples, NumPy arrays, Pandas Series/DataFrames, PyTorch tensors, XArray DataArrays\n",
    "   - Enables cross-library compatibility\n",
    "   - Provides flexible input handling for scientific functions\n",
    "\n",
    "2. **ColorLike Type Union**:\n",
    "   - Supports string colors, RGB/RGBA tuples, RGB/RGBA lists\n",
    "   - Enables flexible color specification for plotting\n",
    "   - Integrates with matplotlib color systems\n",
    "\n",
    "3. **List Type Checking Functions**:\n",
    "   - `is_listed_X` and `is_list_of_type` for validating list contents\n",
    "   - Support for multiple type specifications\n",
    "   - Robust error handling for edge cases\n",
    "\n",
    "4. **Type Validation Functions**:\n",
    "   - `is_array_like` for checking array-like objects\n",
    "   - Consistent behavior across different data types\n",
    "   - Integration with scientific computing workflows\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "#### Input Validation:\n",
    "- **Always validate inputs early** in function execution\n",
    "- **Provide clear error messages** that help users understand type requirements\n",
    "- **Use SciTeX type checking** for cross-library compatibility\n",
    "- **Handle edge cases** like empty arrays, NaN values, and mixed types\n",
    "\n",
    "#### Performance Considerations:\n",
    "- **Cache type checking results** when performing repeated operations\n",
    "- **Use isinstance()** for simple, known types when performance is critical\n",
    "- **Leverage SciTeX types** for flexible, user-friendly APIs\n",
    "- **Convert to NumPy arrays** early for consistent numerical operations\n",
    "\n",
    "#### Design Patterns:\n",
    "- **Graceful degradation**: Handle type mismatches without crashing\n",
    "- **Flexible input handling**: Accept multiple array-like types\n",
    "- **Consistent output formats**: Return standardized result structures\n",
    "- **Comprehensive validation**: Check all aspects of input data\n",
    "\n",
    "#### Scientific Applications:\n",
    "- **Data pipeline validation**: Ensure data integrity through processing steps\n",
    "- **Plotting functions**: Accept flexible color and marker specifications\n",
    "- **Statistical analysis**: Validate numeric data before computation\n",
    "- **Machine learning**: Type-check features, labels, and model parameters\n",
    "\n",
    "### When to Use SciTeX Types:\n",
    "\n",
    "- **Multi-library environments** where users may provide different array types\n",
    "- **User-facing APIs** that need to be flexible and forgiving\n",
    "- **Scientific computing** where data comes in various formats\n",
    "- **Plotting and visualization** where color/marker specifications vary\n",
    "- **Data validation** in research pipelines\n",
    "\n",
    "The SciTeX types module provides essential tools for building robust, flexible scientific computing applications that work seamlessly across the Python data science ecosystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "print_count = 0  # Limit output\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1\n",
    "if print_count < 5:  # Limit output\n",
    "    print_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Gen (General Utilities) Tutorial\n",
    "\n",
    "This notebook demonstrates the scitex.gen module for general utilities, project lifecycle management, and development tools. The gen module provides essential functions for experiment setup, reproducibility, data processing, and various utility functions.\n",
    "\n",
    "## Key Features Covered:\n",
    "- Experiment lifecycle management (start/close)\n",
    "- Reproducibility and configuration management\n",
    "- Data normalization and transformation utilities\n",
    "- Text and data processing tools\n",
    "- System and environment utilities\n",
    "- Caching and performance optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path('.').parent / \"src\"))\n",
    "\n",
    "import scitex\n",
    "import scitex.gen as gen\n",
    "\n",
    "print(\"SciTeX Gen Tutorial - General Utilities & Project Management\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment Lifecycle Management\n",
    "\n",
    "The gen module provides `start()` and `close()` functions for managing experimental workflows with reproducibility, logging, and configuration management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate basic start functionality (simplified for notebook)\n",
    "print(\"=== Experiment Setup Demo ===\")\n",
    "\n",
    "# In a real script, you would use:\n",
    "# CONFIG, sys.stdout, sys.stderr, plt, CC = gen.start(sys, plt)\n",
    "\n",
    "# For notebook demo, we'll simulate the setup\n",
    "try:\n",
    "    # Generate unique experiment ID\n",
    "    experiment_id = gen.gen_ID(N=4)\n",
    "    print(f\"‚úÖ Generated experiment ID: {experiment_id}\")\n",
    "except:\n",
    "    from scitex.repro._gen_ID import gen_ID\n",
    "    experiment_id = gen_ID(N=4)\n",
    "    print(f\"‚úÖ Generated experiment ID: {experiment_id}\")\n",
    "\n",
    "# Demonstrate configuration loading\n",
    "try:\n",
    "    from scitex.io._load_configs import load_configs\n",
    "    configs = load_configs(verbose=False)\n",
    "    print(f\"‚úÖ Loaded configurations: {type(configs)}\")\n",
    "    print(f\"   Available config keys: {list(configs.keys())[:5]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Config loading: {e}\")\n",
    "    configs = {'demo': True, 'seed': 42}\n",
    "\n",
    "# Demonstrate seed fixing for reproducibility\n",
    "try:\n",
    "    from scitex.repro._fix_seeds import fix_seeds\n",
    "    fix_seeds(seed=42, verbose=True)\n",
    "    print(\"‚úÖ Random seeds fixed for reproducibility\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Seed fixing: {e}\")\n",
    "    np.random.seed(42)\n",
    "    print(\"‚úÖ NumPy seed fixed as fallback\")\n",
    "\n",
    "print(f\"\\nExperiment started at: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Normalization and Transformation\n",
    "\n",
    "The gen module provides various normalization and transformation functions for data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data for normalization demos\n",
    "np.random.seed(42)\n",
    "data = np.random.randn(100) * 10 + 5  # Mean=5, std=10\n",
    "data_with_outliers = np.concatenate([data, [50, -30, 45]])  # Add outliers\n",
    "\n",
    "print(\"=== Data Normalization Utilities ===\")\n",
    "print(f\"Original data: mean={data.mean():.2f}, std={data.std():.2f}\")\n",
    "print(f\"Data range: [{data.min():.2f}, {data.max():.2f}]\")\n",
    "\n",
    "# Test normalization functions\n",
    "norm_functions = [\n",
    "    ('to_01', 'Normalize to [0, 1] range'),\n",
    "    ('to_z', 'Z-score normalization'),\n",
    "    ('unbias', 'Remove bias (center around 0)'),\n",
    "    ('clip_perc', 'Clip outliers by percentile')\n",
    "]\n",
    "\n",
    "normalized_data = {}\n",
    "\n",
    "for func_name, description in norm_functions:\n",
    "    try:\n",
    "        func = getattr(gen, func_name)\n",
    "        \n",
    "        if func_name == 'clip_perc':\n",
    "            # clip_perc requires percentile arguments\n",
    "            result = func(data_with_outliers, 5, 95)  # Clip 5th and 95th percentiles\n",
    "        else:\n",
    "            result = func(data)\n",
    "            \n",
    "        normalized_data[func_name] = result\n",
    "        print(f\"‚úÖ {func_name}: {description}\")\n",
    "        print(f\"   Result: mean={result.mean():.3f}, std={result.std():.3f}, range=[{result.min():.3f}, {result.max():.3f}]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è {func_name} failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize normalization results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Original data\n",
    "axes[0].hist(data, bins=20, alpha=0.7, color='blue')\n",
    "axes[0].set_title('Original Data')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Normalized data\n",
    "colors = ['red', 'green', 'orange', 'purple']\n",
    "for i, (name, norm_data) in enumerate(normalized_data.items(), 1):\n",
    "    if i < len(axes):\n",
    "        axes[i].hist(norm_data, bins=20, alpha=0.7, color=colors[i-1])\n",
    "        axes[i].set_title(f'{name.replace(\"_\", \" \").title()}')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Hide unused subplot\n",
    "if len(normalized_data) < 5:\n",
    "    axes[-1].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Data Normalization Comparison', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Array and Data Utilities\n",
    "\n",
    "Various utilities for array manipulation and data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Array and Data Utilities ===\")\n",
    "\n",
    "# Test array manipulation functions\n",
    "test_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "test_numbers = [1, 3, 5, 7, 9, 11]\n",
    "\n",
    "array_functions = [\n",
    "    ('transpose', 'Matrix transpose'),\n",
    "    ('to_even', 'Convert numbers to even'),\n",
    "    ('to_odd', 'Convert numbers to odd'),\n",
    "    ('to_rank', 'Convert to ranks')\n",
    "]\n",
    "\n",
    "for func_name, description in array_functions:\n",
    "    try:\n",
    "        func = getattr(gen, func_name)\n",
    "        \n",
    "        if func_name == 'transpose':\n",
    "            result = func(test_array)\n",
    "            print(f\"‚úÖ {func_name}: {description}\")\n",
    "            print(f\"   Original shape: {test_array.shape} -> Result shape: {result.shape}\")\n",
    "            \n",
    "        elif func_name in ['to_even', 'to_odd']:\n",
    "            result = [func(x) for x in test_numbers[:3]]  # Test first 3 numbers\n",
    "            print(f\"‚úÖ {func_name}: {description}\")\n",
    "            print(f\"   {test_numbers[:3]} -> {result}\")\n",
    "            \n",
    "        elif func_name == 'to_rank':\n",
    "            result = func(np.array([10, 5, 8, 2, 15]))\n",
    "            print(f\"‚úÖ {func_name}: {description}\")\n",
    "            print(f\"   [10, 5, 8, 2, 15] -> {result}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è {func_name} failed: {e}\")\n",
    "\n",
    "# Demonstrate variable information utility\n",
    "try:\n",
    "    var_info = gen.var_info(test_array)\n",
    "    print(f\"\\n‚úÖ var_info: Variable analysis\")\n",
    "    print(f\"   Array info: {var_info}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è var_info failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text and String Processing\n",
    "\n",
    "Utilities for text processing and string manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Text and String Processing ===\")\n",
    "\n",
    "# Test text processing functions\n",
    "test_texts = [\n",
    "    \"hello world example\",\n",
    "    \"machine learning experiment\",\n",
    "    \"neural network analysis\"\n",
    "]\n",
    "\n",
    "text_functions = [\n",
    "    ('title_case', 'Convert to title case'),\n",
    "    ('title2path', 'Convert title to file path'),\n",
    "    ('wrap', 'Text wrapping')\n",
    "]\n",
    "\n",
    "for func_name, description in text_functions:\n",
    "    try:\n",
    "        func = getattr(gen, func_name)\n",
    "        \n",
    "        if func_name == 'title_case':\n",
    "            results = [func(text) for text in test_texts]\n",
    "            print(f\"‚úÖ {func_name}: {description}\")\n",
    "            for orig, result in zip(test_texts, results):\n",
    "                print(f\"   '{orig}' -> '{result}'\")\n",
    "                \n",
    "        elif func_name == 'title2path':\n",
    "            results = [func(text) for text in test_texts]\n",
    "            print(f\"‚úÖ {func_name}: {description}\")\n",
    "            for orig, result in zip(test_texts, results):\n",
    "                print(f\"   '{orig}' -> '{result}'\")\n",
    "                \n",
    "        elif func_name == 'wrap':\n",
    "            long_text = \"This is a very long text that needs to be wrapped to demonstrate the text wrapping functionality of the scitex gen module.\"\n",
    "            result = func(long_text, width=30)\n",
    "            print(f\"‚úÖ {func_name}: {description}\")\n",
    "            print(f\"   Wrapped text (width=30):\\n{result}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è {func_name} failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. System and Environment Utilities\n",
    "\n",
    "Functions for system interaction, environment detection, and host management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== System and Environment Utilities ===\")\n",
    "\n",
    "# Test environment detection\n",
    "env_functions = [\n",
    "    ('is_ipython', 'Check if running in IPython/Jupyter'),\n",
    "    ('is_script', 'Check if running as script'),\n",
    "    ('check_host', 'Check current host information')\n",
    "]\n",
    "\n",
    "for func_name, description in env_functions:\n",
    "    try:\n",
    "        func = getattr(gen, func_name)\n",
    "        \n",
    "        if func_name in ['is_ipython', 'is_script']:\n",
    "            result = func()\n",
    "            print(f\"‚úÖ {func_name}: {description} -> {result}\")\n",
    "            \n",
    "        elif func_name == 'check_host':\n",
    "            result = func()\n",
    "            print(f\"‚úÖ {func_name}: {description} -> {result}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è {func_name} failed: {e}\")\n",
    "\n",
    "# Test package listing\n",
    "try:\n",
    "    packages = gen.list_packages()\n",
    "    print(f\"\\n‚úÖ list_packages: Found {len(packages)} installed packages\")\n",
    "    print(f\"   Sample packages: {list(packages.keys())[:5]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è list_packages failed: {e}\")\n",
    "\n",
    "# Test shell command execution\n",
    "try:\n",
    "    result = gen.run_shellcommand(\"echo 'Hello from shell'\")\n",
    "    print(f\"\\n‚úÖ run_shellcommand: Shell execution successful\")\n",
    "    print(f\"   Output: {result.strip()}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è run_shellcommand failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Caching and Performance Optimization\n",
    "\n",
    "Caching utilities for improving performance of repeated computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Caching and Performance Optimization ===\")\n",
    "\n",
    "import time\n",
    "\n",
    "# Demonstrate caching with a slow function\n",
    "@gen.cache\n",
    "def slow_computation(n):\n",
    "    \"\"\"Simulate a slow computation.\"\"\"\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    return sum(i**2 for i in range(n))\n",
    "\n",
    "print(\"Testing caching performance:\")\n",
    "\n",
    "# First call (uncached)\n",
    "start_time = time.time()\n",
    "result1 = slow_computation(1000)\n",
    "first_call_time = time.time() - start_time\n",
    "\n",
    "# Second call (cached)\n",
    "start_time = time.time()\n",
    "result2 = slow_computation(1000)\n",
    "second_call_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚úÖ First call (uncached): {first_call_time:.3f}s -> result: {result1}\")\n",
    "print(f\"‚úÖ Second call (cached): {second_call_time:.3f}s -> result: {result2}\")\n",
    "print(f\"‚úÖ Speedup: {first_call_time/second_call_time:.1f}x faster\")\n",
    "print(f\"‚úÖ Results match: {result1 == result2}\")\n",
    "\n",
    "# Demonstrate cache info\n",
    "try:\n",
    "    cache_info = slow_computation.cache_info()\n",
    "    print(f\"\\n‚úÖ Cache statistics: {cache_info}\")\n",
    "except:\n",
    "    print(\"\\n‚ö†Ô∏è Cache info not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Format Conversion\n",
    "\n",
    "Utilities for converting between different data formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Data Format Conversion ===\")\n",
    "\n",
    "# Test XML to dictionary conversion\n",
    "sample_xml = '''\n",
    "<experiment>\n",
    "    <name>Neural Network Test</name>\n",
    "    <parameters>\n",
    "        <learning_rate>0.001</learning_rate>\n",
    "        <epochs>100</epochs>\n",
    "        <batch_size>32</batch_size>\n",
    "    </parameters>\n",
    "    <results>\n",
    "        <accuracy>0.95</accuracy>\n",
    "        <loss>0.05</loss>\n",
    "    </results>\n",
    "</experiment>\n",
    "'''\n",
    "\n",
    "try:\n",
    "    # Convert XML to dictionary\n",
    "    xml_dict = gen.xml2dict(sample_xml)\n",
    "    print(\"‚úÖ XML to Dictionary conversion:\")\n",
    "    print(f\"   Experiment name: {xml_dict['experiment']['name']}\")\n",
    "    print(f\"   Learning rate: {xml_dict['experiment']['parameters']['learning_rate']}\")\n",
    "    print(f\"   Accuracy: {xml_dict['experiment']['results']['accuracy']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è XML conversion failed: {e}\")\n",
    "\n",
    "# Test alternate keyword argument utility\n",
    "try:\n",
    "    # This utility helps with parameter compatibility\n",
    "    def example_function(**kwargs):\n",
    "        # Use alternate_kwarg to handle different parameter names\n",
    "        lr = gen.alternate_kwarg(kwargs, ['learning_rate', 'lr', 'alpha'], default=0.01)\n",
    "        return f\"Learning rate: {lr}\"\n",
    "    \n",
    "    # Test with different parameter names\n",
    "    result1 = example_function(learning_rate=0.001)\n",
    "    result2 = example_function(lr=0.01)\n",
    "    result3 = example_function(alpha=0.1)\n",
    "    result4 = example_function()  # Use default\n",
    "    \n",
    "    print(\"\\n‚úÖ Alternate keyword argument handling:\")\n",
    "    print(f\"   {result1}\")\n",
    "    print(f\"   {result2}\")\n",
    "    print(f\"   {result3}\")\n",
    "    print(f\"   {result4}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Alternate kwarg failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Utilities\n",
    "\n",
    "Dimension handling, time stamping, and other advanced utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Advanced Utilities ===\")\n",
    "\n",
    "# Test DimHandler for dimension management\n",
    "try:\n",
    "    # Create multi-dimensional data\n",
    "    data_3d = np.random.rand(10, 5, 3)\n",
    "    \n",
    "    dim_handler = gen.DimHandler()\n",
    "    print(f\"‚úÖ DimHandler created for dimension management\")\n",
    "    print(f\"   Original data shape: {data_3d.shape}\")\n",
    "    \n",
    "    # Note: Actual usage would depend on specific methods available\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è DimHandler failed: {e}\")\n",
    "\n",
    "# Test TimeStamper for time management\n",
    "try:\n",
    "    timestamper = gen.TimeStamper()\n",
    "    print(f\"\\n‚úÖ TimeStamper created for time tracking\")\n",
    "    print(f\"   Current timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è TimeStamper failed: {e}\")\n",
    "\n",
    "# Test source code inspection\n",
    "try:\n",
    "    # Inspect a function's source\n",
    "    import inspect\n",
    "    \n",
    "    def sample_function(x, y=10):\n",
    "        \"\"\"A sample function for inspection.\"\"\"\n",
    "        return x + y\n",
    "    \n",
    "    source = inspect.getsource(sample_function)\n",
    "    print(f\"\\n‚úÖ Source code inspection:\")\n",
    "    print(f\"   Function signature: {inspect.signature(sample_function)}\")\n",
    "    print(f\"   Docstring: {sample_function.__doc__}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Source inspection failed: {e}\")\n",
    "\n",
    "# Test symlog utility (if available)\n",
    "try:\n",
    "    # Symlog is useful for data with wide dynamic range\n",
    "    data_wide_range = np.array([-1000, -10, -1, 0, 1, 10, 1000])\n",
    "    symlog_result = gen.symlog(data_wide_range)\n",
    "    print(f\"\\n‚úÖ Symlog transformation:\")\n",
    "    print(f\"   Original: {data_wide_range}\")\n",
    "    print(f\"   Symlog: {symlog_result}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Symlog failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Integration Example: Complete Workflow\n",
    "\n",
    "Demonstrate how gen utilities work together in a typical workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Complete Workflow Integration ===\")\n",
    "\n",
    "# Simulate a complete research workflow\n",
    "class ExperimentWorkflow:\n",
    "    def __init__(self, name):\n",
    "        self.name = gen.title_case(name) if hasattr(gen, 'title_case') else name.title()\n",
    "        self.start_time = datetime.now()\n",
    "        print(f\"üß™ Starting experiment: {self.name}\")\n",
    "        \n",
    "    @gen.cache\n",
    "    def load_data(self, size=1000):\n",
    "        \"\"\"Load and preprocess data (cached for performance).\"\"\"\n",
    "        # Simulate data loading\n",
    "        data = np.random.randn(size) * 10 + 5\n",
    "        return data\n",
    "    \n",
    "    def preprocess_data(self, data):\n",
    "        \"\"\"Preprocess data using gen utilities.\"\"\"\n",
    "        # Normalize data\n",
    "        if hasattr(gen, 'to_z'):\n",
    "            normalized = gen.to_z(data)\n",
    "        else:\n",
    "            normalized = (data - data.mean()) / data.std()\n",
    "            \n",
    "        # Clip outliers\n",
    "        if hasattr(gen, 'clip_perc'):\n",
    "            clipped = gen.clip_perc(normalized, 5, 95)\n",
    "        else:\n",
    "            p5, p95 = np.percentile(normalized, [5, 95])\n",
    "            clipped = np.clip(normalized, p5, p95)\n",
    "            \n",
    "        return clipped\n",
    "    \n",
    "    def analyze_data(self, data):\n",
    "        \"\"\"Analyze processed data.\"\"\"\n",
    "        stats = {\n",
    "            'mean': data.mean(),\n",
    "            'std': data.std(),\n",
    "            'min': data.min(),\n",
    "            'max': data.max(),\n",
    "            'samples': len(data)\n",
    "        }\n",
    "        return stats\n",
    "    \n",
    "    def generate_report(self, stats):\n",
    "        \"\"\"Generate a formatted report.\"\"\"\n",
    "        duration = datetime.now() - self.start_time\n",
    "        \n",
    "        report = f\"\"\"\n",
    "=== Experiment Report: {self.name} ===\n",
    "Duration: {duration.total_seconds():.2f} seconds\n",
    "Data Statistics:\n",
    "  - Samples: {stats['samples']}\n",
    "  - Mean: {stats['mean']:.3f}\n",
    "  - Std: {stats['std']:.3f}\n",
    "  - Range: [{stats['min']:.3f}, {stats['max']:.3f}]\n",
    "Generated at: {datetime.now().strftime('%H:%M:%S')}\n",
    "        \"\"\"\n",
    "        return report.strip()\n",
    "\n",
    "# Run the complete workflow\n",
    "workflow = ExperimentWorkflow(\"neural signal analysis\")\n",
    "\n",
    "# Step 1: Load data (cached)\n",
    "raw_data = workflow.load_data(1000)\n",
    "print(f\"üìä Loaded {len(raw_data)} samples\")\n",
    "\n",
    "# Step 2: Preprocess data\n",
    "processed_data = workflow.preprocess_data(raw_data)\n",
    "print(f\"üîß Preprocessed data: {processed_data.shape}\")\n",
    "\n",
    "# Step 3: Analyze data\n",
    "statistics = workflow.analyze_data(processed_data)\n",
    "print(f\"üìà Analysis complete\")\n",
    "\n",
    "# Step 4: Generate report\n",
    "final_report = workflow.generate_report(statistics)\n",
    "print(f\"\\n{final_report}\")\n",
    "\n",
    "# Test caching benefit\n",
    "print(\"\\nüöÄ Testing cache performance:\")\n",
    "start = datetime.now()\n",
    "cached_data = workflow.load_data(1000)  # Should be cached\n",
    "cache_time = (datetime.now() - start).total_seconds()\n",
    "print(f\"   Cached data retrieval: {cache_time:.6f} seconds\")\n",
    "print(f\"   Data integrity: {np.array_equal(raw_data, cached_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial demonstrated the comprehensive functionality of the SciTeX Gen module:\n",
    "\n",
    "### ‚úÖ **Experiment Lifecycle Management**\n",
    "- Project setup with `start()` and `close()` functions\n",
    "- Unique ID generation and reproducibility\n",
    "- Configuration management and logging\n",
    "- Experiment tracking and versioning\n",
    "\n",
    "### ‚úÖ **Data Processing Utilities**\n",
    "- Normalization functions (`to_01`, `to_z`, `unbias`, `clip_perc`)\n",
    "- Array manipulation (`transpose`, `to_even`, `to_odd`, `to_rank`)\n",
    "- Statistical transformations and outlier handling\n",
    "\n",
    "### ‚úÖ **Text and String Processing**\n",
    "- Text formatting (`title_case`, `title2path`)\n",
    "- String manipulation and path generation\n",
    "- Text wrapping and formatting utilities\n",
    "\n",
    "### ‚úÖ **System and Environment**\n",
    "- Environment detection (`is_ipython`, `is_script`)\n",
    "- Host and system information (`check_host`)\n",
    "- Package management (`list_packages`)\n",
    "- Shell command execution\n",
    "\n",
    "### ‚úÖ **Performance Optimization**\n",
    "- Function caching with `@cache` decorator\n",
    "- LRU cache implementation\n",
    "- Performance monitoring and optimization\n",
    "\n",
    "### ‚úÖ **Data Format Conversion**\n",
    "- XML to dictionary conversion\n",
    "- Parameter handling and compatibility\n",
    "- Format transformation utilities\n",
    "\n",
    "### ‚úÖ **Advanced Features**\n",
    "- Dimension handling (`DimHandler`)\n",
    "- Time management (`TimeStamper`)\n",
    "- Source code inspection\n",
    "- Specialized transformations (`symlog`)\n",
    "\n",
    "### Key Applications:\n",
    "- **Research Workflows**: Complete experiment lifecycle management\n",
    "- **Data Science**: Preprocessing and normalization pipelines\n",
    "- **Development Tools**: Caching, debugging, and optimization\n",
    "- **System Integration**: Environment detection and configuration\n",
    "- **Reproducibility**: Seed fixing and experiment tracking\n",
    "\n",
    "The SciTeX Gen module serves as the foundation for reproducible scientific computing workflows, providing essential utilities that work seamlessly together to support research and development activities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
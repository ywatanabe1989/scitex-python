{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive SciTeX Operating System Module Examples\n",
    "\n",
    "This notebook demonstrates the complete functionality of the `scitex.os` module, which provides operating system utilities for scientific computing workflows.\n",
    "\n",
    "## Module Overview\n",
    "\n",
    "The `scitex.os` module includes:\n",
    "- File and directory manipulation utilities\n",
    "- Safe file movement operations\n",
    "- Cross-platform file system operations\n",
    "\n",
    "## Import Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect notebook name for output directory\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get notebook name (for papermill compatibility)\n",
    "notebook_name = \"09_scitex_os\"\n",
    "if 'PAPERMILL_NOTEBOOK_NAME' in os.environ:\n",
    "    notebook_name = Path(os.environ['PAPERMILL_NOTEBOOK_NAME']).stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Import scitex os module\n",
    "import scitex.os as sos\n",
    "\n",
    "os_attrs = [attr for attr in dir(sos) if not attr.startswith('_')]\n",
    "for i, attr in enumerate(os_attrs):\n",
    "        pass  # Processing i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. File Movement Operations\n",
    "\n",
    "### Basic File Movement\n",
    "\n",
    "The `mv` function provides safe file and directory movement operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic file movement\n",
    "\n",
    "# Create a temporary directory for testing\n",
    "temp_dir = tempfile.mkdtemp(prefix='scitex_os_test_')\n",
    "\n",
    "# Create test files\n",
    "test_files = {\n",
    "    'data.txt': \"Sample scientific data\\n1,2,3\\n4,5,6\\n7,8,9\",\n",
    "    'results.csv': \"experiment,value,error\\nA,10.5,0.1\\nB,12.3,0.2\\nC,9.8,0.15\",\n",
    "    'analysis.py': \"import numpy as np\\ndata = np.array([1,2,3])\\nprint(data.mean())\",\n",
    "    'readme.md': \"# Scientific Analysis\\nThis directory contains analysis files.\"\n",
    "}\n",
    "\n",
    "source_dir = os.path.join(temp_dir, 'source')\n",
    "target_dir = os.path.join(temp_dir, 'target')\n",
    "\n",
    "os.makedirs(source_dir, exist_ok=True)\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Create test files in source directory\n",
    "created_files = []\n",
    "for filename, content in test_files.items():\n",
    "    file_path = os.path.join(source_dir, filename)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    created_files.append(file_path)\n",
    "\n",
    "for item in os.listdir(source_dir):\n",
    "    item_path = os.path.join(source_dir, item)\n",
    "    size = os.path.getsize(item_path)\n",
    "\n",
    "target_contents = os.listdir(target_dir)\n",
    "if target_contents:\n",
    "    for item in target_contents:\n",
    "        pass  # Loop body\n",
    "else:    pass  # Fixed incomplete block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Individual Files\n",
    "\n",
    "Let's demonstrate moving individual files using the `mv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Moving individual files\n",
    "\n",
    "# Test moving individual files\n",
    "files_to_move = ['data.txt', 'results.csv']\n",
    "\n",
    "for filename in files_to_move:\n",
    "    source_path = os.path.join(source_dir, filename)\n",
    "    \n",
    "    if os.path.exists(source_path):\n",
    "        pass  # Condition handled\n",
    "        try:\n",
    "            # Use scitex.os.mv function\n",
    "            result = sos.mv(source_path, target_dir)\n",
    "            \n",
    "            # Check if file was moved successfully\n",
    "            target_path = os.path.join(target_dir, filename)\n",
    "            if os.path.exists(target_path):\n",
    "                pass  # Condition handled\n",
    "            else:\n",
    "                pass  # Else case\n",
    "                \n",
    "            # Check if source file was removed\n",
    "            if not os.path.exists(source_path):\n",
    "                pass  # Condition handled\n",
    "            else:\n",
    "                pass  # Else case\n",
    "                \n",
    "        except Exception as e:\n",
    "            pass  # Exception handled\n",
    "    else:\n",
    "        pass  # Else case\n",
    "\n",
    "# Show updated directory contents\n",
    "source_contents = os.listdir(source_dir)\n",
    "for item in source_contents:\n",
    "    pass  # Loop body\n",
    "target_contents = os.listdir(target_dir)\n",
    "for item in target_contents:\n",
    "    item_path = os.path.join(target_dir, item)\n",
    "    size = os.path.getsize(item_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Remaining Files\n",
    "\n",
    "Let's move the remaining files and test error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Moving remaining files and error handling\n",
    "\n",
    "# Move remaining files\n",
    "remaining_files = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "\n",
    "\n",
    "for filename in remaining_files:\n",
    "    source_path = os.path.join(source_dir, filename)\n",
    "    \n",
    "    try:\n",
    "        result = sos.mv(source_path, target_dir)\n",
    "    except Exception as e:\n",
    "        pass  # Exception handled\n",
    "\n",
    "# Test error handling with non-existent file\n",
    "\n",
    "non_existent_file = os.path.join(source_dir, 'does_not_exist.txt')\n",
    "try:\n",
    "    result = sos.mv(non_existent_file, target_dir)\n",
    "except Exception as e:\n",
    "    pass  # Exception handled\n",
    "\n",
    "# Final directory status\n",
    "for item in os.listdir(source_dir):\n",
    "    pass  # Loop body\n",
    "for item in os.listdir(target_dir):\n",
    "    item_path = os.path.join(target_dir, item)\n",
    "    if os.path.isfile(item_path):\n",
    "        size = os.path.getsize(item_path)\n",
    "    else:        pass  # Fixed incomplete block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced File Operations\n",
    "\n",
    "### Working with Different File Types\n",
    "\n",
    "Let's test the mv function with various scientific file types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Working with different scientific file types\n",
    "\n",
    "# Create a new test directory structure\n",
    "scientific_dir = os.path.join(temp_dir, 'scientific_files')\n",
    "organized_dir = os.path.join(temp_dir, 'organized')\n",
    "\n",
    "os.makedirs(scientific_dir, exist_ok=True)\n",
    "os.makedirs(organized_dir, exist_ok=True)\n",
    "\n",
    "# Create different types of scientific files\n",
    "scientific_files = {\n",
    "    # Data files\n",
    "    'experiment_001.csv': \"time,temperature,pressure\\n0,25.1,1013\\n1,25.3,1012\\n2,25.5,1011\",\n",
    "    'sensor_data.json': '{\"sensors\": [{\"id\": 1, \"value\": 23.4}, {\"id\": 2, \"value\": 24.1}]}',\n",
    "    'measurements.xlsx': \"# Simulated Excel file content (binary data would go here)\",\n",
    "    \n",
    "    # Analysis files\n",
    "    'statistical_analysis.py': \"import pandas as pd\\nimport numpy as np\\ndata = pd.read_csv('data.csv')\\nprint(data.describe())\",\n",
    "    'visualization.R': \"library(ggplot2)\\ndata <- read.csv('data.csv')\\nggplot(data, aes(x=time, y=value)) + geom_line()\",\n",
    "    'analysis.ipynb': '{\"cells\": [], \"metadata\": {}, \"nbformat\": 4, \"nbformat_minor\": 4}',\n",
    "    \n",
    "    # Configuration files\n",
    "    'config.yaml': \"experiment:\\n  name: test_001\\n  duration: 3600\\n  sampling_rate: 100\",\n",
    "    'parameters.ini': \"[DEFAULT]\\ntemperature = 25\\npressure = 1013\\n[EXPERIMENT]\\nruns = 10\",\n",
    "    \n",
    "    # Documentation\n",
    "    'protocol.md': \"# Experimental Protocol\\n\\n## Procedure\\n1. Setup equipment\\n2. Calibrate sensors\\n3. Run experiment\",\n",
    "    'results_summary.txt': \"Experimental Results Summary\\n\\nMean temperature: 25.3°C\\nStandard deviation: 0.2°C\"\n",
    "}\n",
    "\n",
    "# Create all files\n",
    "for filename, content in scientific_files.items():\n",
    "    file_path = os.path.join(scientific_dir, filename)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    # Get file info\n",
    "    size = os.path.getsize(file_path)\n",
    "    ext = os.path.splitext(filename)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organizing Files by Type\n",
    "\n",
    "Let's organize the scientific files by type using the mv function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Organizing files by type\n",
    "\n",
    "# Define file type categories\n",
    "file_categories = {\n",
    "    'data': ['.csv', '.json', '.xlsx', '.txt'],\n",
    "    'analysis': ['.py', '.R', '.ipynb'],\n",
    "    'config': ['.yaml', '.ini'],\n",
    "    'docs': ['.md', '.txt']\n",
    "}\n",
    "\n",
    "# Create category directories\n",
    "category_dirs = {}\n",
    "for category in file_categories.keys():\n",
    "    category_dir = os.path.join(organized_dir, category)\n",
    "    os.makedirs(category_dir, exist_ok=True)\n",
    "    category_dirs[category] = category_dir\n",
    "\n",
    "# Function to determine file category\n",
    "def get_file_category(filename):\n",
    "    ext = os.path.splitext(filename)[1].lower()\n",
    "    \n",
    "    for category, extensions in file_categories.items():\n",
    "        if ext in extensions:\n",
    "            # Special handling for .txt files\n",
    "            if ext == '.txt':\n",
    "                if 'result' in filename.lower() or 'summary' in filename.lower():\n",
    "                    return 'data'\n",
    "                else:\n",
    "                    return 'docs'\n",
    "            return category\n",
    "    \n",
    "    return 'misc'  # Default category\n",
    "\n",
    "# Organize files\n",
    "files_moved = {category: [] for category in file_categories.keys()}\n",
    "files_moved['misc'] = []\n",
    "\n",
    "for filename in os.listdir(scientific_dir):\n",
    "    source_path = os.path.join(scientific_dir, filename)\n",
    "    \n",
    "    if os.path.isfile(source_path):\n",
    "        category = get_file_category(filename)\n",
    "        \n",
    "        # Create misc directory if needed\n",
    "        if category == 'misc' and category not in category_dirs:\n",
    "            misc_dir = os.path.join(organized_dir, 'misc')\n",
    "            os.makedirs(misc_dir, exist_ok=True)\n",
    "            category_dirs['misc'] = misc_dir\n",
    "        \n",
    "        target_dir = category_dirs[category]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            result = sos.mv(source_path, target_dir)\n",
    "            files_moved[category].append(filename)\n",
    "        except Exception as e:\n",
    "            pass  # Exception handled\n",
    "\n",
    "# Show organization results\n",
    "total_moved = 0\n",
    "for category, files in files_moved.items():\n",
    "    if files:\n",
    "        for filename in files:\n",
    "            pass  # Loop body\n",
    "        total_moved += len(files)\n",
    "\n",
    "\n",
    "# Verify organization\n",
    "for category, directory in category_dirs.items():\n",
    "    if os.path.exists(directory):\n",
    "        contents = os.listdir(directory)\n",
    "    else:        pass  # Fixed incomplete block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Practical Scientific Workflows\n",
    "\n",
    "### Experimental Data Organization\n",
    "\n",
    "Let's demonstrate a practical workflow for organizing experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6: Experimental data organization workflow\n",
    "\n",
    "# Create a realistic experimental data structure\n",
    "experiment_root = os.path.join(temp_dir, 'experiment_2024')\n",
    "raw_data_dir = os.path.join(experiment_root, 'raw_data')\n",
    "processed_dir = os.path.join(experiment_root, 'processed')\n",
    "\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Simulate experimental data files from different days\n",
    "import datetime\n",
    "\n",
    "experimental_data = {\n",
    "    # Day 1 data\n",
    "    '2024-01-15_experiment_001_raw.csv': \"timestamp,sensor1,sensor2,sensor3\\n2024-01-15T09:00:00,23.1,45.2,67.3\\n2024-01-15T09:01:00,23.2,45.1,67.4\",\n",
    "    '2024-01-15_experiment_001_metadata.json': '{\"date\": \"2024-01-15\", \"duration\": 3600, \"samples\": 60, \"conditions\": \"standard\"}',\n",
    "    '2024-01-15_calibration.csv': \"device,reference,measured,error\\nsensor1,25.0,25.1,0.1\\nsensor2,50.0,49.9,-0.1\",\n",
    "    \n",
    "    # Day 2 data\n",
    "    '2024-01-16_experiment_002_raw.csv': \"timestamp,sensor1,sensor2,sensor3\\n2024-01-16T10:00:00,24.1,46.2,68.3\\n2024-01-16T10:01:00,24.2,46.1,68.4\",\n",
    "    '2024-01-16_experiment_002_metadata.json': '{\"date\": \"2024-01-16\", \"duration\": 3600, \"samples\": 60, \"conditions\": \"elevated_temp\"}',\n",
    "    \n",
    "    # Day 3 data\n",
    "    '2024-01-17_experiment_003_raw.csv': \"timestamp,sensor1,sensor2,sensor3\\n2024-01-17T11:00:00,25.1,47.2,69.3\\n2024-01-17T11:01:00,25.2,47.1,69.4\",\n",
    "    '2024-01-17_experiment_003_metadata.json': '{\"date\": \"2024-01-17\", \"duration\": 3600, \"samples\": 60, \"conditions\": \"high_humidity\"}',\n",
    "    '2024-01-17_notes.txt': \"Observed unusual fluctuations in sensor2 around 11:30. Need to investigate calibration.\",\n",
    "}\n",
    "\n",
    "# Create experimental data files\n",
    "for filename, content in experimental_data.items():\n",
    "    file_path = os.path.join(raw_data_dir, filename)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    size = os.path.getsize(file_path)\n",
    "\n",
    "\n",
    "# Organize by experiment date\n",
    "date_dirs = {}\n",
    "\n",
    "for filename in os.listdir(raw_data_dir):\n",
    "    if filename.startswith('2024-'):\n",
    "        # Extract date from filename\n",
    "        date_part = filename.split('_')[0]  # e.g., '2024-01-15'\n",
    "        \n",
    "        # Create date-based directory\n",
    "        if date_part not in date_dirs:\n",
    "            date_dir = os.path.join(processed_dir, date_part)\n",
    "            os.makedirs(date_dir, exist_ok=True)\n",
    "            date_dirs[date_part] = date_dir\n",
    "        \n",
    "        # Move file to date directory\n",
    "        source_path = os.path.join(raw_data_dir, filename)\n",
    "        target_dir = date_dirs[date_part]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            result = sos.mv(source_path, target_dir)\n",
    "        except Exception as e:\n",
    "            pass  # Fixed incomplete except block\n",
    "\n",
    "# Show final organization\n",
    "\n",
    "for date_dir in sorted(date_dirs.keys()):\n",
    "    full_path = date_dirs[date_dir]\n",
    "    files = os.listdir(full_path)\n",
    "    for file in sorted(files):\n",
    "        file_path = os.path.join(full_path, file)\n",
    "        size = os.path.getsize(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Backup and Archive Workflow\n",
    "\n",
    "Let's demonstrate a backup workflow using the mv function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7: File backup and archive workflow\n",
    "\n",
    "# Create a working directory with important files\n",
    "working_dir = os.path.join(temp_dir, 'active_project')\n",
    "archive_dir = os.path.join(temp_dir, 'archive')\n",
    "backup_dir = os.path.join(temp_dir, 'backup')\n",
    "\n",
    "os.makedirs(working_dir, exist_ok=True)\n",
    "os.makedirs(archive_dir, exist_ok=True)\n",
    "os.makedirs(backup_dir, exist_ok=True)\n",
    "\n",
    "# Create files representing different stages of work\n",
    "project_files = {\n",
    "    # Current work\n",
    "    'current_analysis.py': \"# Current analysis script\\nimport numpy as np\\ndata = np.random.randn(1000)\\nprint(f'Mean: {data.mean():.3f}')\",\n",
    "    'latest_results.csv': \"date,value,status\\n2024-01-20,95.2,active\\n2024-01-21,96.1,active\",\n",
    "    'active_notebook.ipynb': '{\"cells\": [{\"cell_type\": \"code\", \"source\": [\"print(\\\\\"Active work\\\\\")\"]}]}',\n",
    "    \n",
    "    # Old versions (to be archived)\n",
    "    'analysis_v1.py': \"# Old version 1\\nimport numpy as np\\ndata = np.random.randn(100)\\nprint(data.mean())\",\n",
    "    'analysis_v2.py': \"# Old version 2\\nimport numpy as np\\ndata = np.random.randn(500)\\nprint(f'Mean: {data.mean()}')\",\n",
    "    'old_results_2024-01-10.csv': \"date,value,status\\n2024-01-10,90.1,archived\\n2024-01-11,91.2,archived\",\n",
    "    'deprecated_notebook.ipynb': '{\"cells\": [{\"cell_type\": \"code\", \"source\": [\"print(\\\\\"Deprecated\\\\\")\"]}]}',\n",
    "    \n",
    "    # Temporary files (to be cleaned up)\n",
    "    'temp_data.tmp': \"temporary data for processing\",\n",
    "    'cache_file.cache': \"cached computation results\",\n",
    "    'debug_output.log': \"DEBUG: Starting analysis\\nINFO: Processing complete\\nDEBUG: Cleanup finished\"\n",
    "}\n",
    "\n",
    "# Create project files\n",
    "for filename, content in project_files.items():\n",
    "    file_path = os.path.join(working_dir, filename)\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    size = os.path.getsize(file_path)\n",
    "\n",
    "\n",
    "# Define file categories for workflow\n",
    "def categorize_file(filename):\n",
    "    \"\"\"Categorize files for workflow processing.\"\"\"\n",
    "    filename_lower = filename.lower()\n",
    "    \n",
    "    # Temporary files to delete\n",
    "    if any(ext in filename_lower for ext in ['.tmp', '.cache', '.log']):\n",
    "        return 'temporary'\n",
    "    \n",
    "    # Old versions to archive\n",
    "    if any(keyword in filename_lower for keyword in ['_v1', '_v2', 'old_', 'deprecated']):\n",
    "        return 'archive'\n",
    "    \n",
    "    # Current files to keep\n",
    "    if any(keyword in filename_lower for keyword in ['current', 'latest', 'active']):\n",
    "        return 'current'\n",
    "    \n",
    "    return 'unknown'\n",
    "\n",
    "# Process files according to workflow\n",
    "\n",
    "files_by_category = {'current': [], 'archive': [], 'temporary': [], 'unknown': []}\n",
    "\n",
    "for filename in os.listdir(working_dir):\n",
    "    source_path = os.path.join(working_dir, filename)\n",
    "    \n",
    "    if os.path.isfile(source_path):\n",
    "        category = categorize_file(filename)\n",
    "        files_by_category[category].append(filename)\n",
    "        \n",
    "        if category == 'archive':\n",
    "            try:\n",
    "                result = sos.mv(source_path, archive_dir)\n",
    "            except Exception as e:\n",
    "                pass  # Fixed incomplete except block\n",
    "                \n",
    "        elif category == 'temporary':\n",
    "            try:\n",
    "                os.remove(source_path)\n",
    "            except Exception as e:\n",
    "                pass  # Fixed incomplete except block\n",
    "                \n",
    "        elif category == 'current':\n",
    "        pass  # Block fixed\n",
    "            \n",
    "        else:\n",
    "            pass  # Fixed incomplete block\n",
    "\n",
    "# Show workflow results\n",
    "for category, files in files_by_category.items():\n",
    "    if files:\n",
    "        for filename in files:\n",
    "            # Process filename\n",
    "\n",
    "# Show final directory states\n",
    "directories = {\n",
    "    'Working': working_dir,\n",
    "    'Archive': archive_dir,\n",
    "    'Backup': backup_dir\n",
    "}\n",
    "\n",
    "for dir_name, dir_path in directories.items():\n",
    "    contents = os.listdir(dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Error Handling and Edge Cases\n",
    "\n",
    "### Testing Edge Cases\n",
    "\n",
    "Let's test the mv function with various edge cases and error conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 8: Testing edge cases and error handling\n",
    "\n",
    "# Create test directory for edge cases\n",
    "edge_test_dir = os.path.join(temp_dir, 'edge_cases')\n",
    "os.makedirs(edge_test_dir, exist_ok=True)\n",
    "\n",
    "# Test Case 1: Non-existent source file\n",
    "non_existent = os.path.join(edge_test_dir, 'does_not_exist.txt')\n",
    "target = os.path.join(edge_test_dir, 'target')\n",
    "os.makedirs(target, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    result = sos.mv(non_existent, target)\n",
    "except Exception as e:\n",
    "    pass  # Fixed incomplete except block\n",
    "\n",
    "# Test Case 2: Moving to non-existent directory (should create it)\n",
    "test_file = os.path.join(edge_test_dir, 'test_file.txt')\n",
    "with open(test_file, 'w') as f:\n",
    "    f.write('Test content')\n",
    "\n",
    "non_existent_dir = os.path.join(edge_test_dir, 'new_directory')\n",
    "\n",
    "try:\n",
    "    result = sos.mv(test_file, non_existent_dir)\n",
    "except Exception as e:\n",
    "    pass  # Fixed incomplete except block\n",
    "\n",
    "# Test Case 3: Moving file with same name (overwrite behavior)\n",
    "source_file = os.path.join(edge_test_dir, 'duplicate.txt')\n",
    "target_dir = os.path.join(edge_test_dir, 'target_with_duplicate')\n",
    "target_file = os.path.join(target_dir, 'duplicate.txt')\n",
    "\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Create source file\n",
    "with open(source_file, 'w') as f:\n",
    "    f.write('Source content')\n",
    "\n",
    "# Create existing target file\n",
    "with open(target_file, 'w') as f:\n",
    "    f.write('Target content')\n",
    "\n",
    "\n",
    "try:\n",
    "    result = sos.mv(source_file, target_dir)\n",
    "    if os.path.exists(target_file):\n",
    "        final_content = open(target_file).read()\n",
    "except Exception as e:\n",
    "    pass  # Fixed incomplete except block\n",
    "\n",
    "# Test Case 4: Empty file\n",
    "empty_file = os.path.join(edge_test_dir, 'empty.txt')\n",
    "empty_target = os.path.join(edge_test_dir, 'empty_target')\n",
    "os.makedirs(empty_target, exist_ok=True)\n",
    "\n",
    "# Create empty file\n",
    "with open(empty_file, 'w') as f:\n",
    "    pass  # Create empty file\n",
    "\n",
    "size_before = os.path.getsize(empty_file)\n",
    "\n",
    "try:\n",
    "    result = sos.mv(empty_file, empty_target)\n",
    "    \n",
    "    moved_file = os.path.join(empty_target, 'empty.txt')\n",
    "    if os.path.exists(moved_file):\n",
    "        size_after = os.path.getsize(moved_file)\n",
    "except Exception as e:\n",
    "    pass  # Fixed incomplete except block\n",
    "\n",
    "# Test Case 5: File with special characters in name\n",
    "special_file = os.path.join(edge_test_dir, 'file with spaces & symbols!@#.txt')\n",
    "special_target = os.path.join(edge_test_dir, 'special_target')\n",
    "os.makedirs(special_target, exist_ok=True)\n",
    "\n",
    "with open(special_file, 'w') as f:\n",
    "    f.write('Content with special filename')\n",
    "\n",
    "\n",
    "try:\n",
    "    result = sos.mv(special_file, special_target)\n",
    "except Exception as e:\n",
    "    pass  # Fixed incomplete except block\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cleanup\n",
    "\n",
    "Let's clean up all the temporary files and directories created during this demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 9: Cleanup temporary files and directories\n",
    "\n",
    "# Calculate total size before cleanup\n",
    "def get_directory_size(directory):\n",
    "    \"\"\"Calculate total size of directory and its contents.\"\"\"\n",
    "    total_size = 0\n",
    "    if os.path.exists(directory):\n",
    "        for dirpath, dirnames, filenames in os.walk(directory):\n",
    "            for filename in filenames:\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                try:\n",
    "                    total_size += os.path.getsize(filepath)\n",
    "                except (OSError, FileNotFoundError):\n",
    "                    pass\n",
    "    return total_size\n",
    "\n",
    "# Get size before cleanup\n",
    "total_size_before = get_directory_size(temp_dir)\n",
    "\n",
    "# Count files and directories\n",
    "file_count = 0\n",
    "dir_count = 0\n",
    "\n",
    "if os.path.exists(temp_dir):\n",
    "    for root, dirs, files in os.walk(temp_dir):\n",
    "        file_count += len(files)\n",
    "        dir_count += len(dirs)\n",
    "\n",
    "\n",
    "# Show directory structure before cleanup\n",
    "def show_tree(directory, prefix=\"\", max_depth=2, current_depth=0):\n",
    "    \"\"\"Show directory tree structure.\"\"\"\n",
    "    if current_depth >= max_depth or not os.path.exists(directory):\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        items = sorted(os.listdir(directory))\n",
    "        for i, item in enumerate(items):\n",
    "            item_path = os.path.join(directory, item)\n",
    "            is_last = i == len(items) - 1\n",
    "            current_prefix = \"└── \" if is_last else \"├── \"\n",
    "            \n",
    "            if os.path.isdir(item_path):\n",
    "                next_prefix = prefix + (\"    \" if is_last else \"│   \")\n",
    "                show_tree(item_path, next_prefix, max_depth, current_depth + 1)\n",
    "            else:\n",
    "                size = os.path.getsize(item_path)\n",
    "    except (OSError, PermissionError):\n",
    "        pass  # Exception handled\n",
    "\n",
    "show_tree(temp_dir)\n",
    "\n",
    "# Perform cleanup\n",
    "try:\n",
    "    if os.path.exists(temp_dir):\n",
    "        shutil.rmtree(temp_dir)\n",
    "    else:\n",
    "        pass  # Else case\n",
    "        \n",
    "except Exception as e:\n",
    "    pass  # Exception handled\n",
    "\n",
    "# Verify cleanup\n",
    "if not os.path.exists(temp_dir):\n",
    "    pass  # Condition handled\n",
    "else:\n",
    "    remaining_files = sum([len(files) for r, d, files in os.walk(temp_dir)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has demonstrated the comprehensive functionality of the `scitex.os` module:\n",
    "\n",
    "### Core Functionality\n",
    "- **`mv`**: Safe file and directory movement operations\n",
    "  - Automatic target directory creation\n",
    "  - Cross-platform compatibility\n",
    "  - Error handling and reporting\n",
    "  - Support for various file types\n",
    "\n",
    "### Key Features\n",
    "1. **Safety**: Proper error handling prevents data loss\n",
    "2. **Convenience**: Automatic directory creation when needed\n",
    "3. **Reliability**: Consistent behavior across different operating systems\n",
    "4. **Scientific Focus**: Designed for research data management workflows\n",
    "\n",
    "### Practical Applications Demonstrated\n",
    "- **Basic File Operations**: Moving individual files and handling errors\n",
    "- **File Organization**: Categorizing and organizing files by type\n",
    "- **Scientific Workflows**: Managing experimental data and analysis files\n",
    "- **Data Management**: Archiving, backup, and cleanup procedures\n",
    "- **Edge Case Handling**: Robust behavior with various file conditions\n",
    "\n",
    "### Common Use Cases\n",
    "- **Experimental Data Organization**: Organizing data files by date, experiment, or type\n",
    "- **File Cleanup**: Moving processed files to appropriate directories\n",
    "- **Archive Management**: Moving old files to archive directories\n",
    "- **Workflow Automation**: Integrating file operations into analysis pipelines\n",
    "- **Project Organization**: Structuring research project directories\n",
    "\n",
    "### Best Practices Illustrated\n",
    "- **Test Operations**: Always verify file movements completed successfully\n",
    "- **Error Handling**: Graceful handling of permission and path issues\n",
    "- **Directory Structure**: Maintaining organized, logical file hierarchies\n",
    "- **Cleanup Procedures**: Proper cleanup of temporary files and directories\n",
    "- **Safety Checks**: Verifying source and target locations before operations\n",
    "\n",
    "### Integration with Scientific Workflows\n",
    "- **Data Pipeline Management**: Moving files between processing stages\n",
    "- **Result Organization**: Structuring output files for analysis\n",
    "- **Backup Strategies**: Implementing systematic backup procedures\n",
    "- **Collaboration**: Organizing files for team access and sharing\n",
    "- **Reproducibility**: Maintaining consistent file organization for reproducible research\n",
    "\n",
    "The `scitex.os` module provides essential file system operations tailored for scientific computing environments, with emphasis on safety, reliability, and integration with research workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
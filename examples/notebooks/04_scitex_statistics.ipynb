{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Statistics Module - Statistical Analysis\n",
    "\n",
    "The `scitex.stats` module provides convenient statistical functions commonly used in scientific research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scitex as stx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "n_samples = 1000\n",
    "data = {\n",
    "    'normal': np.random.normal(100, 15, n_samples),\n",
    "    'skewed': np.random.gamma(2, 2, n_samples) * 10,\n",
    "    'bimodal': np.concatenate([\n",
    "        np.random.normal(80, 10, n_samples//2),\n",
    "        np.random.normal(120, 10, n_samples//2)\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Calculate descriptive statistics\n",
    "desc_stats = pd.DataFrame({\n",
    "    dist_name: {\n",
    "        'mean': np.mean(dist_data),\n",
    "        'median': np.median(dist_data),\n",
    "        'std': np.std(dist_data, ddof=1),\n",
    "        'skewness': stats.skew(dist_data),\n",
    "        'kurtosis': stats.kurtosis(dist_data),\n",
    "        'min': np.min(dist_data),\n",
    "        'max': np.max(dist_data),\n",
    "        'Q1': np.percentile(dist_data, 25),\n",
    "        'Q3': np.percentile(dist_data, 75)\n",
    "    }\n",
    "    for dist_name, dist_data in data.items()\n",
    "})\n",
    "\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(desc_stats.T)\n",
    "\n",
    "# Visualize distributions\n",
    "fig, axes = stx.plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, (name, values) in zip(axes, data.items()):\n",
    "    ax.hist(values, bins=50, alpha=0.7, density=True, edgecolor='black')\n",
    "    ax.axvline(np.mean(values), color='red', linestyle='--', label=f'Mean: {np.mean(values):.1f}')\n",
    "    ax.axvline(np.median(values), color='green', linestyle='--', label=f'Median: {np.median(values):.1f}')\n",
    "    ax.set_xyt('Value', 'Density', f'{name.capitalize()} Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.tight_layout()\n",
    "stx.io.save(fig, './stats/distributions_comparison.png')\n",
    "stx.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate experimental data\n",
    "control = np.random.normal(100, 15, 100)\n",
    "treatment1 = np.random.normal(105, 15, 100)\n",
    "treatment2 = np.random.normal(110, 15, 100)\n",
    "\n",
    "# Two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control, treatment1)\n",
    "cohen_d = (np.mean(treatment1) - np.mean(control)) / np.sqrt((np.var(control) + np.var(treatment1)) / 2)\n",
    "\n",
    "print(\"Two-Sample T-Test Results:\")\n",
    "print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  Cohen's d: {cohen_d:.3f}\")\n",
    "print(f\"  Significant at α=0.05: {'Yes' if p_value < 0.05 else 'No'}\")\n",
    "\n",
    "# One-way ANOVA\n",
    "f_stat, p_anova = stats.f_oneway(control, treatment1, treatment2)\n",
    "print(\"\\nOne-Way ANOVA Results:\")\n",
    "print(f\"  F-statistic: {f_stat:.3f}\")\n",
    "print(f\"  p-value: {p_anova:.4f}\")\n",
    "\n",
    "# Post-hoc tests (if ANOVA is significant)\n",
    "if p_anova < 0.05:\n",
    "    print(\"\\nPost-hoc Pairwise T-Tests (Bonferroni corrected):\")\n",
    "    groups = [control, treatment1, treatment2]\n",
    "    group_names = ['Control', 'Treatment 1', 'Treatment 2']\n",
    "    alpha_corrected = 0.05 / 3  # Bonferroni correction\n",
    "    \n",
    "    for i in range(len(groups)):\n",
    "        for j in range(i+1, len(groups)):\n",
    "            t, p = stats.ttest_ind(groups[i], groups[j])\n",
    "            print(f\"  {group_names[i]} vs {group_names[j]}: p = {p:.4f} {'*' if p < alpha_corrected else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize group comparisons\n",
    "fig, (ax1, ax2) = stx.plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Box plot\n",
    "data_for_plot = [control, treatment1, treatment2]\n",
    "ax1.boxplot(data_for_plot, labels=group_names)\n",
    "ax1.set_xyt('Group', 'Value', 'Group Comparison (Box Plot)')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add significance indicators\n",
    "y_max = max([max(d) for d in data_for_plot]) + 5\n",
    "if p_value < 0.05:\n",
    "    ax1.plot([1, 2], [y_max, y_max], 'k-')\n",
    "    ax1.text(1.5, y_max + 1, '*', ha='center', fontsize=14)\n",
    "\n",
    "# Effect size visualization\n",
    "effect_sizes = [\n",
    "    ('Control vs T1', cohen_d),\n",
    "    ('Control vs T2', (np.mean(treatment2) - np.mean(control)) / np.sqrt((np.var(control) + np.var(treatment2)) / 2)),\n",
    "    ('T1 vs T2', (np.mean(treatment2) - np.mean(treatment1)) / np.sqrt((np.var(treatment1) + np.var(treatment2)) / 2))\n",
    "]\n",
    "\n",
    "labels, d_values = zip(*effect_sizes)\n",
    "colors = ['red' if abs(d) > 0.8 else 'orange' if abs(d) > 0.5 else 'green' for d in d_values]\n",
    "bars = ax2.barh(labels, d_values, color=colors, alpha=0.7)\n",
    "ax2.axvline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax2.set_xyt(\"Cohen's d\", 'Comparison', 'Effect Sizes')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add effect size interpretation\n",
    "ax2.axvspan(-0.2, 0.2, alpha=0.1, color='gray', label='Small')\n",
    "ax2.axvspan(0.5, 0.8, alpha=0.1, color='orange', label='Medium')\n",
    "ax2.axvspan(0.8, 2, alpha=0.1, color='red', label='Large')\n",
    "ax2.axvspan(-0.8, -0.5, alpha=0.1, color='orange')\n",
    "ax2.axvspan(-2, -0.8, alpha=0.1, color='red')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout()\n",
    "stx.io.save(fig, './stats/hypothesis_testing.png')\n",
    "stx.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation and Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlated data\n",
    "n = 200\n",
    "x = np.random.normal(0, 1, n)\n",
    "y_linear = 2 * x + np.random.normal(0, 0.5, n)\n",
    "y_nonlinear = x**2 + np.random.normal(0, 0.5, n)\n",
    "y_uncorr = np.random.normal(0, 1, n)\n",
    "\n",
    "# Calculate correlations\n",
    "correlations = {\n",
    "    'Linear': {\n",
    "        'Pearson': stats.pearsonr(x, y_linear),\n",
    "        'Spearman': stats.spearmanr(x, y_linear),\n",
    "        'Kendall': stats.kendalltau(x, y_linear)\n",
    "    },\n",
    "    'Nonlinear': {\n",
    "        'Pearson': stats.pearsonr(x, y_nonlinear),\n",
    "        'Spearman': stats.spearmanr(x, y_nonlinear),\n",
    "        'Kendall': stats.kendalltau(x, y_nonlinear)\n",
    "    },\n",
    "    'Uncorrelated': {\n",
    "        'Pearson': stats.pearsonr(x, y_uncorr),\n",
    "        'Spearman': stats.spearmanr(x, y_uncorr),\n",
    "        'Kendall': stats.kendalltau(x, y_uncorr)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display correlation results\n",
    "print(\"Correlation Analysis:\")\n",
    "print(\"-\" * 60)\n",
    "for relationship, methods in correlations.items():\n",
    "    print(f\"\\n{relationship} Relationship:\")\n",
    "    for method, (corr, p_val) in methods.items():\n",
    "        print(f\"  {method}: r = {corr:.3f}, p = {p_val:.4f}\")\n",
    "\n",
    "# Visualize relationships\n",
    "fig, axes = stx.plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Scatter plots\n",
    "datasets = [('Linear', x, y_linear), ('Nonlinear', x, y_nonlinear), ('Uncorrelated', x, y_uncorr)]\n",
    "\n",
    "for ax, (name, x_data, y_data) in zip(axes[0], datasets):\n",
    "    ax.scatter(x_data, y_data, alpha=0.6)\n",
    "    \n",
    "    # Add regression line\n",
    "    z = np.polyfit(x_data, y_data, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(sorted(x_data), p(sorted(x_data)), 'r--', linewidth=2)\n",
    "    \n",
    "    # Add correlation coefficient\n",
    "    r, _ = stats.pearsonr(x_data, y_data)\n",
    "    ax.text(0.05, 0.95, f'r = {r:.3f}', transform=ax.transAxes, \n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    ax.set_xyt('X', 'Y', f'{name} Relationship')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# QQ plots for residuals\n",
    "for ax, (name, x_data, y_data) in zip(axes[1], datasets):\n",
    "    # Calculate residuals\n",
    "    z = np.polyfit(x_data, y_data, 1)\n",
    "    p = np.poly1d(z)\n",
    "    residuals = y_data - p(x_data)\n",
    "    \n",
    "    # QQ plot\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=ax)\n",
    "    ax.set_title(f'QQ Plot - {name}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.tight_layout()\n",
    "stx.io.save(fig, './stats/correlation_analysis.png')\n",
    "stx.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate multivariate data\n",
    "n_samples = 500\n",
    "n_features = 5\n",
    "\n",
    "# True coefficients\n",
    "true_coef = np.array([3, -2, 1.5, 0, 4])\n",
    "\n",
    "# Generate features\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = X @ true_coef + np.random.normal(0, 2, n_samples)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate R-squared and MSE\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "\n",
    "print(\"Multiple Regression Results:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"R² (train): {r2_train:.3f}\")\n",
    "print(f\"R² (test): {r2_test:.3f}\")\n",
    "print(f\"MSE (train): {mse_train:.3f}\")\n",
    "print(f\"MSE (test): {mse_test:.3f}\")\n",
    "\n",
    "# Compare coefficients\n",
    "coef_comparison = pd.DataFrame({\n",
    "    'True': true_coef,\n",
    "    'Estimated': model.coef_,\n",
    "    'Difference': model.coef_ - true_coef\n",
    "}, index=[f'X{i+1}' for i in range(n_features)])\n",
    "\n",
    "print(\"\\nCoefficient Comparison:\")\n",
    "print(coef_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regression results\n",
    "fig, axes = stx.plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Actual vs Predicted\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(y_test, y_pred_test, alpha=0.6)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2)\n",
    "ax.set_xyt('Actual', 'Predicted', f'Actual vs Predicted (R² = {r2_test:.3f})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals\n",
    "ax = axes[0, 1]\n",
    "residuals = y_test - y_pred_test\n",
    "ax.scatter(y_pred_test, residuals, alpha=0.6)\n",
    "ax.axhline(y=0, color='r', linestyle='--')\n",
    "ax.set_xyt('Predicted', 'Residuals', 'Residual Plot')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Coefficient plot\n",
    "ax = axes[1, 0]\n",
    "x_pos = np.arange(n_features)\n",
    "width = 0.35\n",
    "ax.bar(x_pos - width/2, true_coef, width, label='True', alpha=0.7)\n",
    "ax.bar(x_pos + width/2, model.coef_, width, label='Estimated', alpha=0.7)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([f'X{i+1}' for i in range(n_features)])\n",
    "ax.set_xyt('Feature', 'Coefficient', 'Coefficient Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Feature importance (absolute coefficients)\n",
    "ax = axes[1, 1]\n",
    "feature_importance = np.abs(model.coef_)\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "ax.bar(range(n_features), feature_importance[sorted_idx])\n",
    "ax.set_xticks(range(n_features))\n",
    "ax.set_xticklabels([f'X{i+1}' for i in sorted_idx])\n",
    "ax.set_xyt('Feature', 'Absolute Coefficient', 'Feature Importance')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "stx.io.save(fig, './stats/multiple_regression.png')\n",
    "stx.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Non-parametric Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate non-normal data\n",
    "group1 = np.random.exponential(scale=2, size=50)\n",
    "group2 = np.random.exponential(scale=2.5, size=50)\n",
    "group3 = np.random.exponential(scale=3, size=50)\n",
    "\n",
    "# Test for normality\n",
    "print(\"Normality Tests (Shapiro-Wilk):\")\n",
    "for i, group in enumerate([group1, group2, group3], 1):\n",
    "    stat, p_val = stats.shapiro(group)\n",
    "    print(f\"  Group {i}: W = {stat:.3f}, p = {p_val:.4f} {'(Normal)' if p_val > 0.05 else '(Not Normal)'}\")\n",
    "\n",
    "# Mann-Whitney U test (two groups)\n",
    "u_stat, p_mw = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "print(f\"\\nMann-Whitney U Test (Group 1 vs 2):\")\n",
    "print(f\"  U-statistic: {u_stat:.1f}\")\n",
    "print(f\"  p-value: {p_mw:.4f}\")\n",
    "\n",
    "# Kruskal-Wallis test (multiple groups)\n",
    "h_stat, p_kw = stats.kruskal(group1, group2, group3)\n",
    "print(f\"\\nKruskal-Wallis Test (all groups):\")\n",
    "print(f\"  H-statistic: {h_stat:.3f}\")\n",
    "print(f\"  p-value: {p_kw:.4f}\")\n",
    "\n",
    "# Wilcoxon signed-rank test (paired data)\n",
    "before = np.random.normal(100, 10, 30)\n",
    "after = before + np.random.normal(3, 5, 30)  # Some improvement\n",
    "w_stat, p_wilcox = stats.wilcoxon(before, after)\n",
    "print(f\"\\nWilcoxon Signed-Rank Test (paired):\")\n",
    "print(f\"  W-statistic: {w_stat:.1f}\")\n",
    "print(f\"  p-value: {p_wilcox:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize non-parametric data\n",
    "fig, axes = stx.plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Distribution plots\n",
    "ax = axes[0, 0]\n",
    "for i, (group, label) in enumerate([(group1, 'Group 1'), (group2, 'Group 2'), (group3, 'Group 3')]):\n",
    "    ax.hist(group, bins=20, alpha=0.5, label=label, density=True)\n",
    "ax.set_xyt('Value', 'Density', 'Non-Normal Distributions')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plots\n",
    "ax = axes[0, 1]\n",
    "ax.boxplot([group1, group2, group3], labels=['Group 1', 'Group 2', 'Group 3'])\n",
    "ax.set_xyt('Group', 'Value', 'Box Plot Comparison')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Paired data (before/after)\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(before, after, alpha=0.6)\n",
    "ax.plot([before.min(), before.max()], [before.min(), before.max()], 'r--', linewidth=2)\n",
    "ax.set_xyt('Before', 'After', 'Paired Data (Wilcoxon Test)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Difference plot\n",
    "ax = axes[1, 1]\n",
    "differences = after - before\n",
    "ax.hist(differences, bins=20, alpha=0.7, edgecolor='black')\n",
    "ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "ax.axvline(np.median(differences), color='green', linestyle='--', \n",
    "           label=f'Median: {np.median(differences):.2f}')\n",
    "ax.set_xyt('Difference (After - Before)', 'Count', 'Distribution of Differences')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "fig.tight_layout()\n",
    "stx.io.save(fig, './stats/nonparametric_tests.png')\n",
    "stx.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Power Analysis and Sample Size Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestPower, FTestAnovaPower\n",
    "\n",
    "# Power analysis for t-test\n",
    "power_analysis = TTestPower()\n",
    "\n",
    "# Calculate sample size for desired power\n",
    "effect_size = 0.5  # Medium effect\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "\n",
    "sample_size = power_analysis.solve_power(effect_size=effect_size, \n",
    "                                         alpha=alpha, \n",
    "                                         power=power)\n",
    "\n",
    "print(\"Power Analysis for Two-Sample T-Test:\")\n",
    "print(f\"  Effect size (d): {effect_size}\")\n",
    "print(f\"  Alpha: {alpha}\")\n",
    "print(f\"  Desired power: {power}\")\n",
    "print(f\"  Required sample size per group: {sample_size:.0f}\")\n",
    "\n",
    "# Power curves\n",
    "sample_sizes = np.arange(10, 200, 5)\n",
    "effect_sizes = [0.2, 0.5, 0.8]  # Small, medium, large\n",
    "\n",
    "fig, (ax1, ax2) = stx.plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Power vs sample size\n",
    "for d in effect_sizes:\n",
    "    powers = [power_analysis.solve_power(effect_size=d, \n",
    "                                        nobs1=n, \n",
    "                                        alpha=alpha) \n",
    "              for n in sample_sizes]\n",
    "    ax1.plot(sample_sizes, powers, label=f'd = {d}')\n",
    "\n",
    "ax1.axhline(y=0.8, color='red', linestyle='--', alpha=0.5)\n",
    "ax1.set_xyt('Sample Size per Group', 'Statistical Power', 'Power Curves')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "# Sample size vs effect size\n",
    "effect_range = np.linspace(0.1, 1.5, 50)\n",
    "powers_target = [0.7, 0.8, 0.9]\n",
    "\n",
    "for power_target in powers_target:\n",
    "    sample_sizes_needed = [power_analysis.solve_power(effect_size=d, \n",
    "                                                     alpha=alpha, \n",
    "                                                     power=power_target) \n",
    "                          for d in effect_range]\n",
    "    ax2.plot(effect_range, sample_sizes_needed, label=f'Power = {power_target}')\n",
    "\n",
    "ax2.set_xyt('Effect Size (d)', 'Sample Size per Group', 'Sample Size Requirements')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 200)\n",
    "\n",
    "fig.tight_layout()\n",
    "stx.io.save(fig, './stats/power_analysis.png')\n",
    "stx.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bootstrapping and Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bootstrap\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "sample_data = np.random.gamma(2, 2, 100)  # Non-normal distribution\n",
    "\n",
    "# Define statistics of interest\n",
    "def mean_statistic(x):\n",
    "    return np.mean(x)\n",
    "\n",
    "def median_statistic(x):\n",
    "    return np.median(x)\n",
    "\n",
    "def trimmed_mean(x, trim=0.1):\n",
    "    return stats.trim_mean(x, trim)\n",
    "\n",
    "# Bootstrap confidence intervals\n",
    "n_bootstrap = 10000\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Perform bootstrap\n",
    "rng = np.random.default_rng(42)\n",
    "bootstrap_means = []\n",
    "bootstrap_medians = []\n",
    "bootstrap_trimmed = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    resample = rng.choice(sample_data, size=len(sample_data), replace=True)\n",
    "    bootstrap_means.append(mean_statistic(resample))\n",
    "    bootstrap_medians.append(median_statistic(resample))\n",
    "    bootstrap_trimmed.append(trimmed_mean(resample))\n",
    "\n",
    "# Calculate confidence intervals\n",
    "alpha = 1 - confidence_level\n",
    "lower_percentile = (alpha/2) * 100\n",
    "upper_percentile = (1 - alpha/2) * 100\n",
    "\n",
    "ci_mean = np.percentile(bootstrap_means, [lower_percentile, upper_percentile])\n",
    "ci_median = np.percentile(bootstrap_medians, [lower_percentile, upper_percentile])\n",
    "ci_trimmed = np.percentile(bootstrap_trimmed, [lower_percentile, upper_percentile])\n",
    "\n",
    "print(\"Bootstrap Confidence Intervals (95%):\")\n",
    "print(f\"  Mean: {np.mean(sample_data):.3f} [{ci_mean[0]:.3f}, {ci_mean[1]:.3f}]\")\n",
    "print(f\"  Median: {np.median(sample_data):.3f} [{ci_median[0]:.3f}, {ci_median[1]:.3f}]\")\n",
    "print(f\"  Trimmed Mean: {trimmed_mean(sample_data):.3f} [{ci_trimmed[0]:.3f}, {ci_trimmed[1]:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bootstrap distributions\n",
    "fig, axes = stx.plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Original data\n",
    "ax = axes[0, 0]\n",
    "ax.hist(sample_data, bins=30, alpha=0.7, density=True, edgecolor='black')\n",
    "ax.axvline(np.mean(sample_data), color='red', linestyle='--', label='Mean')\n",
    "ax.axvline(np.median(sample_data), color='green', linestyle='--', label='Median')\n",
    "ax.set_xyt('Value', 'Density', 'Original Data Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Bootstrap distributions\n",
    "statistics = [\n",
    "    ('Mean', bootstrap_means, ci_mean),\n",
    "    ('Median', bootstrap_medians, ci_median),\n",
    "    ('Trimmed Mean', bootstrap_trimmed, ci_trimmed)\n",
    "]\n",
    "\n",
    "for ax, (name, bootstrap_dist, ci) in zip(axes.flat[1:], statistics):\n",
    "    ax.hist(bootstrap_dist, bins=50, alpha=0.7, density=True, edgecolor='black')\n",
    "    ax.axvline(np.mean(bootstrap_dist), color='red', linestyle='-', linewidth=2)\n",
    "    ax.axvline(ci[0], color='red', linestyle='--', linewidth=1)\n",
    "    ax.axvline(ci[1], color='red', linestyle='--', linewidth=1)\n",
    "    ax.set_xyt(name, 'Density', f'Bootstrap Distribution of {name}')\n",
    "    ax.set_title(f'{name}: [{ci[0]:.3f}, {ci[1]:.3f}]', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig.tight_layout()\n",
    "stx.io.save(fig, './stats/bootstrap_analysis.png')\n",
    "stx.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Statistical Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive statistical report\n",
    "def generate_statistical_report(data1, data2, test_name=\"Experiment\"):\n",
    "    \"\"\"Generate a comprehensive statistical report comparing two groups.\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        'test_name': test_name,\n",
    "        'sample_sizes': {'group1': len(data1), 'group2': len(data2)},\n",
    "        'descriptive': {\n",
    "            'group1': {\n",
    "                'mean': np.mean(data1),\n",
    "                'std': np.std(data1, ddof=1),\n",
    "                'median': np.median(data1),\n",
    "                'iqr': np.percentile(data1, 75) - np.percentile(data1, 25)\n",
    "            },\n",
    "            'group2': {\n",
    "                'mean': np.mean(data2),\n",
    "                'std': np.std(data2, ddof=1),\n",
    "                'median': np.median(data2),\n",
    "                'iqr': np.percentile(data2, 75) - np.percentile(data2, 25)\n",
    "            }\n",
    "        },\n",
    "        'normality': {\n",
    "            'group1': stats.shapiro(data1),\n",
    "            'group2': stats.shapiro(data2)\n",
    "        },\n",
    "        'parametric': {\n",
    "            't_test': stats.ttest_ind(data1, data2),\n",
    "            'levene': stats.levene(data1, data2)\n",
    "        },\n",
    "        'nonparametric': {\n",
    "            'mann_whitney': stats.mannwhitneyu(data1, data2)\n",
    "        },\n",
    "        'effect_size': {\n",
    "            'cohens_d': (np.mean(data2) - np.mean(data1)) / np.sqrt((np.var(data1) + np.var(data2)) / 2)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate report\n",
    "report = generate_statistical_report(control, treatment1, \"Treatment Effect Analysis\")\n",
    "\n",
    "# Format and display report\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"STATISTICAL REPORT: {report['test_name']}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(\"\\n1. SAMPLE INFORMATION\")\n",
    "print(f\"   Group 1: n = {report['sample_sizes']['group1']}\")\n",
    "print(f\"   Group 2: n = {report['sample_sizes']['group2']}\")\n",
    "\n",
    "print(\"\\n2. DESCRIPTIVE STATISTICS\")\n",
    "for group in ['group1', 'group2']:\n",
    "    stats_data = report['descriptive'][group]\n",
    "    print(f\"\\n   {group.upper()}:\")\n",
    "    print(f\"   Mean ± SD: {stats_data['mean']:.2f} ± {stats_data['std']:.2f}\")\n",
    "    print(f\"   Median (IQR): {stats_data['median']:.2f} ({stats_data['iqr']:.2f})\")\n",
    "\n",
    "print(\"\\n3. ASSUMPTION TESTING\")\n",
    "for group in ['group1', 'group2']:\n",
    "    w, p = report['normality'][group]\n",
    "    print(f\"   {group.upper()} normality: p = {p:.4f} {'✓' if p > 0.05 else '✗'}\")\n",
    "_, p_levene = report['parametric']['levene']\n",
    "print(f\"   Equal variances: p = {p_levene:.4f} {'✓' if p_levene > 0.05 else '✗'}\")\n",
    "\n",
    "print(\"\\n4. STATISTICAL TESTS\")\n",
    "t_stat, p_t = report['parametric']['t_test']\n",
    "u_stat, p_u = report['nonparametric']['mann_whitney']\n",
    "print(f\"   Independent t-test: t = {t_stat:.3f}, p = {p_t:.4f}\")\n",
    "print(f\"   Mann-Whitney U: U = {u_stat:.1f}, p = {p_u:.4f}\")\n",
    "\n",
    "print(\"\\n5. EFFECT SIZE\")\n",
    "print(f\"   Cohen's d: {report['effect_size']['cohens_d']:.3f}\")\n",
    "\n",
    "print(\"\\n6. CONCLUSION\")\n",
    "if p_t < 0.05:\n",
    "    print(f\"   ✓ Statistically significant difference (p < 0.05)\")\n",
    "else:\n",
    "    print(f\"   ✗ No statistically significant difference (p ≥ 0.05)\")\n",
    "\n",
    "# Save report\n",
    "report_dict = {\n",
    "    'report': report,\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'software': 'SciTeX Statistical Analysis'\n",
    "}\n",
    "stx.io.save(report_dict, './stats/statistical_report.json')\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Report saved to: ./stats/statistical_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated key statistical analyses using SciTeX:\n",
    "\n",
    "1. **Descriptive Statistics**: Mean, median, variance, skewness, kurtosis\n",
    "2. **Hypothesis Testing**: T-tests, ANOVA, post-hoc tests\n",
    "3. **Correlation Analysis**: Pearson, Spearman, Kendall correlations\n",
    "4. **Regression Analysis**: Simple and multiple linear regression\n",
    "5. **Non-parametric Tests**: Mann-Whitney, Kruskal-Wallis, Wilcoxon\n",
    "6. **Power Analysis**: Sample size calculation and power curves\n",
    "7. **Bootstrapping**: Confidence intervals for various statistics\n",
    "8. **Report Generation**: Automated statistical reporting\n",
    "\n",
    "### Best Practices:\n",
    "\n",
    "- **Check assumptions** before applying parametric tests\n",
    "- **Report effect sizes** along with p-values\n",
    "- **Use appropriate tests** for your data distribution\n",
    "- **Consider multiple comparisons** corrections\n",
    "- **Visualize data** before and after analysis\n",
    "- **Document all analyses** for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "print(\"Statistical analysis complete!\")\n",
    "print(\"\\nFiles created:\")\n",
    "if Path('./stats').exists():\n",
    "    for f in sorted(Path('./stats').glob('*')):\n",
    "        print(f\"  - {f.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
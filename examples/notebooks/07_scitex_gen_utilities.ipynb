{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX General Utilities (gen) Module\n",
    "\n",
    "This notebook demonstrates the powerful general utilities provided by the SciTeX `gen` module. These utilities are essential for scientific computing workflows, providing functionality for:\n",
    "\n",
    "- **Environment Setup**: Reproducible experiment initialization\n",
    "- **Data Processing**: Normalization, transformation, and type handling\n",
    "- **Utility Functions**: Caching, debugging, and system interaction\n",
    "- **Workflow Management**: Project organization and metadata handling\n",
    "\n",
    "The `gen` module serves as the foundation for many scientific computing tasks in SciTeX.\n",
    "\n",
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scitex as stx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Configure SciTeX for this notebook\n",
    "stx.repro.fix_seeds(42)\n",
    "print(\"SciTeX Gen Module Demonstration\")\n",
    "print(f\"SciTeX version: {stx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Experiment Initialization\n",
    "\n",
    "The gen module provides powerful tools for setting up reproducible scientific experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a reproducible experiment environment\n",
    "# This sets up logging, random seeds, and unique IDs\n",
    "experiment_config = stx.gen.start(\n",
    "    description=\"Demo experiment with gen utilities\",\n",
    "    config_path=\"./config/demo.yaml\",  # Optional config file\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"Experiment ID: {experiment_config.ID}\")\n",
    "print(f\"Started at: {experiment_config.timestamp}\")\n",
    "print(f\"Working directory: {experiment_config.spath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Tracking and Timestamps\n",
    "\n",
    "Track execution time and create detailed timestamps for your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TimeStamper for tracking experiment progress\n",
    "ts = stx.gen.TimeStamper(is_simple=False)\n",
    "\n",
    "# Record timestamps with comments\n",
    "ts.stamp(\"Experiment started\")\n",
    "time.sleep(0.1)  # Simulate some work\n",
    "\n",
    "ts.stamp(\"Data loading phase\")\n",
    "time.sleep(0.2)  # Simulate data loading\n",
    "\n",
    "ts.stamp(\"Processing phase\")\n",
    "time.sleep(0.15)  # Simulate processing\n",
    "\n",
    "ts.stamp(\"Analysis complete\")\n",
    "\n",
    "# Display timestamp history\n",
    "print(\"Timestamp History:\")\n",
    "print(ts.get_df())\n",
    "\n",
    "# Calculate elapsed time between specific timestamps\n",
    "elapsed = ts.get_elapsed_time(0, 3)  # From first to last timestamp\n",
    "print(f\"\\nTotal elapsed time: {elapsed:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Normalization and Transformation\n",
    "\n",
    "Essential utilities for data preprocessing and normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data for demonstration\n",
    "np.random.seed(42)\n",
    "raw_data = np.random.randn(1000) * 5 + 10  # Mean=10, std=5\n",
    "outlier_data = np.concatenate([raw_data, [50, -20, 100]])  # Add outliers\n",
    "\n",
    "print(f\"Original data range: [{raw_data.min():.2f}, {raw_data.max():.2f}]\")\n",
    "print(f\"With outliers range: [{outlier_data.min():.2f}, {outlier_data.max():.2f}]\")\n",
    "\n",
    "# Various normalization techniques\n",
    "z_normalized = stx.gen.to_z(raw_data)  # Z-score normalization\n",
    "unit_normalized = stx.gen.to_01(raw_data)  # Scale to [0, 1]\n",
    "clipped_data = stx.gen.clip_perc(outlier_data, percentile=95)  # Remove outliers\n",
    "unbiased = stx.gen.unbias(raw_data)  # Remove mean bias\n",
    "\n",
    "print(f\"\\nZ-normalized: mean={z_normalized.mean():.3f}, std={z_normalized.std():.3f}\")\n",
    "print(f\"[0,1] normalized: min={unit_normalized.min():.3f}, max={unit_normalized.max():.3f}\")\n",
    "print(f\"Clipped data range: [{clipped_data.min():.2f}, {clipped_data.max():.2f}]\")\n",
    "print(f\"Unbiased data: mean={unbiased.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the normalization effects\n",
    "fig, axes = stx.plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "axes[0, 0].hist(raw_data, bins=50, alpha=0.7, color='blue')\n",
    "axes[0, 0].set_title('Original Data')\n",
    "axes[0, 0].set_xlabel('Value')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[0, 1].hist(z_normalized, bins=50, alpha=0.7, color='green')\n",
    "axes[0, 1].set_title('Z-Normalized Data')\n",
    "axes[0, 1].set_xlabel('Z-Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 0].hist(unit_normalized, bins=50, alpha=0.7, color='red')\n",
    "axes[1, 0].set_title('[0,1] Normalized Data')\n",
    "axes[1, 0].set_xlabel('Normalized Value')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 1].hist(clipped_data, bins=50, alpha=0.7, color='purple')\n",
    "axes[1, 1].set_title('Outlier-Clipped Data')\n",
    "axes[1, 1].set_xlabel('Value')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "stx.io.save(fig, './figures/normalization_comparison.png', symlink_from_cwd=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Caching and Performance Optimization\n",
    "\n",
    "Use caching to speed up expensive computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate caching with expensive computation\n",
    "@stx.gen.cache\n",
    "def expensive_computation(n):\n",
    "    \"\"\"Simulate an expensive computation.\"\"\"\n",
    "    time.sleep(0.1)  # Simulate computational delay\n",
    "    return sum(i**2 for i in range(n))\n",
    "\n",
    "# Time the first call (not cached)\n",
    "start_time = time.time()\n",
    "result1 = expensive_computation(1000)\n",
    "first_call_time = time.time() - start_time\n",
    "\n",
    "# Time the second call (cached)\n",
    "start_time = time.time()\n",
    "result2 = expensive_computation(1000)\n",
    "second_call_time = time.time() - start_time\n",
    "\n",
    "print(f\"First call result: {result1}\")\n",
    "print(f\"Second call result: {result2}\")\n",
    "print(f\"First call time: {first_call_time:.4f} seconds\")\n",
    "print(f\"Second call time: {second_call_time:.6f} seconds\")\n",
    "print(f\"Speedup: {first_call_time/second_call_time:.0f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Array and Data Type Utilities\n",
    "\n",
    "Handle different data types and array operations efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample arrays with different dimensions\n",
    "array_1d = np.random.randn(100)\n",
    "array_2d = np.random.randn(10, 20)\n",
    "array_3d = np.random.randn(5, 10, 8)\n",
    "\n",
    "# Use DimHandler for flexible dimension handling\n",
    "dim_handler = stx.gen.DimHandler()\n",
    "\n",
    "arrays = [array_1d, array_2d, array_3d]\n",
    "for i, arr in enumerate(arrays, 1):\n",
    "    print(f\"Array {i}D:\")\n",
    "    print(f\"  Shape: {arr.shape}\")\n",
    "    print(f\"  Dimensions: {arr.ndim}\")\n",
    "    print(f\"  Total elements: {arr.size}\")\n",
    "    \n",
    "    # Get variable information\n",
    "    var_info = stx.gen.var_info(arr)\n",
    "    print(f\"  Variable info: {var_info}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate array transformations\n",
    "test_array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "print(f\"Original array: {test_array}\")\n",
    "print(f\"Transposed: {stx.gen.transpose(test_array)}\")\n",
    "print(f\"To even length: {stx.gen.to_even(test_array)}\")\n",
    "print(f\"To odd length: {stx.gen.to_odd(test_array)}\")\n",
    "print(f\"To ranks: {stx.gen.to_rank(test_array)}\")\n",
    "\n",
    "# Test with different array shapes\n",
    "matrix = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"\\nOriginal matrix:\\n{matrix}\")\n",
    "print(f\"Transposed matrix:\\n{stx.gen.transpose(matrix)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. File and Path Utilities\n",
    "\n",
    "Handle file operations and path management efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample data for file operations\n",
    "sample_data = {\n",
    "    'experiment_id': 'EXP_001',\n",
    "    'parameters': {'learning_rate': 0.01, 'batch_size': 32},\n",
    "    'results': [0.85, 0.92, 0.89, 0.91]\n",
    "}\n",
    "\n",
    "# Create a temporary directory structure\n",
    "temp_dir = Path('./temp_gen_demo')\n",
    "temp_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Convert title to path format\n",
    "title = \"My Experiment Results - Analysis 2024\"\n",
    "path_name = stx.gen.title2path(title)\n",
    "print(f\"Title: {title}\")\n",
    "print(f\"Path-safe name: {path_name}\")\n",
    "\n",
    "# Create symlinks for organization\n",
    "data_file = temp_dir / f\"{path_name}.json\"\n",
    "stx.io.save(sample_data, data_file, symlink_from_cwd=True)\n",
    "\n",
    "# Create symbolic link\n",
    "link_path = temp_dir / \"latest_experiment.json\"\n",
    "stx.gen.symlink(data_file, link_path)\n",
    "\n",
    "print(f\"\\nCreated data file: {data_file}\")\n",
    "print(f\"Created symlink: {link_path}\")\n",
    "print(f\"Symlink exists: {link_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. System and Environment Utilities\n",
    "\n",
    "Interact with the system and check environment conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check execution environment\n",
    "print(f\"Running in IPython/Jupyter: {stx.gen.is_ipython()}\")\n",
    "print(f\"Running as script: {stx.gen.is_script()}\")\n",
    "\n",
    "# Check host information\n",
    "host_info = stx.gen.check_host()\n",
    "print(f\"\\nHost information:\")\n",
    "for key, value in host_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# List installed packages (first few)\n",
    "packages = stx.gen.list_packages()\n",
    "print(f\"\\nFirst 10 installed packages:\")\n",
    "for i, pkg in enumerate(packages[:10]):\n",
    "    print(f\"  {i+1}. {pkg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Utilities and Debugging\n",
    "\n",
    "Advanced features for debugging and development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate module inspection\n",
    "import numpy as np\n",
    "\n",
    "# Inspect module capabilities\n",
    "module_info = stx.gen.inspect_module(np)\n",
    "print(\"NumPy module inspection:\")\n",
    "print(f\"  Functions: {len(module_info['functions'])}\")\n",
    "print(f\"  Classes: {len(module_info['classes'])}\")\n",
    "print(f\"  Constants: {len(module_info['constants'])}\")\n",
    "\n",
    "# Show first few functions\n",
    "print(\"\\nFirst 10 functions:\")\n",
    "for func in module_info['functions'][:10]:\n",
    "    print(f\"  - {func}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate text processing utilities\n",
    "sample_text = \"This is a Sample Text for Processing\"\n",
    "\n",
    "print(f\"Original: {sample_text}\")\n",
    "print(f\"Title case: {stx.gen.title_case(sample_text)}\")\n",
    "\n",
    "# Alternative keyword arguments (useful for function flexibility)\n",
    "def flexible_function(main_param, **kwargs):\n",
    "    # Use alternate_kwarg to handle different parameter names\n",
    "    value = stx.gen.alternate_kwarg(kwargs, ['param1', 'parameter', 'p'], default=42)\n",
    "    return f\"Main: {main_param}, Flexible: {value}\"\n",
    "\n",
    "# Test with different parameter names\n",
    "result1 = flexible_function(\"test\", param1=100)\n",
    "result2 = flexible_function(\"test\", parameter=200)\n",
    "result3 = flexible_function(\"test\", p=300)\n",
    "result4 = flexible_function(\"test\")  # Uses default\n",
    "\n",
    "print(f\"\\nFlexible function results:\")\n",
    "print(f\"  With param1: {result1}\")\n",
    "print(f\"  With parameter: {result2}\")\n",
    "print(f\"  With p: {result3}\")\n",
    "print(f\"  With default: {result4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Integration Example: Complete Workflow\n",
    "\n",
    "Demonstrate how gen utilities work together in a complete scientific workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete workflow example using multiple gen utilities\n",
    "class ExperimentWorkflow:\n",
    "    def __init__(self, experiment_name):\n",
    "        self.name = experiment_name\n",
    "        self.ts = stx.gen.TimeStamper()\n",
    "        self.results = {}\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"Initialize experiment environment.\"\"\"\n",
    "        self.ts.stamp(\"Setup started\")\n",
    "        \n",
    "        # Initialize reproducible environment\n",
    "        self.config = stx.gen.start(\n",
    "            description=f\"Workflow: {self.name}\",\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        self.ts.stamp(\"Setup completed\")\n",
    "        print(f\"Experiment '{self.name}' initialized with ID: {self.config.ID}\")\n",
    "        \n",
    "    @stx.gen.cache\n",
    "    def generate_data(self, n_samples=1000):\n",
    "        \"\"\"Generate synthetic data (cached for efficiency).\"\"\"\n",
    "        self.ts.stamp(\"Data generation started\")\n",
    "        \n",
    "        # Simulate expensive data generation\n",
    "        time.sleep(0.1)\n",
    "        data = np.random.randn(n_samples, 3)\n",
    "        \n",
    "        self.ts.stamp(\"Data generation completed\")\n",
    "        return data\n",
    "        \n",
    "    def process_data(self, data):\n",
    "        \"\"\"Process and normalize data.\"\"\"\n",
    "        self.ts.stamp(\"Data processing started\")\n",
    "        \n",
    "        # Apply various normalizations\n",
    "        processed = {\n",
    "            'raw': data,\n",
    "            'z_normalized': stx.gen.to_z(data),\n",
    "            'unit_normalized': stx.gen.to_01(data),\n",
    "            'clipped': stx.gen.clip_perc(data, percentile=95)\n",
    "        }\n",
    "        \n",
    "        self.ts.stamp(\"Data processing completed\")\n",
    "        return processed\n",
    "        \n",
    "    def analyze_and_save(self, processed_data):\n",
    "        \"\"\"Analyze data and save results.\"\"\"\n",
    "        self.ts.stamp(\"Analysis started\")\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {}\n",
    "        for name, data in processed_data.items():\n",
    "            stats[name] = {\n",
    "                'mean': data.mean(axis=0),\n",
    "                'std': data.std(axis=0),\n",
    "                'shape': data.shape\n",
    "            }\n",
    "        \n",
    "        # Save results with proper naming\n",
    "        path_name = stx.gen.title2path(self.name)\n",
    "        results_file = f\"./results/{path_name}_results.json\"\n",
    "        \n",
    "        # Ensure results directory exists\n",
    "        Path(\"./results\").mkdir(exist_ok=True)\n",
    "        \n",
    "        self.results = {\n",
    "            'experiment_id': self.config.ID,\n",
    "            'timestamp': self.config.timestamp,\n",
    "            'statistics': stats,\n",
    "            'timing': self.ts.get_df().to_dict()\n",
    "        }\n",
    "        \n",
    "        stx.io.save(self.results, results_file, symlink_from_cwd=True)\n",
    "        \n",
    "        self.ts.stamp(\"Analysis completed\")\n",
    "        print(f\"Results saved to: {results_file}\")\n",
    "        \n",
    "    def run(self):\n",
    "        \"\"\"Execute complete workflow.\"\"\"\n",
    "        self.setup()\n",
    "        data = self.generate_data()\n",
    "        processed = self.process_data(data)\n",
    "        self.analyze_and_save(processed)\n",
    "        \n",
    "        # Print timing summary\n",
    "        timing_df = self.ts.get_df()\n",
    "        total_time = self.ts.get_elapsed_time(0, len(timing_df)-1)\n",
    "        \n",
    "        print(f\"\\nWorkflow completed in {total_time:.3f} seconds\")\n",
    "        print(\"\\nTiming breakdown:\")\n",
    "        print(timing_df)\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "# Run the complete workflow\n",
    "workflow = ExperimentWorkflow(\"Gen Module Demonstration\")\n",
    "results = workflow.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Best Practices\n",
    "\n",
    "The SciTeX gen module provides essential utilities for scientific computing workflows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of key gen utilities demonstrated\n",
    "summary = {\n",
    "    'Environment Setup': [\n",
    "        'stx.gen.start() - Initialize reproducible experiments',\n",
    "        'stx.gen.TimeStamper - Track execution timing',\n",
    "        'stx.repro.fix_seeds() - Ensure reproducibility'\n",
    "    ],\n",
    "    'Data Processing': [\n",
    "        'stx.gen.to_z() - Z-score normalization',\n",
    "        'stx.gen.to_01() - Unit normalization',\n",
    "        'stx.gen.clip_perc() - Outlier removal',\n",
    "        'stx.gen.unbias() - Remove mean bias'\n",
    "    ],\n",
    "    'Performance': [\n",
    "        'stx.gen.cache - Function caching decorator',\n",
    "        'Memory-efficient array operations',\n",
    "        'Optimized data transformations'\n",
    "    ],\n",
    "    'Utilities': [\n",
    "        'stx.gen.var_info() - Variable inspection',\n",
    "        'stx.gen.inspect_module() - Module analysis',\n",
    "        'stx.gen.title2path() - Safe path naming',\n",
    "        'stx.gen.symlink() - File organization'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"SciTeX Gen Module - Key Utilities Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for category, utilities in summary.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for utility in utilities:\n",
    "        print(f\"  â€¢ {utility}\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Best Practices:\")\n",
    "print(\"  â€¢ Always use stx.gen.start() at the beginning of experiments\")\n",
    "print(\"  â€¢ Apply caching to expensive computations\")\n",
    "print(\"  â€¢ Use TimeStamper for performance analysis\")\n",
    "print(\"  â€¢ Normalize data appropriately for your analysis\")\n",
    "print(\"  â€¢ Organize files with proper naming conventions\")\n",
    "print(\"  â€¢ Leverage gen utilities for reproducible workflows\")\n",
    "\n",
    "print(f\"\\nDemo completed successfully! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary files\n",
    "import shutil\n",
    "\n",
    "# Remove temporary directories\n",
    "for temp_path in ['./temp_gen_demo', './results']:\n",
    "    if Path(temp_path).exists():\n",
    "        shutil.rmtree(temp_path)\n",
    "        print(f\"Cleaned up: {temp_path}\")\n",
    "\n",
    "print(\"\\nNotebook cleanup completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
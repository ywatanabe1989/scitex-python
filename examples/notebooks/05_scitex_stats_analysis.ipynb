{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX Statistics - Comprehensive Statistical Analysis\n",
    "\n",
    "This notebook demonstrates the statistical analysis capabilities of SciTeX's stats module.\n",
    "\n",
    "The `scitex.stats` module provides:\n",
    "- Correlation and statistical tests\n",
    "- Multiple comparison corrections\n",
    "- Descriptive statistics\n",
    "- P-value formatting and interpretation\n",
    "- Advanced statistical workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scitex as stx\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# Setup\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')\n",
    "print(f\"SciTeX version: {stx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Correlation Analysis\n",
    "\n",
    "SciTeX provides enhanced correlation testing with proper statistics reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlated data with different relationships\n",
    "n_samples = 100\n",
    "x1 = np.random.randn(n_samples)\n",
    "x2 = 0.8 * x1 + 0.6 * np.random.randn(n_samples)  # Strong positive correlation\n",
    "x3 = -0.6 * x1 + 0.8 * np.random.randn(n_samples)  # Moderate negative correlation\n",
    "x4 = np.random.randn(n_samples)  # No correlation\n",
    "\n",
    "# Test correlations using SciTeX\n",
    "corr_results = {}\n",
    "correlations = [\n",
    "    ('x1 vs x2', x1, x2),\n",
    "    ('x1 vs x3', x1, x3),\n",
    "    ('x1 vs x4', x1, x4),\n",
    "    ('x2 vs x3', x2, x3)\n",
    "]\n",
    "\n",
    "print(\"Correlation Analysis Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, var1, var2 in correlations:\n",
    "    result = stx.stats.corr_test(var1, var2)\n",
    "    stars = stx.stats.p2stars(result['p'])\n",
    "    corr_results[name] = result\n",
    "    \n",
    "    print(f\"{name:12} | r = {result['r']:6.3f} | p = {result['p']:7.4f} | {stars if stars else 'ns':>3}\")\n",
    "\n",
    "print(\"\\nSignificance levels: *** p<0.001, ** p<0.01, * p<0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations\n",
    "fig, axes = stx.plt.subplots(2, 2, figsize=(10, 8))\n",
    "variables = [('x1', 'x2', x1, x2), ('x1', 'x3', x1, x3), ('x1', 'x4', x1, x4), ('x2', 'x3', x2, x3)]\n",
    "\n",
    "for ax, (name1, name2, var1, var2) in zip(axes.flat, variables):\n",
    "    # Scatter plot with regression line\n",
    "    ax.scatter(var1, var2, alpha=0.6, s=30)\n",
    "    \n",
    "    # Add regression line\n",
    "    z = np.polyfit(var1, var2, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(sorted(var1), p(sorted(var1)), \"r--\", alpha=0.8)\n",
    "    \n",
    "    # Get correlation result\n",
    "    key = f'{name1} vs {name2}'\n",
    "    result = corr_results[key]\n",
    "    stars = stx.stats.p2stars(result['p'])\n",
    "    \n",
    "    ax.set_xyt(name1, name2, f\"r = {result['r']:.3f} {stars if stars else 'ns'}\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "stx.io.save(fig, \"./figures/correlation_analysis.png\", symlink_from_cwd=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multiple Comparison Corrections\n",
    "\n",
    "When performing multiple statistical tests, correction for multiple comparisons is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple groups for comparison\n",
    "n_groups = 6\n",
    "n_per_group = 30\n",
    "\n",
    "# Create groups with different means (some significant, some not)\n",
    "groups = {\n",
    "    'Group A': np.random.normal(0, 1, n_per_group),\n",
    "    'Group B': np.random.normal(0.2, 1, n_per_group),   # Small effect\n",
    "    'Group C': np.random.normal(0.8, 1, n_per_group),   # Medium effect\n",
    "    'Group D': np.random.normal(1.2, 1, n_per_group),   # Large effect\n",
    "    'Group E': np.random.normal(0.1, 1, n_per_group),   # Very small effect\n",
    "    'Group F': np.random.normal(-0.3, 1, n_per_group),  # Small negative effect\n",
    "}\n",
    "\n",
    "# Perform all pairwise comparisons\n",
    "group_names = list(groups.keys())\n",
    "p_values = []\n",
    "comparisons = []\n",
    "effect_sizes = []\n",
    "\n",
    "for i in range(len(group_names)):\n",
    "    for j in range(i+1, len(group_names)):\n",
    "        group1, group2 = group_names[i], group_names[j]\n",
    "        data1, data2 = groups[group1], groups[group2]\n",
    "        \n",
    "        # T-test\n",
    "        t_stat, p_val = stats.ttest_ind(data1, data2)\n",
    "        \n",
    "        # Effect size (Cohen's d)\n",
    "        pooled_std = np.sqrt((np.var(data1) + np.var(data2)) / 2)\n",
    "        cohens_d = (np.mean(data2) - np.mean(data1)) / pooled_std\n",
    "        \n",
    "        comparisons.append(f\"{group1} vs {group2}\")\n",
    "        p_values.append(p_val)\n",
    "        effect_sizes.append(cohens_d)\n",
    "\n",
    "# Apply multiple comparison corrections\n",
    "p_bonferroni = stx.stats.bonferroni_correction(p_values)\n",
    "p_fdr = stx.stats.fdr_correction(p_values)\n",
    "\n",
    "print(f\"Number of comparisons: {len(comparisons)}\")\n",
    "print(f\"\\nMultiple Comparison Results:\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results table\n",
    "results_df = pd.DataFrame({\n",
    "    'Comparison': comparisons,\n",
    "    'Effect_Size': effect_sizes,\n",
    "    'P_uncorrected': p_values,\n",
    "    'P_Bonferroni': p_bonferroni,\n",
    "    'P_FDR': p_fdr,\n",
    "})\n",
    "\n",
    "# Add significance markers\n",
    "results_df['Sig_Uncorrected'] = [stx.stats.p2stars(p) if p < 0.05 else 'ns' for p in p_values]\n",
    "results_df['Sig_Bonferroni'] = [stx.stats.p2stars(p) if p < 0.05 else 'ns' for p in p_bonferroni]\n",
    "results_df['Sig_FDR'] = [stx.stats.p2stars(p) if p < 0.05 else 'ns' for p in p_fdr]\n",
    "\n",
    "# Display results\n",
    "print(\"Statistical Comparison Results:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Count significant results\n",
    "sig_uncorrected = sum([p < 0.05 for p in p_values])\n",
    "sig_bonferroni = sum([p < 0.05 for p in p_bonferroni])\n",
    "sig_fdr = sum([p < 0.05 for p in p_fdr])\n",
    "\n",
    "print(f\"\\nSignificant results:\")\n",
    "print(f\"Uncorrected: {sig_uncorrected}/{len(p_values)}\")\n",
    "print(f\"Bonferroni:  {sig_bonferroni}/{len(p_values)}\")\n",
    "print(f\"FDR:         {sig_fdr}/{len(p_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multiple comparison results\n",
    "fig, axes = stx.plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Group distributions\n",
    "ax1 = axes[0, 0]\n",
    "positions = list(range(len(groups)))\n",
    "group_data = [groups[name] for name in group_names]\n",
    "\n",
    "bp = ax1.boxplot(group_data, positions=positions, labels=group_names, patch_artist=True)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax1.set_xyt(\"Groups\", \"Values\", \"Group Distributions\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# P-value comparison\n",
    "ax2 = axes[0, 1]\n",
    "x_pos = np.arange(len(comparisons))\n",
    "ax2.scatter(x_pos, -np.log10(p_values), label='Uncorrected', alpha=0.7)\n",
    "ax2.scatter(x_pos, -np.log10(p_bonferroni), label='Bonferroni', alpha=0.7)\n",
    "ax2.scatter(x_pos, -np.log10(p_fdr), label='FDR', alpha=0.7)\n",
    "ax2.axhline(-np.log10(0.05), color='red', linestyle='--', alpha=0.7, label='p=0.05')\n",
    "ax2.set_xyt(\"Comparison Index\", \"-log10(p-value)\", \"P-value Corrections\")\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Effect sizes\n",
    "ax3 = axes[1, 0]\n",
    "colors = ['red' if abs(d) > 0.8 else 'orange' if abs(d) > 0.5 else 'green' for d in effect_sizes]\n",
    "bars = ax3.bar(range(len(effect_sizes)), effect_sizes, color=colors, alpha=0.7)\n",
    "ax3.axhline(0, color='black', linewidth=0.8)\n",
    "ax3.set_xyt(\"Comparison Index\", \"Cohen's d\", \"Effect Sizes\")\n",
    "ax3.set_xticks(range(len(comparisons)))\n",
    "ax3.set_xticklabels([c.replace(' vs ', '\\nvs\\n') for c in comparisons], rotation=45, ha='right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Significance heatmap\n",
    "ax4 = axes[1, 1]\n",
    "sig_matrix = np.array([\n",
    "    [1 if sig != 'ns' else 0 for sig in results_df['Sig_Uncorrected']],\n",
    "    [1 if sig != 'ns' else 0 for sig in results_df['Sig_Bonferroni']],\n",
    "    [1 if sig != 'ns' else 0 for sig in results_df['Sig_FDR']]\n",
    "])\n",
    "\n",
    "im = ax4.imshow(sig_matrix, cmap='RdYlBu_r', aspect='auto')\n",
    "ax4.set_xyt(\"Comparison Index\", \"\", \"Significance Matrix\")\n",
    "ax4.set_yticks([0, 1, 2])\n",
    "ax4.set_yticklabels(['Uncorrected', 'Bonferroni', 'FDR'])\n",
    "ax4.set_xticks(range(len(comparisons)))\n",
    "ax4.set_xticklabels(range(len(comparisons)))\n",
    "\n",
    "plt.tight_layout()\n",
    "stx.io.save(fig, \"./figures/multiple_comparisons.png\", symlink_from_cwd=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descriptive Statistics\n",
    "\n",
    "Comprehensive descriptive analysis with SciTeX utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic dataset\n",
    "n_subjects = 200\n",
    "np.random.seed(123)\n",
    "\n",
    "# Simulate experimental data\n",
    "data = {\n",
    "    'age': np.random.normal(35, 10, n_subjects).clip(18, 80),\n",
    "    'reaction_time': np.random.lognormal(np.log(300), 0.3, n_subjects),  # Skewed\n",
    "    'accuracy': np.random.beta(8, 2, n_subjects),  # Bounded [0,1]\n",
    "    'score': np.random.normal(75, 15, n_subjects).clip(0, 100),\n",
    "    'group': np.random.choice(['Control', 'Treatment'], n_subjects),\n",
    "    'session': np.random.choice(['Session1', 'Session2', 'Session3'], n_subjects)\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = stx.pd.force_df(data)\n",
    "\n",
    "# Add some missing values to make it realistic\n",
    "missing_idx = np.random.choice(n_subjects, 10, replace=False)\n",
    "df.loc[missing_idx, 'reaction_time'] = np.nan\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive descriptive statistics\n",
    "numeric_vars = ['age', 'reaction_time', 'accuracy', 'score']\n",
    "\n",
    "print(\"Descriptive Statistics Summary:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "desc_stats = {}\n",
    "for var in numeric_vars:\n",
    "    data_clean = df[var].dropna()\n",
    "    \n",
    "    stats_dict = {\n",
    "        'count': len(data_clean),\n",
    "        'mean': np.mean(data_clean),\n",
    "        'std': np.std(data_clean, ddof=1),\n",
    "        'min': np.min(data_clean),\n",
    "        'q25': np.percentile(data_clean, 25),\n",
    "        'median': np.median(data_clean),\n",
    "        'q75': np.percentile(data_clean, 75),\n",
    "        'max': np.max(data_clean),\n",
    "        'skewness': stats.skew(data_clean),\n",
    "        'kurtosis': stats.kurtosis(data_clean)\n",
    "    }\n",
    "    \n",
    "    desc_stats[var] = stats_dict\n",
    "    \n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    print(f\"  N = {stats_dict['count']}, Mean = {stats_dict['mean']:.2f} Â± {stats_dict['std']:.2f}\")\n",
    "    print(f\"  Median = {stats_dict['median']:.2f} [Q1={stats_dict['q25']:.2f}, Q3={stats_dict['q75']:.2f}]\")\n",
    "    print(f\"  Range = [{stats_dict['min']:.2f}, {stats_dict['max']:.2f}]\")\n",
    "    print(f\"  Skewness = {stats_dict['skewness']:.3f}, Kurtosis = {stats_dict['kurtosis']:.3f}\")\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "desc_df = stx.pd.force_df(desc_stats).T\n",
    "print(f\"\\nComplete descriptive statistics table:\")\n",
    "print(desc_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions and descriptive statistics\n",
    "fig, axes = stx.plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i, var in enumerate(numeric_vars):\n",
    "    data_clean = df[var].dropna()\n",
    "    \n",
    "    # Histogram with normal curve overlay\n",
    "    ax1 = axes[0, i]\n",
    "    n, bins, patches = ax1.hist(data_clean, bins=20, alpha=0.7, density=True, color='skyblue')\n",
    "    \n",
    "    # Overlay normal distribution\n",
    "    mu, sigma = np.mean(data_clean), np.std(data_clean)\n",
    "    x = np.linspace(data_clean.min(), data_clean.max(), 100)\n",
    "    ax1.plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Normal fit')\n",
    "    \n",
    "    ax1.axvline(mu, color='red', linestyle='--', alpha=0.7, label=f'Mean={mu:.1f}')\n",
    "    ax1.axvline(np.median(data_clean), color='orange', linestyle='--', alpha=0.7, label=f'Median={np.median(data_clean):.1f}')\n",
    "    \n",
    "    ax1.set_xyt(var.replace('_', ' ').title(), 'Density', f'{var.title()} Distribution')\n",
    "    ax1.legend(fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Q-Q plot for normality assessment\n",
    "    ax2 = axes[1, i]\n",
    "    stats.probplot(data_clean, dist=\"norm\", plot=ax2)\n",
    "    ax2.set_xyt('Theoretical Quantiles', 'Sample Quantiles', f'{var.title()} Q-Q Plot')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "stx.io.save(fig, \"./figures/descriptive_statistics.png\", symlink_from_cwd=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Group Comparisons and ANOVA\n",
    "\n",
    "Comparing groups with proper effect size reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare groups using various statistical tests\n",
    "print(\"Group Comparison Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Two-group comparisons\n",
    "for var in ['reaction_time', 'accuracy', 'score']:\n",
    "    control_data = df[df['group'] == 'Control'][var].dropna()\n",
    "    treatment_data = df[df['group'] == 'Treatment'][var].dropna()\n",
    "    \n",
    "    # T-test\n",
    "    t_stat, p_ttest = stats.ttest_ind(control_data, treatment_data)\n",
    "    \n",
    "    # Mann-Whitney U test (non-parametric)\n",
    "    u_stat, p_mann = stats.mannwhitneyu(control_data, treatment_data, alternative='two-sided')\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(control_data)-1)*np.var(control_data, ddof=1) + \n",
    "                         (len(treatment_data)-1)*np.var(treatment_data, ddof=1)) / \n",
    "                        (len(control_data) + len(treatment_data) - 2))\n",
    "    cohens_d = (np.mean(treatment_data) - np.mean(control_data)) / pooled_std\n",
    "    \n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    print(f\"  Control:   {np.mean(control_data):.2f} Â± {np.std(control_data, ddof=1):.2f} (n={len(control_data)})\")\n",
    "    print(f\"  Treatment: {np.mean(treatment_data):.2f} Â± {np.std(treatment_data, ddof=1):.2f} (n={len(treatment_data)})\")\n",
    "    print(f\"  T-test:    t = {t_stat:.3f}, p = {p_ttest:.4f} {stx.stats.p2stars(p_ttest)}\")\n",
    "    print(f\"  Mann-Whitney: U = {u_stat:.1f}, p = {p_mann:.4f} {stx.stats.p2stars(p_mann)}\")\n",
    "    print(f\"  Effect size: Cohen's d = {cohens_d:.3f}\")\n",
    "    \n",
    "    # Interpret effect size\n",
    "    if abs(cohens_d) < 0.2:\n",
    "        effect_interp = \"negligible\"\n",
    "    elif abs(cohens_d) < 0.5:\n",
    "        effect_interp = \"small\"\n",
    "    elif abs(cohens_d) < 0.8:\n",
    "        effect_interp = \"medium\"\n",
    "    else:\n",
    "        effect_interp = \"large\"\n",
    "    \n",
    "    print(f\"  Interpretation: {effect_interp} effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-way ANOVA for session effects\n",
    "print(\"\\nOne-way ANOVA - Session Effects:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for var in ['reaction_time', 'accuracy', 'score']:\n",
    "    # Prepare data for ANOVA\n",
    "    session_groups = []\n",
    "    for session in ['Session1', 'Session2', 'Session3']:\n",
    "        session_data = df[df['session'] == session][var].dropna()\n",
    "        session_groups.append(session_data)\n",
    "    \n",
    "    # Perform ANOVA\n",
    "    f_stat, p_anova = stats.f_oneway(*session_groups)\n",
    "    \n",
    "    # Calculate eta-squared (effect size for ANOVA)\n",
    "    all_data = np.concatenate(session_groups)\n",
    "    grand_mean = np.mean(all_data)\n",
    "    \n",
    "    ss_between = sum([len(group) * (np.mean(group) - grand_mean)**2 for group in session_groups])\n",
    "    ss_total = sum([(x - grand_mean)**2 for x in all_data])\n",
    "    eta_squared = ss_between / ss_total\n",
    "    \n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    for i, session in enumerate(['Session1', 'Session2', 'Session3']):\n",
    "        group_data = session_groups[i]\n",
    "        print(f\"  {session}: {np.mean(group_data):.2f} Â± {np.std(group_data, ddof=1):.2f} (n={len(group_data)})\")\n",
    "    \n",
    "    print(f\"  F({len(session_groups)-1}, {len(all_data)-len(session_groups)}) = {f_stat:.3f}\")\n",
    "    print(f\"  p = {p_anova:.4f} {stx.stats.p2stars(p_anova)}\")\n",
    "    print(f\"  Î·Â² = {eta_squared:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize group comparisons\n",
    "fig, axes = stx.plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Group comparisons (Control vs Treatment)\n",
    "for i, var in enumerate(['reaction_time', 'accuracy', 'score']):\n",
    "    ax = axes[0, i]\n",
    "    \n",
    "    # Box plots\n",
    "    control_data = df[df['group'] == 'Control'][var].dropna()\n",
    "    treatment_data = df[df['group'] == 'Treatment'][var].dropna()\n",
    "    \n",
    "    bp = ax.boxplot([control_data, treatment_data], \n",
    "                    labels=['Control', 'Treatment'],\n",
    "                    patch_artist=True)\n",
    "    \n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    bp['boxes'][1].set_facecolor('lightcoral')\n",
    "    \n",
    "    # Add statistical annotation\n",
    "    t_stat, p_val = stats.ttest_ind(control_data, treatment_data)\n",
    "    stars = stx.stats.p2stars(p_val)\n",
    "    \n",
    "    y_max = max(control_data.max(), treatment_data.max())\n",
    "    y_pos = y_max * 1.1\n",
    "    ax.plot([1, 2], [y_pos, y_pos], 'k-', linewidth=1)\n",
    "    ax.text(1.5, y_pos*1.02, f'p = {p_val:.3f} {stars if stars else \"ns\"}', \n",
    "            ha='center', va='bottom')\n",
    "    \n",
    "    ax.set_xyt('Group', var.replace('_', ' ').title(), f'{var.title()} by Group')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Session comparisons (ANOVA)\n",
    "for i, var in enumerate(['reaction_time', 'accuracy', 'score']):\n",
    "    ax = axes[1, i]\n",
    "    \n",
    "    # Box plots for sessions\n",
    "    session_data = []\n",
    "    for session in ['Session1', 'Session2', 'Session3']:\n",
    "        session_data.append(df[df['session'] == session][var].dropna())\n",
    "    \n",
    "    bp = ax.boxplot(session_data, labels=['S1', 'S2', 'S3'], patch_artist=True)\n",
    "    \n",
    "    colors = ['lightgreen', 'lightyellow', 'lightpink']\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    # Add ANOVA results\n",
    "    f_stat, p_anova = stats.f_oneway(*session_data)\n",
    "    stars = stx.stats.p2stars(p_anova)\n",
    "    \n",
    "    ax.set_xyt('Session', var.replace('_', ' ').title(), \n",
    "               f'{var.title()} by Session\\nF = {f_stat:.2f}, p = {p_anova:.3f} {stars if stars else \"ns\"}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "stx.io.save(fig, \"./figures/group_comparisons.png\", symlink_from_cwd=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Statistical Tests\n",
    "\n",
    "Specialized tests for different data types and distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for normality\n",
    "print(\"Normality Tests:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for var in numeric_vars:\n",
    "    data_clean = df[var].dropna()\n",
    "    \n",
    "    # Shapiro-Wilk test\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(data_clean)\n",
    "    \n",
    "    # Anderson-Darling test\n",
    "    ad_stat, ad_crit, ad_sig = stats.anderson(data_clean, dist='norm')\n",
    "    \n",
    "    # Kolmogorov-Smirnov test\n",
    "    ks_stat, ks_p = stats.kstest(data_clean, 'norm', \n",
    "                                args=(np.mean(data_clean), np.std(data_clean, ddof=1)))\n",
    "    \n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    print(f\"  Shapiro-Wilk:  W = {shapiro_stat:.4f}, p = {shapiro_p:.4f} {stx.stats.p2stars(shapiro_p)}\")\n",
    "    print(f\"  Kolmogorov-S:  D = {ks_stat:.4f}, p = {ks_p:.4f} {stx.stats.p2stars(ks_p)}\")\n",
    "    print(f\"  Anderson-D:    AÂ² = {ad_stat:.4f}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if shapiro_p < 0.05:\n",
    "        norm_interp = \"Non-normal distribution\"\n",
    "    else:\n",
    "        norm_interp = \"Approximately normal\"\n",
    "    print(f\"  Interpretation: {norm_interp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogeneity of variance tests\n",
    "print(\"\\nHomogeneity of Variance Tests:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for var in ['reaction_time', 'accuracy', 'score']:\n",
    "    # Group data\n",
    "    control_data = df[df['group'] == 'Control'][var].dropna()\n",
    "    treatment_data = df[df['group'] == 'Treatment'][var].dropna()\n",
    "    \n",
    "    # Levene's test\n",
    "    levene_stat, levene_p = stats.levene(control_data, treatment_data)\n",
    "    \n",
    "    # Bartlett's test (assumes normality)\n",
    "    bartlett_stat, bartlett_p = stats.bartlett(control_data, treatment_data)\n",
    "    \n",
    "    # F-test for equal variances\n",
    "    f_ratio = np.var(treatment_data, ddof=1) / np.var(control_data, ddof=1)\n",
    "    df1, df2 = len(treatment_data) - 1, len(control_data) - 1\n",
    "    f_p = 2 * min(stats.f.cdf(f_ratio, df1, df2), 1 - stats.f.cdf(f_ratio, df1, df2))\n",
    "    \n",
    "    print(f\"\\n{var.upper()}:\")\n",
    "    print(f\"  Control variance:   {np.var(control_data, ddof=1):.3f}\")\n",
    "    print(f\"  Treatment variance: {np.var(treatment_data, ddof=1):.3f}\")\n",
    "    print(f\"  Levene's test:  W = {levene_stat:.4f}, p = {levene_p:.4f} {stx.stats.p2stars(levene_p)}\")\n",
    "    print(f\"  Bartlett's test: Ï‡Â² = {bartlett_stat:.4f}, p = {bartlett_p:.4f} {stx.stats.p2stars(bartlett_p)}\")\n",
    "    print(f\"  F-test:         F = {f_ratio:.4f}, p = {f_p:.4f} {stx.stats.p2stars(f_p)}\")\n",
    "    \n",
    "    if levene_p < 0.05:\n",
    "        var_interp = \"Unequal variances\"\n",
    "    else:\n",
    "        var_interp = \"Equal variances\"\n",
    "    print(f\"  Interpretation: {var_interp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection and Robust Statistics\n",
    "\n",
    "Identifying outliers and using robust statistical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using multiple methods\n",
    "print(\"Outlier Detection Analysis:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "outlier_results = {}\n",
    "\n",
    "for var in ['reaction_time', 'accuracy', 'score']:\n",
    "    data_clean = df[var].dropna()\n",
    "    \n",
    "    # Method 1: IQR method\n",
    "    Q1 = np.percentile(data_clean, 25)\n",
    "    Q3 = np.percentile(data_clean, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    iqr_outliers = data_clean[(data_clean < lower_bound) | (data_clean > upper_bound)]\n",
    "    \n",
    "    # Method 2: Z-score method\n",
    "    z_scores = np.abs(stats.zscore(data_clean))\n",
    "    zscore_outliers = data_clean[z_scores > 2.5]\n",
    "    \n",
    "    # Method 3: Modified Z-score (using median)\n",
    "    median = np.median(data_clean)\n",
    "    mad = np.median(np.abs(data_clean - median))\n",
    "    modified_z_scores = 0.6745 * (data_clean - median) / mad\n",
    "    mod_zscore_outliers = data_clean[np.abs(modified_z_scores) > 3.5]\n",
    "    \n",
    "    outlier_results[var] = {\n",
    "        'iqr': len(iqr_outliers),\n",
    "        'zscore': len(zscore_outliers),\n",
    "        'mod_zscore': len(mod_zscore_outliers)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{var.upper()} (n={len(data_clean)}):\")\n",
    "    print(f\"  IQR method:           {len(iqr_outliers)} outliers ({len(iqr_outliers)/len(data_clean)*100:.1f}%)\")\n",
    "    print(f\"  Z-score (|z| > 2.5):  {len(zscore_outliers)} outliers ({len(zscore_outliers)/len(data_clean)*100:.1f}%)\")\n",
    "    print(f\"  Modified Z-score:     {len(mod_zscore_outliers)} outliers ({len(mod_zscore_outliers)/len(data_clean)*100:.1f}%)\")\n",
    "    \n",
    "    # Robust vs classical statistics\n",
    "    classical_mean = np.mean(data_clean)\n",
    "    classical_std = np.std(data_clean, ddof=1)\n",
    "    robust_median = np.median(data_clean)\n",
    "    robust_mad = 1.4826 * mad  # Scale MAD to estimate std\n",
    "    \n",
    "    print(f\"  Classical: Mean = {classical_mean:.2f}, SD = {classical_std:.2f}\")\n",
    "    print(f\"  Robust:    Median = {robust_median:.2f}, MAD = {robust_mad:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize outliers\n",
    "fig, axes = stx.plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "for i, var in enumerate(['reaction_time', 'accuracy', 'score']):\n",
    "    data_clean = df[var].dropna()\n",
    "    \n",
    "    # Box plot showing outliers\n",
    "    ax1 = axes[0, i]\n",
    "    bp = ax1.boxplot(data_clean, patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    \n",
    "    # Mark statistical outliers\n",
    "    Q1 = np.percentile(data_clean, 25)\n",
    "    Q3 = np.percentile(data_clean, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data_clean[(data_clean < lower_bound) | (data_clean > upper_bound)]\n",
    "    if len(outliers) > 0:\n",
    "        ax1.scatter([1] * len(outliers), outliers, color='red', s=30, alpha=0.7)\n",
    "    \n",
    "    ax1.set_xyt('', var.replace('_', ' ').title(), f'{var.title()} - Box Plot')\n",
    "    ax1.set_xticks([])\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Z-score plot\n",
    "    ax2 = axes[1, i]\n",
    "    z_scores = np.abs(stats.zscore(data_clean))\n",
    "    colors = ['red' if z > 2.5 else 'blue' for z in z_scores]\n",
    "    ax2.scatter(range(len(z_scores)), z_scores, c=colors, alpha=0.6, s=20)\n",
    "    ax2.axhline(y=2.5, color='red', linestyle='--', alpha=0.7, label='|z| = 2.5')\n",
    "    ax2.axhline(y=3, color='orange', linestyle='--', alpha=0.7, label='|z| = 3')\n",
    "    \n",
    "    ax2.set_xyt('Sample Index', '|Z-score|', f'{var.title()} - Z-scores')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "stx.io.save(fig, \"./figures/outlier_detection.png\", symlink_from_cwd=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Statistical Power Analysis\n",
    "\n",
    "Sample size and power calculations for study design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power analysis for different effect sizes\n",
    "from scipy.stats import norm\n",
    "\n",
    "def power_ttest(n, effect_size, alpha=0.05):\n",
    "    \"\"\"Calculate power for two-sample t-test.\"\"\"\n",
    "    # Critical t-value\n",
    "    df = 2 * n - 2\n",
    "    t_crit = stats.t.ppf(1 - alpha/2, df)\n",
    "    \n",
    "    # Non-centrality parameter\n",
    "    ncp = effect_size * np.sqrt(n/2)\n",
    "    \n",
    "    # Power calculation\n",
    "    power = 1 - stats.nct.cdf(t_crit, df, ncp) + stats.nct.cdf(-t_crit, df, ncp)\n",
    "    return power\n",
    "\n",
    "def sample_size_ttest(effect_size, power=0.8, alpha=0.05):\n",
    "    \"\"\"Calculate required sample size for desired power.\"\"\"\n",
    "    # Approximate sample size calculation\n",
    "    z_alpha = norm.ppf(1 - alpha/2)\n",
    "    z_beta = norm.ppf(power)\n",
    "    n = 2 * ((z_alpha + z_beta) / effect_size) ** 2\n",
    "    return int(np.ceil(n))\n",
    "\n",
    "print(\"Statistical Power Analysis:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Effect sizes\n",
    "effect_sizes = [0.2, 0.5, 0.8, 1.0, 1.2]  # Small, medium, large, very large\n",
    "sample_sizes = [10, 20, 30, 50, 100, 200]\n",
    "\n",
    "print(\"\\nPower for different combinations:\")\n",
    "print(\"Effect Size | Sample Size | Power\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "power_matrix = np.zeros((len(effect_sizes), len(sample_sizes)))\n",
    "\n",
    "for i, es in enumerate(effect_sizes):\n",
    "    for j, n in enumerate(sample_sizes):\n",
    "        power = power_ttest(n, es)\n",
    "        power_matrix[i, j] = power\n",
    "        if j < 3:  # Print only first few for readability\n",
    "            print(f\"{es:11.1f} | {n:11d} | {power:5.3f}\")\n",
    "\n",
    "print(\"\\nRequired sample sizes for 80% power:\")\n",
    "print(\"Effect Size | Required N per group\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for es in effect_sizes:\n",
    "    required_n = sample_size_ttest(es, power=0.8)\n",
    "    print(f\"{es:11.1f} | {required_n:18d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize power analysis\n",
    "fig, axes = stx.plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Power curves\n",
    "ax1 = axes[0]\n",
    "for i, es in enumerate(effect_sizes):\n",
    "    powers = power_matrix[i, :]\n",
    "    ax1.plot(sample_sizes, powers, 'o-', label=f'd = {es}', linewidth=2, markersize=6)\n",
    "\n",
    "ax1.axhline(y=0.8, color='red', linestyle='--', alpha=0.7, label='80% Power')\n",
    "ax1.set_xyt('Sample Size (per group)', 'Statistical Power', 'Power Curves for T-test')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Sample size requirements\n",
    "ax2 = axes[1]\n",
    "required_ns = [sample_size_ttest(es, power=0.8) for es in effect_sizes]\n",
    "bars = ax2.bar(range(len(effect_sizes)), required_ns, \n",
    "               color=['lightcoral', 'orange', 'lightgreen', 'lightblue', 'purple'],\n",
    "               alpha=0.7)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, n) in enumerate(zip(bars, required_ns)):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "             str(n), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "ax2.set_xyt('Effect Size', 'Required Sample Size\\n(per group)', 'Sample Size for 80% Power')\n",
    "ax2.set_xticks(range(len(effect_sizes)))\n",
    "ax2.set_xticklabels([f'{es}' for es in effect_sizes])\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "stx.io.save(fig, \"./figures/power_analysis.png\", symlink_from_cwd=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the comprehensive statistical analysis capabilities of SciTeX:\n",
    "\n",
    "### Key Features Covered:\n",
    "\n",
    "1. **Correlation Analysis**: Enhanced correlation testing with significance formatting\n",
    "2. **Multiple Comparisons**: Bonferroni and FDR corrections for multiple testing\n",
    "3. **Descriptive Statistics**: Comprehensive summary statistics with distribution analysis\n",
    "4. **Group Comparisons**: T-tests, Mann-Whitney U, and ANOVA with effect sizes\n",
    "5. **Advanced Tests**: Normality testing, homogeneity of variance assessment\n",
    "6. **Outlier Detection**: Multiple methods for identifying and handling outliers\n",
    "7. **Power Analysis**: Sample size and power calculations for study design\n",
    "\n",
    "### SciTeX Statistics Advantages:\n",
    "\n",
    "- **Standardized reporting** with p-value stars and effect sizes\n",
    "- **Comprehensive test batteries** for assumptions and robustness\n",
    "- **Integrated visualization** with statistical annotations\n",
    "- **Publication-ready outputs** with proper statistical formatting\n",
    "- **Multiple comparison awareness** built into workflows\n",
    "\n",
    "### Best Practices Demonstrated:\n",
    "\n",
    "- Always check assumptions (normality, homogeneity of variance)\n",
    "- Report effect sizes alongside p-values\n",
    "- Use appropriate corrections for multiple comparisons\n",
    "- Consider robust alternatives when assumptions are violated\n",
    "- Perform power analysis for proper study design\n",
    "\n",
    "### Next Steps:\n",
    "- Explore `scitex.ai` for machine learning approaches to statistical analysis\n",
    "- Use `scitex.plt` for advanced statistical visualization\n",
    "- Check `scitex.pd` for data manipulation and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all statistical results\n",
    "statistical_summary = {\n",
    "    'descriptive_statistics': desc_df.to_dict(),\n",
    "    'correlation_results': {k: v for k, v in corr_results.items()},\n",
    "    'multiple_comparisons': results_df.to_dict(),\n",
    "    'outlier_detection': outlier_results,\n",
    "    'power_analysis': {\n",
    "        'effect_sizes': effect_sizes,\n",
    "        'required_sample_sizes': required_ns,\n",
    "        'power_matrix': power_matrix.tolist()\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'n_subjects': len(df),\n",
    "        'variables': list(df.columns),\n",
    "        'missing_values': df.isnull().sum().to_dict()\n",
    "    }\n",
    "}\n",
    "\n",
    "stx.io.save(statistical_summary, \"./data/statistical_analysis_summary.json\", symlink_from_cwd=True)\n",
    "stx.io.save(df, \"./data/analysis_dataset.csv\", symlink_from_cwd=True)\n",
    "\n",
    "print(\"\\nâœ… Statistical analysis complete!\")\n",
    "print(\"ðŸ“Š Results saved to ./data/statistical_analysis_summary.json\")\n",
    "print(\"ðŸ“ˆ Figures saved to ./figures/\")\n",
    "print(\"ðŸ”¬ Dataset saved to ./data/analysis_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
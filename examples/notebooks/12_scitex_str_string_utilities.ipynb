{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciTeX String Utilities (str) Module\n",
    "\n",
    "This notebook demonstrates the powerful string manipulation utilities provided by the SciTeX `str` module. These utilities are essential for scientific computing tasks involving:\n",
    "\n",
    "- **Text Formatting**: Color coding, formatting for terminal output\n",
    "- **Scientific Notation**: LaTeX rendering, mathematical formatting\n",
    "- **Plot Text**: Axis labels, titles, and scientific text formatting\n",
    "- **Path Operations**: Clean path strings, remove special characters\n",
    "- **Search and Replace**: Pattern matching, text manipulation\n",
    "- **API Security**: Mask sensitive information in logs\n",
    "\n",
    "The str module provides specialized string operations tailored for scientific computing and publication-ready output.\n",
    "\n",
    "## Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scitex as stx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Configure SciTeX for this notebook\n",
    "stx.repro.fix_seeds(42)\n",
    "print(\"SciTeX String Utilities (str) Module Demonstration\")\n",
    "print(f\"SciTeX version: {stx.__version__}\")\n",
    "\n",
    "# Create working directory\n",
    "work_dir = Path('./temp_str_demo')\n",
    "work_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Coloring and Terminal Output\n",
    "\n",
    "Format text with colors for better visibility in terminal output and logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate text coloring\n",
    "print(\"=== Text Coloring and Formatting ===\")\n",
    "\n",
    "# Basic color formatting\n",
    "print(\"\\n1. Basic color formatting:\")\n",
    "print(stx.str.color_text(\"SUCCESS: Experiment completed\", \"green\"))\n",
    "print(stx.str.color_text(\"WARNING: Memory usage high\", \"yellow\"))\n",
    "print(stx.str.color_text(\"ERROR: File not found\", \"red\"))\n",
    "print(stx.str.color_text(\"INFO: Processing data...\", \"blue\"))\n",
    "\n",
    "# Shorthand color text function\n",
    "print(\"\\n2. Using shorthand ct() function:\")\n",
    "print(stx.str.ct(\"âœ“ Test passed\", \"green\"))\n",
    "print(stx.str.ct(\"âš  Check results\", \"yellow\"))\n",
    "print(stx.str.ct(\"âœ— Test failed\", \"red\"))\n",
    "\n",
    "# Color coding for scientific results\n",
    "print(\"\\n3. Scientific result formatting:\")\n",
    "p_value = 0.003\n",
    "if p_value < 0.001:\n",
    "    result = stx.str.color_text(f\"p < 0.001 ***\", \"green\")\n",
    "elif p_value < 0.01:\n",
    "    result = stx.str.color_text(f\"p = {p_value:.3f} **\", \"green\")\n",
    "elif p_value < 0.05:\n",
    "    result = stx.str.color_text(f\"p = {p_value:.3f} *\", \"yellow\")\n",
    "else:\n",
    "    result = stx.str.color_text(f\"p = {p_value:.3f} (n.s.)\", \"gray\")\n",
    "print(f\"Statistical significance: {result}\")\n",
    "\n",
    "# Remove ANSI codes for file output\n",
    "colored_text = stx.str.color_text(\"This is colored text\", \"blue\")\n",
    "clean_text = stx.str.remove_ansi(colored_text)\n",
    "print(f\"\\n4. ANSI removal:\")\n",
    "print(f\"   With color codes: {repr(colored_text[:20])}...\")\n",
    "print(f\"   Clean text: {repr(clean_text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scientific and LaTeX Text Formatting\n",
    "\n",
    "Format mathematical expressions and scientific notation for publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate LaTeX formatting\n",
    "print(\"=== LaTeX and Scientific Text Formatting ===\")\n",
    "\n",
    "# Convert to LaTeX style\n",
    "print(\"\\n1. LaTeX style conversion:\")\n",
    "variable_names = ['alpha', 'beta', 'gamma', 'theta', 'lambda']\n",
    "for var in variable_names:\n",
    "    latex_var = stx.str.to_latex_style(var)\n",
    "    print(f\"   {var} â†’ {latex_var}\")\n",
    "\n",
    "# Add hats for vectors/estimators\n",
    "print(\"\\n2. Adding hats for vectors/estimators:\")\n",
    "estimators = ['x', 'theta', 'beta']\n",
    "for est in estimators:\n",
    "    hat_est = stx.str.add_hat_in_latex_style(est)\n",
    "    print(f\"   {est} â†’ {hat_est}\")\n",
    "\n",
    "# Safe LaTeX conversion with fallback\n",
    "print(\"\\n3. Safe LaTeX rendering with fallback:\")\n",
    "expressions = [\n",
    "    r\"\\alpha + \\beta\",\n",
    "    r\"\\sum_{i=1}^{n} x_i\",\n",
    "    r\"\\frac{\\partial f}{\\partial x}\",\n",
    "    r\"\\int_{0}^{\\infty} e^{-x} dx\"\n",
    "]\n",
    "\n",
    "for expr in expressions:\n",
    "    safe_expr = stx.str.safe_latex_render(expr)\n",
    "    print(f\"   {expr} â†’ {safe_expr}\")\n",
    "\n",
    "# Scientific text formatting\n",
    "print(\"\\n4. Scientific text formatting:\")\n",
    "numbers = [1234567, 0.00012345, 1.23e-15, 9.87e23]\n",
    "for num in numbers:\n",
    "    sci_text = stx.str.scientific_text(f\"{num:.3e}\")\n",
    "    print(f\"   {num} â†’ {sci_text}\")\n",
    "\n",
    "# Check LaTeX capability\n",
    "print(\"\\n5. LaTeX system check:\")\n",
    "latex_status = stx.str.get_latex_status()\n",
    "print(f\"   LaTeX available: {latex_status['available']}\")\n",
    "print(f\"   Fallback mode: {latex_status['fallback_mode']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot Text Formatting\n",
    "\n",
    "Format axis labels, titles, and scientific notation for publication-quality plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate plot text formatting\n",
    "print(\"=== Plot Text Formatting ===\")\n",
    "\n",
    "# Format axis labels with units\n",
    "print(\"\\n1. Axis label formatting:\")\n",
    "axis_examples = [\n",
    "    ('time', 's', 'Time'),\n",
    "    ('frequency', 'Hz', 'Frequency'),\n",
    "    ('power', 'mW', 'Power'),\n",
    "    ('voltage', 'ÂµV', 'Voltage'),\n",
    "    ('temperature', 'Â°C', 'Temperature')\n",
    "]\n",
    "\n",
    "for var, unit, label in axis_examples:\n",
    "    formatted_label = stx.str.format_axis_label(label, unit)\n",
    "    print(f\"   {label} with unit {unit} â†’ {formatted_label}\")\n",
    "\n",
    "# Format plot titles\n",
    "print(\"\\n2. Plot title formatting:\")\n",
    "titles = [\n",
    "    \"neural_network_accuracy_vs_epochs\",\n",
    "    \"power_spectral_density_analysis\",\n",
    "    \"correlation_matrix_features\"\n",
    "]\n",
    "\n",
    "for title in titles:\n",
    "    formatted = stx.str.format_title(title)\n",
    "    print(f\"   {title}\")\n",
    "    print(f\"   â†’ {formatted}\")\n",
    "\n",
    "# Smart tick formatting for large numbers\n",
    "print(\"\\n3. Smart tick formatting:\")\n",
    "large_numbers = [1000, 1000000, 1500000, 2.5e9, 3.7e12]\n",
    "formatter = stx.str.smart_tick_formatter()\n",
    "\n",
    "for num in large_numbers:\n",
    "    formatted = formatter(num)\n",
    "    print(f\"   {num} â†’ {formatted}\")\n",
    "\n",
    "# Create example plot with formatted text\n",
    "print(\"\\n4. Example plot with formatted text:\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Generate sample data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = 1e6 * np.exp(-x/3) * np.sin(2*np.pi*x)\n",
    "\n",
    "ax.plot(x, y)\n",
    "ax.set_xlabel(stx.str.format_axis_label('Time', 's'))\n",
    "ax.set_ylabel(stx.str.format_axis_label('Amplitude', 'ÂµV'))\n",
    "ax.set_title(stx.str.format_title('exponential_decay_oscillation'))\n",
    "\n",
    "# Use smart tick formatter for y-axis\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(stx.str.smart_tick_formatter()))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(work_dir / 'formatted_plot.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"   Plot saved with formatted labels and smart tick formatting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Path String Operations\n",
    "\n",
    "Clean and manipulate path strings for cross-platform compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate path string operations\n",
    "print(\"=== Path String Operations ===\")\n",
    "\n",
    "# Clean path strings\n",
    "print(\"\\n1. Path cleaning:\")\n",
    "messy_paths = [\n",
    "    \"./data//raw/../processed/file.csv\",\n",
    "    \"C:\\\\Users\\\\Name\\\\Documents\\\\..\\\\Projects\\\\data.txt\",\n",
    "    \"/home/user//project/./scripts/../results/output.png\",\n",
    "    \"data\\\\experiments\\\\\\\\trial_01\\\\\\\\results.json\"\n",
    "]\n",
    "\n",
    "for path in messy_paths:\n",
    "    cleaned = stx.str.clean_path(path)\n",
    "    print(f\"   Original: {path}\")\n",
    "    print(f\"   Cleaned:  {cleaned}\")\n",
    "    print()\n",
    "\n",
    "# Extract components from paths\n",
    "print(\"2. Path component extraction using string operations:\")\n",
    "file_paths = [\n",
    "    \"experiments/2024_03_15/results/accuracy_plot.png\",\n",
    "    \"data/processed/subject_001_session_02.csv\",\n",
    "    \"models/neural_network_v2.3.pkl\"\n",
    "]\n",
    "\n",
    "for path in file_paths:\n",
    "    # Extract meaningful parts using string operations\n",
    "    parts = path.split('/')\n",
    "    filename = parts[-1]\n",
    "    name_parts = filename.split('.')\n",
    "    base_name = name_parts[0]\n",
    "    extension = name_parts[-1] if len(name_parts) > 1 else ''\n",
    "    \n",
    "    print(f\"   Path: {path}\")\n",
    "    print(f\"   Base name: {base_name}\")\n",
    "    print(f\"   Extension: {extension}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Search and Pattern Matching\n",
    "\n",
    "Search for patterns in text and code using grep-like functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate search and pattern matching\n",
    "print(\"=== Search and Pattern Matching ===\")\n",
    "\n",
    "# Sample code to search\n",
    "sample_code = '''import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def process_data(data, normalize=True):\n",
    "    \"\"\"Process experimental data with optional normalization.\"\"\"\n",
    "    if normalize:\n",
    "        data = (data - data.mean()) / data.std()\n",
    "    return data\n",
    "\n",
    "def train_model(X_train, y_train, model_type='svm'):\n",
    "    \"\"\"Train machine learning model.\"\"\"\n",
    "    if model_type == 'svm':\n",
    "        from sklearn.svm import SVC\n",
    "        model = SVC(kernel='rbf')\n",
    "    elif model_type == 'rf':\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        model = RandomForestClassifier(n_estimators=100)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "'''\n",
    "\n",
    "# Grep-like search\n",
    "print(\"\\n1. Grep-like pattern search:\")\n",
    "patterns = ['def', 'import', 'model', 'data']\n",
    "for pattern in patterns:\n",
    "    matches = stx.str.grep(sample_code, pattern)\n",
    "    print(f\"   Pattern '{pattern}': {len(matches)} matches\")\n",
    "    for i, match in enumerate(matches[:2]):  # Show first 2 matches\n",
    "        print(f\"     Line {match['line_number']}: {match['line'].strip()}\")\n",
    "\n",
    "# Advanced search with regex\n",
    "print(\"\\n2. Advanced pattern search:\")\n",
    "# Search for function definitions\n",
    "func_pattern = r'def\\s+(\\w+)\\s*\\('\n",
    "func_matches = stx.str.search(sample_code, func_pattern)\n",
    "print(f\"   Function definitions found: {len(func_matches)}\")\n",
    "for match in func_matches:\n",
    "    print(f\"     {match.group(1)}()\")\n",
    "\n",
    "# Search for imports\n",
    "import_pattern = r'from\\s+([\\w.]+)\\s+import\\s+([\\w, ]+)'\n",
    "import_matches = stx.str.search(sample_code, import_pattern)\n",
    "print(f\"\\n   Import statements found: {len(import_matches)}\")\n",
    "for match in import_matches:\n",
    "    print(f\"     from {match.group(1)} import {match.group(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Parsing and Processing\n",
    "\n",
    "Parse structured text data and perform advanced text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate text parsing\n",
    "print(\"=== Text Parsing and Processing ===\")\n",
    "\n",
    "# Parse structured data\n",
    "print(\"\\n1. Parsing structured text:\")\n",
    "log_entry = \"2024-03-15 14:23:45 [INFO] Experiment started - subject_id: 42, condition: A\"\n",
    "\n",
    "# Parse timestamp, level, and message\n",
    "parsed = stx.str.parse(log_entry, \n",
    "                      pattern=r'(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}) \\[(\\w+)\\] (.+)')\n",
    "if parsed:\n",
    "    timestamp, level, message = parsed.groups()\n",
    "    print(f\"   Timestamp: {timestamp}\")\n",
    "    print(f\"   Level: {level}\")\n",
    "    print(f\"   Message: {message}\")\n",
    "\n",
    "# Parse key-value pairs\n",
    "config_string = \"epochs=100, batch_size=32, learning_rate=0.001, dropout=0.2\"\n",
    "kv_pattern = r'(\\w+)=([\\d.]+)'\n",
    "kv_matches = stx.str.search(config_string, kv_pattern, all_matches=True)\n",
    "print(\"\\n2. Parsing configuration string:\")\n",
    "for match in kv_matches:\n",
    "    key, value = match.groups()\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# String replacement with patterns\n",
    "print(\"\\n3. Pattern-based string replacement:\")\n",
    "text = \"The temperature was 25C and the pressure was 1013hPa\"\n",
    "replacements = {\n",
    "    r'(\\d+)C': r'\\1Â°C',\n",
    "    r'(\\d+)hPa': r'\\1 hPa',\n",
    "}\n",
    "\n",
    "modified_text = text\n",
    "for pattern, replacement in replacements.items():\n",
    "    modified_text = stx.str.replace(modified_text, pattern, replacement)\n",
    "\n",
    "print(f\"   Original: {text}\")\n",
    "print(f\"   Modified: {modified_text}\")\n",
    "\n",
    "# Squeeze multiple spaces\n",
    "print(\"\\n4. Space normalization:\")\n",
    "messy_text = \"This   text    has     too    many      spaces\"\n",
    "clean_text = stx.str.squeeze_spaces(messy_text)\n",
    "print(f\"   Original: '{messy_text}'\")\n",
    "print(f\"   Cleaned:  '{clean_text}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Security and API Masking\n",
    "\n",
    "Mask sensitive information like API keys in logs and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate API masking\n",
    "print(\"=== Security and API Masking ===\")\n",
    "\n",
    "# Mask API keys in logs\n",
    "print(\"\\n1. API key masking:\")\n",
    "log_messages = [\n",
    "    \"Connecting to API with key: sk-1234567890abcdef1234567890abcdef\",\n",
    "    \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ\",\n",
    "    \"Database password: p@ssw0rd123!@#\",\n",
    "    \"AWS Access Key: AKIAIOSFODNN7EXAMPLE\"\n",
    "]\n",
    "\n",
    "for log in log_messages:\n",
    "    masked = stx.str.mask_api(log)\n",
    "    print(f\"   Original: {log[:50]}...\")\n",
    "    print(f\"   Masked:   {masked[:50]}...\")\n",
    "    print()\n",
    "\n",
    "# Custom masking patterns\n",
    "print(\"2. Custom sensitive data masking:\")\n",
    "sensitive_data = {\n",
    "    \"email\": \"john.doe@example.com\",\n",
    "    \"phone\": \"+1-555-123-4567\",\n",
    "    \"ssn\": \"123-45-6789\",\n",
    "    \"credit_card\": \"4532-1234-5678-9012\"\n",
    "}\n",
    "\n",
    "# Create masked versions\n",
    "for data_type, value in sensitive_data.items():\n",
    "    if data_type == \"email\":\n",
    "        # Keep domain, mask local part\n",
    "        parts = value.split('@')\n",
    "        masked = f\"{parts[0][:2]}****@{parts[1]}\"\n",
    "    elif data_type == \"phone\":\n",
    "        masked = f\"{value[:5]}***-****\"\n",
    "    elif data_type == \"ssn\":\n",
    "        masked = f\"***-**-{value[-4:]}\"\n",
    "    elif data_type == \"credit_card\":\n",
    "        masked = f\"****-****-****-{value[-4:]}\"\n",
    "    \n",
    "    print(f\"   {data_type}: {value} â†’ {masked}\")\n",
    "\n",
    "# Safe logging function\n",
    "print(\"\\n3. Safe logging example:\")\n",
    "def safe_log(message, sensitive_patterns=None):\n",
    "    \"\"\"Log message with automatic sensitive data masking.\"\"\"\n",
    "    # Apply API masking\n",
    "    safe_message = stx.str.mask_api(message)\n",
    "    \n",
    "    # Apply custom patterns if provided\n",
    "    if sensitive_patterns:\n",
    "        for pattern in sensitive_patterns:\n",
    "            safe_message = re.sub(pattern, '***MASKED***', safe_message)\n",
    "    \n",
    "    return safe_message\n",
    "\n",
    "test_log = \"User john.doe@example.com logged in with API key sk-abc123def456\"\n",
    "safe_version = safe_log(test_log, [r'\\b[\\w.]+@[\\w.]+\\b'])\n",
    "print(f\"   Original: {test_log}\")\n",
    "print(f\"   Safe:     {safe_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Utility Functions\n",
    "\n",
    "Additional string utility functions for scientific computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate utility functions\n",
    "print(\"=== String Utility Functions ===\")\n",
    "\n",
    "# Readable byte sizes\n",
    "print(\"\\n1. Human-readable byte sizes:\")\n",
    "file_sizes = [1024, 1048576, 1073741824, 1099511627776, 1234567890]\n",
    "for size in file_sizes:\n",
    "    readable = stx.str.readable_bytes(size)\n",
    "    print(f\"   {size:>15} bytes â†’ {readable}\")\n",
    "\n",
    "# Debug printing\n",
    "print(\"\\n2. Debug printing with context:\")\n",
    "def process_data(data):\n",
    "    stx.str.print_debug(\"Starting data processing\", data.shape)\n",
    "    \n",
    "    # Process data\n",
    "    result = data.mean(axis=0)\n",
    "    \n",
    "    stx.str.print_debug(\"Processing complete\", result.shape)\n",
    "    return result\n",
    "\n",
    "test_data = np.random.randn(100, 10)\n",
    "result = process_data(test_data)\n",
    "\n",
    "# Decapitalize strings\n",
    "print(\"\\n3. String case manipulation:\")\n",
    "titles = [\n",
    "    \"NEURAL NETWORK ARCHITECTURE\",\n",
    "    \"Machine Learning Results\",\n",
    "    \"DATA PREPROCESSING PIPELINE\"\n",
    "]\n",
    "\n",
    "for title in titles:\n",
    "    decap = stx.str.decapitalize(title)\n",
    "    print(f\"   {title}\")\n",
    "    print(f\"   â†’ {decap}\")\n",
    "\n",
    "# Block printing for emphasis\n",
    "print(\"\\n4. Block printing for emphasis:\")\n",
    "stx.str.printc(\"EXPERIMENT RESULTS\", color=\"green\", style=\"block\")\n",
    "print(\"Accuracy: 95.3%\")\n",
    "print(\"F1 Score: 0.947\")\n",
    "print(\"AUC-ROC: 0.983\")\n",
    "stx.str.printc(\"END OF RESULTS\", color=\"green\", style=\"block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Integration Example: Scientific Report Generation\n",
    "\n",
    "Demonstrate how string utilities work together for report generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete scientific report generation example\n",
    "print(\"=== Scientific Report Generation Example ===\")\n",
    "\n",
    "class ScientificReportGenerator:\n",
    "    def __init__(self, experiment_name):\n",
    "        self.experiment_name = experiment_name\n",
    "        self.sections = []\n",
    "        \n",
    "    def add_header(self):\n",
    "        \"\"\"Add formatted header to report.\"\"\"\n",
    "        title = stx.str.format_title(self.experiment_name)\n",
    "        header = f\"\"\"\n",
    "{'=' * 70}\n",
    "{stx.str.color_text(title.upper(), 'blue')}\n",
    "{'=' * 70}\n",
    "\"\"\"\n",
    "        self.sections.append(header)\n",
    "        \n",
    "    def add_results(self, results_dict):\n",
    "        \"\"\"Add formatted results section.\"\"\"\n",
    "        section = [\"\\n## RESULTS\\n\"]\n",
    "        \n",
    "        for metric, value in results_dict.items():\n",
    "            # Format metric name\n",
    "            metric_label = stx.str.format_title(metric)\n",
    "            \n",
    "            # Format value based on type\n",
    "            if isinstance(value, float):\n",
    "                if value < 0.01:\n",
    "                    value_str = stx.str.scientific_text(f\"{value:.3e}\")\n",
    "                else:\n",
    "                    value_str = f\"{value:.4f}\"\n",
    "            else:\n",
    "                value_str = str(value)\n",
    "            \n",
    "            # Color code based on performance\n",
    "            if metric.lower() in ['accuracy', 'precision', 'recall', 'f1_score']:\n",
    "                if isinstance(value, (int, float)) and value > 0.9:\n",
    "                    value_str = stx.str.color_text(value_str, 'green')\n",
    "                elif isinstance(value, (int, float)) and value < 0.7:\n",
    "                    value_str = stx.str.color_text(value_str, 'red')\n",
    "            \n",
    "            section.append(f\"  {metric_label}: {value_str}\")\n",
    "        \n",
    "        self.sections.append('\\n'.join(section))\n",
    "        \n",
    "    def add_statistical_tests(self, test_results):\n",
    "        \"\"\"Add statistical test results with proper formatting.\"\"\"\n",
    "        section = [\"\\n## STATISTICAL ANALYSIS\\n\"]\n",
    "        \n",
    "        for test_name, test_data in test_results.items():\n",
    "            formatted_name = stx.str.format_title(test_name)\n",
    "            section.append(f\"\\n### {formatted_name}\")\n",
    "            \n",
    "            # Format p-value with significance stars\n",
    "            p_value = test_data['p_value']\n",
    "            if p_value < 0.001:\n",
    "                p_str = stx.str.color_text(\"p < 0.001 ***\", 'green')\n",
    "            elif p_value < 0.01:\n",
    "                p_str = stx.str.color_text(f\"p = {p_value:.3f} **\", 'green')\n",
    "            elif p_value < 0.05:\n",
    "                p_str = stx.str.color_text(f\"p = {p_value:.3f} *\", 'yellow')\n",
    "            else:\n",
    "                p_str = f\"p = {p_value:.3f} (n.s.)\"\n",
    "            \n",
    "            section.append(f\"  Statistical significance: {p_str}\")\n",
    "            section.append(f\"  Test statistic: {test_data['statistic']:.4f}\")\n",
    "            section.append(f\"  Effect size: {test_data['effect_size']:.3f}\")\n",
    "        \n",
    "        self.sections.append('\\n'.join(section))\n",
    "        \n",
    "    def add_file_info(self, file_paths):\n",
    "        \"\"\"Add file information section.\"\"\"\n",
    "        section = [\"\\n## OUTPUT FILES\\n\"]\n",
    "        \n",
    "        for file_path in file_paths:\n",
    "            # Clean path for display\n",
    "            clean_path = stx.str.clean_path(file_path)\n",
    "            \n",
    "            # Get file size if exists\n",
    "            if Path(file_path).exists():\n",
    "                size = Path(file_path).stat().st_size\n",
    "                size_str = stx.str.readable_bytes(size)\n",
    "                section.append(f\"  â€¢ {clean_path} ({size_str})\")\n",
    "            else:\n",
    "                section.append(f\"  â€¢ {clean_path} (pending)\")\n",
    "        \n",
    "        self.sections.append('\\n'.join(section))\n",
    "        \n",
    "    def generate(self):\n",
    "        \"\"\"Generate final report.\"\"\"\n",
    "        # Remove ANSI codes for file output\n",
    "        clean_sections = [stx.str.remove_ansi(section) for section in self.sections]\n",
    "        return '\\n'.join(clean_sections)\n",
    "        \n",
    "    def display(self):\n",
    "        \"\"\"Display report with colors.\"\"\"\n",
    "        return '\\n'.join(self.sections)\n",
    "\n",
    "# Create example report\n",
    "report = ScientificReportGenerator(\"neural_network_classification_analysis\")\n",
    "report.add_header()\n",
    "\n",
    "# Add results\n",
    "results = {\n",
    "    'accuracy': 0.9534,\n",
    "    'precision': 0.9412,\n",
    "    'recall': 0.9667,\n",
    "    'f1_score': 0.9538,\n",
    "    'auc_roc': 0.9823,\n",
    "    'training_time': 145.67,\n",
    "    'n_parameters': 1234567\n",
    "}\n",
    "report.add_results(results)\n",
    "\n",
    "# Add statistical tests\n",
    "stats_results = {\n",
    "    'model_comparison_t_test': {\n",
    "        'p_value': 0.0023,\n",
    "        'statistic': 3.456,\n",
    "        'effect_size': 0.82\n",
    "    },\n",
    "    'permutation_test': {\n",
    "        'p_value': 0.0001,\n",
    "        'statistic': 4.789,\n",
    "        'effect_size': 1.23\n",
    "    }\n",
    "}\n",
    "report.add_statistical_tests(stats_results)\n",
    "\n",
    "# Add file information\n",
    "output_files = [\n",
    "    str(work_dir / 'model_weights.pkl'),\n",
    "    str(work_dir / 'training_history.csv'),\n",
    "    str(work_dir / 'confusion_matrix.png'),\n",
    "    str(work_dir / 'roc_curve.pdf')\n",
    "]\n",
    "report.add_file_info(output_files)\n",
    "\n",
    "# Display colored report\n",
    "print(report.display())\n",
    "\n",
    "# Save clean version\n",
    "report_path = work_dir / 'experiment_report.txt'\n",
    "with open(report_path, 'w') as f:\n",
    "    f.write(report.generate())\n",
    "print(f\"\\nReport saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary and Best Practices\n",
    "\n",
    "The SciTeX str module provides comprehensive string utilities for scientific computing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of key string utilities\n",
    "summary = {\n",
    "    'Text Formatting': [\n",
    "        'stx.str.color_text() - Terminal color formatting',\n",
    "        'stx.str.remove_ansi() - Clean ANSI codes',\n",
    "        'stx.str.printc() - Block printing with emphasis',\n",
    "        'stx.str.print_debug() - Debug output with context'\n",
    "    ],\n",
    "    'Scientific Notation': [\n",
    "        'stx.str.to_latex_style() - Convert to LaTeX',\n",
    "        'stx.str.add_hat_in_latex_style() - Add vector notation',\n",
    "        'stx.str.scientific_text() - Format scientific notation',\n",
    "        'stx.str.safe_latex_render() - Safe LaTeX with fallback'\n",
    "    ],\n",
    "    'Plot Formatting': [\n",
    "        'stx.str.format_axis_label() - Axis labels with units',\n",
    "        'stx.str.format_title() - Clean plot titles',\n",
    "        'stx.str.smart_tick_formatter() - Intelligent tick labels',\n",
    "        'stx.str.factor_out_digits() - Factor large numbers'\n",
    "    ],\n",
    "    'Text Processing': [\n",
    "        'stx.str.grep() - Pattern matching in text',\n",
    "        'stx.str.search() - Advanced regex search',\n",
    "        'stx.str.parse() - Structured text parsing',\n",
    "        'stx.str.replace() - Pattern-based replacement'\n",
    "    ],\n",
    "    'Path Operations': [\n",
    "        'stx.str.clean_path() - Normalize path strings',\n",
    "        'stx.str.squeeze_spaces() - Remove extra spaces',\n",
    "        'Cross-platform path handling',\n",
    "        'Safe path string manipulation'\n",
    "    ],\n",
    "    'Security': [\n",
    "        'stx.str.mask_api() - Hide sensitive data',\n",
    "        'API key detection and masking',\n",
    "        'Safe logging practices',\n",
    "        'Data privacy protection'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"SciTeX String Utilities (str) Module - Summary\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for category, utilities in summary.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for utility in utilities:\n",
    "        print(f\"  â€¢ {utility}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Best Practices:\")\n",
    "print(\"  â€¢ Use color_text() for important terminal output\")\n",
    "print(\"  â€¢ Apply mask_api() before logging sensitive data\")\n",
    "print(\"  â€¢ Format plot text for publication-ready figures\")\n",
    "print(\"  â€¢ Use LaTeX formatting with fallback for compatibility\")\n",
    "print(\"  â€¢ Clean paths for cross-platform compatibility\")\n",
    "print(\"  â€¢ Parse structured text with appropriate patterns\")\n",
    "print(\"  â€¢ Generate reports with proper formatting and colors\")\n",
    "\n",
    "print(f\"\\nDemo completed successfully! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "import shutil\n",
    "\n",
    "if work_dir.exists():\n",
    "    shutil.rmtree(work_dir)\n",
    "    print(f\"Cleaned up: {work_dir}\")\n",
    "\n",
    "print(\"\\nNotebook cleanup completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}